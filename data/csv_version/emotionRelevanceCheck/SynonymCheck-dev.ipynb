{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ac9108f-2bc5-4a48-ad6c-07a07b7d7f4d",
   "metadata": {},
   "source": [
    "This notebook should be processed after the initial pre-processing of the dev data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a3b90c1-83e2-4e08-813c-abcdde097949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Â§öÁ∫øÁ®ã‰ºòÂåñ\n",
    "\n",
    "# ÊâæÂà∞‰∏Ä‰∫õÂÖ∂‰ªñÁöÑÊï∞ÊçÆÈõÜÔºåÁÑ∂ÂêéÂÆûË∑µÔºåÁúãÊ≥õÂåñÊÄß\n",
    "# ÊÉÖÊÑüÊñπÂêëÔºàÂπø‰∏Ä‰∫õÔºâ\n",
    "\n",
    "# Áúã percentage, ÊîπÈòàÂÄº\n",
    "# CLIP‰∏∫ plan b (too much...)\n",
    "\n",
    "# ÁúãÂçï‰∏™caseÁöÑËøë‰πâËØçÔºå‰∏çÂà†Èô§Ôºå‰ΩÜÊòØcluster\n",
    "# | <- ÂàÜÈöîÁ¨¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f392e1e2-ed3c-42de-a9c7-a719402613c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# use only for dictionary parsing...\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35284f7d-d1f8-4fc2-a281-b83e3febeb17",
   "metadata": {},
   "source": [
    "# 0. Review: synonyms detection\n",
    "## synonymNet\n",
    "https://arxiv.org/abs/1901.00056https://arxiv.org/abs/1901.00056\n",
    "\n",
    "Being able to automatically discover synonymous entities in an open-world setting benefits various tasks such as entity disambiguation or knowledge graph canonicalization. Existing works either only utilize entity features, or rely on structured annotations from a single piece of context where the entity is mentioned. To leverage diverse contexts where entities are mentioned, in this paper, we generalize the distributional hypothesis to a multi-context setting and propose a synonym discovery framework that detects entity synonyms from free-text corpora with considerations on effectiveness and robustness. As one of the key components in synonym discovery, we introduce a neural network model SYNONYMNET to determine whether or not two given entities are synonym with each other. Instead of using entities features, SYNONYMNET makes use of multiple pieces of contexts in which the entity is mentioned, and compares the context-level similarity via a bilateral matching schema. Experimental results demonstrate that the proposed model is able to detect synonym sets that are not observed during training on both generic and domain-specific datasets: Wiki+Freebase, PubMed+UMLS, and MedBook+MKG, with up to 4.16% improvement in terms of Area Under the Curve and 3.19% in terms of Mean Average Precision compared to the best baseline method.Being able to automatically discover synonymous entities in an open-world setting benefits various tasks such as entity disambiguation or knowledge graph canonicalization. Existing works either only utilize entity features, or rely on structured annotations from a single piece of context where the entity is mentioned. To leverage diverse contexts where entities are mentioned, in this paper, we generalize the distributional hypothesis to a multi-context setting and propose a synonym discovery framework that detects entity synonyms from free-text corpora with considerations on effectiveness and robustness. As one of the key components in synonym discovery, we introduce a neural network model SYNONYMNET to determine whether or not two given entities are synonym with each other. Instead of using entities features, SYNONYMNET makes use of multiple pieces of contexts in which the entity is mentioned, and compares the context-level similarity via a bilateral matching schema. Experimental results demonstrate that the proposed model is able to detect synonym sets that are not observed during training on both generic and domain-specific datasets: Wiki+Freebase, PubMed+UMLS, and MedBook+MKG, with up to 4.16% improvement in terms of Area Under the Curve and 3.19% in terms of Mean Average Precision compared to the best baseline method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a1122d2-5d28-4cee-9508-d773eb321e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smart_open library not found; falling back to local-filesystem-only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jieba] default dict file path ..\\data\\vocab.txt\n",
      "[jieba] default dict file path ..\\data\\vocab.txt\n",
      "[jieba] load default dict ..\\data\\vocab.txt ...\n",
      "[jieba] load default dict ..\\data\\vocab.txt ...\n",
      ">> Synonyms load wordseg dict [C:\\Python\\miniconda3\\envs\\story_cloze\\lib\\site-packages\\synonyms\\data\\vocab.txt] ... \n",
      ">> Synonyms on loading stopwords [C:\\Python\\miniconda3\\envs\\story_cloze\\lib\\site-packages\\synonyms\\data\\stopwords.txt] ...\n",
      "[Synonyms] on loading vectors [C:\\Python\\miniconda3\\envs\\story_cloze\\lib\\site-packages\\synonyms\\data\\words.vector.gz] ...\n"
     ]
    }
   ],
   "source": [
    "import synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9abd13be-867b-44ca-8ea6-059f34a234b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÂºÄÂøÉ:  (['ÂºÄÂøÉ', 'È´òÂÖ¥', 'ÂÖ¥Â•ã', 'ÊÑâÂø´', 'ÈöæËøá', 'Âø´‰πê', '‰º§ÂøÉ', 'ÁóõÂø´', 'Â∞ΩÂÖ¥', 'ÂæóÊÑè'], [1.0, 0.80510014, 0.7370683, 0.7110831, 0.7060874, 0.69482696, 0.67555505, 0.65788877, 0.6525332, 0.64982194])\n",
      "‰º§ÂøÉ:  (['‰º§ÂøÉ', 'ÈöæËøá', 'ÂøÉÁóõ', 'ÊÇ≤‰º§', 'ÊÇ≤Áóõ', 'ÊÇîÊÅ®', 'ÂøÉÁñº', 'ÈÉÅÈó∑', 'ÊÇ≤ÊÑ§', 'ÂøêÂøë'], [1.0, 0.87252134, 0.8377604, 0.82897615, 0.7907454, 0.75183433, 0.7486311, 0.7461942, 0.7386005, 0.7325378])\n",
      "NOT_EXIST:  ([], [])\n"
     ]
    }
   ],
   "source": [
    "# ‰∏≠ÊñáËøòË°å\n",
    "print(\"ÂºÄÂøÉ: \", synonyms.nearby(\"ÂºÄÂøÉ\"))\n",
    "print(\"‰º§ÂøÉ: \", synonyms.nearby(\"‰º§ÂøÉ\"))\n",
    "print(\"NOT_EXIST: \", synonyms.nearby(\"NOT_EXIST\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21118b8e-755b-400b-af24-9c5a257aa8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy:  (['happy', 'Let', 'is', 'This', 'all', 'it', 'To', 'fame', 'spend', 'creates'], [1.0, 0.6119284, 0.5868017, 0.5624877, 0.5546613, 0.5529554, 0.5517211, 0.5055882, 0.49800324, 0.46012384])\n",
      "sad:  (['sad', 'failing', 'esta', 'initially', 'Though', 'defend', 'returning', 'fame', 'begun', 'proved'], [1.0, 0.5269767, 0.52678764, 0.5045616, 0.49744284, 0.49625623, 0.4941613, 0.4784833, 0.4747744, 0.4695003])\n"
     ]
    }
   ],
   "source": [
    "# Ëã±ÊñáÂØÑ‰∫Ü\n",
    "print(\"happy: \", synonyms.nearby(\"happy\"))\n",
    "print(\"sad: \", synonyms.nearby(\"sad\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c1a1ae-d76e-483f-a9e7-6277f4f3f9d3",
   "metadata": {},
   "source": [
    "## NLTK - wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da43c9e5-e71e-4bed-9c1c-c867984b41a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9628315-88c2-485e-8b38-a3dafc3f151f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('happy.a.01'),\n",
       " Synset('felicitous.s.02'),\n",
       " Synset('glad.s.02'),\n",
       " Synset('happy.s.04')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet.synsets('happy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "222cae44-ed77-4a6a-b0ba-b8bf8be2f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordNetCheck(wordInput):\n",
    "    # Then, we're going to use the term \"program\" to find synsets like so:\n",
    "    syns = wordnet.synsets(wordInput)\n",
    "\n",
    "    # An example of a synset:\n",
    "    print(syns[0].name())\n",
    "\n",
    "    # Just the word:\n",
    "    print(syns[0].lemmas()[0].name())\n",
    "\n",
    "    # Definition of that first synset:\n",
    "    print(syns[0].definition())\n",
    "\n",
    "    # Examples of the word in use in sentences:\n",
    "    print(syns[0].examples(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "755bde00-d654-45a8-8370-1347cac8e65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy.a.01\n",
      "happy\n",
      "enjoying or showing or marked by joy or pleasure\n",
      "['a happy smile', 'spent many happy days on the beach', 'a happy marriage'] \n",
      "\n",
      "gladiolus.n.01\n",
      "gladiolus\n",
      "any of numerous plants of the genus Gladiolus native chiefly to tropical and South Africa having sword-shaped leaves and one-sided spikes of brightly colored funnel-shaped flowers; widely cultivated\n",
      "[] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "wordNetCheck('happy')\n",
    "\n",
    "wordNetCheck('glad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a0cee1-052e-4f5b-9f8c-15acde71497d",
   "metadata": {},
   "source": [
    "We can use this framework to find possible synonyms & antonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4330d34-4195-4a43-a4c5-959720311ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'stressed', 'disturbed', 'in_a_bad_way', 'hard-pressed', 'distress', 'dysphoric', 'distressed', 'hard_put', 'straiten', 'upset', 'unhappy', 'disquieted', 'worried'}\n",
      "{'euphoric'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['stressed',\n",
       " 'disturbed',\n",
       " 'in_a_bad_way',\n",
       " 'hard-pressed',\n",
       " 'distress',\n",
       " 'dysphoric',\n",
       " 'distressed',\n",
       " 'hard_put',\n",
       " 'straiten',\n",
       " 'upset',\n",
       " 'unhappy',\n",
       " 'disquieted',\n",
       " 'worried']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "synonyms = []\n",
    "antonyms = []\n",
    "for syn in wordnet.synsets(\"distressed\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "            \n",
    "print(set(synonyms))\n",
    "print(set(antonyms))\n",
    "\n",
    "list(x.antonyms()[0].name() for y in wordnet.synsets(\"distressed\") for x in y.lemmas() if x.antonyms())\n",
    "list(set(list(emotion.name() for allrelated in wordnet.synsets(\"distressed\") for emotion in allrelated.lemmas())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c3d948-365d-435f-89c7-d28a2e2eb4cf",
   "metadata": {},
   "source": [
    "Method 1Ôºö\n",
    "\n",
    "Create undirected weighted graph and find link or path\n",
    "\n",
    "\n",
    "üëá\n",
    "\n",
    "Method 2Ôºö\n",
    "\n",
    "use wordNet definition of each emotion to find context similarities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f775b4f-e892-429f-b2fc-29d2f73fb022",
   "metadata": {},
   "source": [
    "## 0.1 Using wordnet to calculate weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "479f2635-485c-4458-8b8b-f22745d92f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateRelavancyUsingWordNet(e1, e2, threshold):\n",
    "    \"\"\"\n",
    "    This function using BFS to calculate the potential weight of 2 emotion\n",
    "    \n",
    "    @param e1:        represents a emotion\n",
    "    @param e2:        represents a emotion\n",
    "    @param threshold: store the maximum score allowed for 2 emotion(usually <= 3)\n",
    "    e.g. 1. we expected score == 0 when e1 == e2\n",
    "    \n",
    "         2. we expected 0 <= score <= threshold when e1 -> e2 is highly related\n",
    "            else score = MAX_INT\n",
    "    \"\"\"\n",
    "    \n",
    "    # invalid input\n",
    "    if (e1.count(\" \") > 0 or e2.count(\" \") > 0):\n",
    "        print(\"Warning: \\\"\"+ e1 + \"\\\" or \\\"\" + e2 + \"\\\" is not a word\")\n",
    "    if (threshold <= 0):\n",
    "        raise Exception(\"Error: invalid threshold\")\n",
    "    \n",
    "    # case: same, no need to analyze\n",
    "    if (e1 == e2): return 0;\n",
    "\n",
    "    # case: normal, start limited BFS\n",
    "    visited = [e1]\n",
    "    queue = [e1]\n",
    "    level = [[] for i in range(threshold)]\n",
    "    level[0].append(e1)\n",
    "    while queue:\n",
    "        currentEmotion = queue.pop(0)\n",
    "        if ([currentEmotion in x for x in level].index(True) + 1 >= threshold): break;\n",
    "        for neighbour in np.unique(list(set(list(emotion.name() for allrelated in wordnet.synsets(currentEmotion) for emotion in allrelated.lemmas())))):\n",
    "            if (neighbour == e2):\n",
    "                # print(\"Success: BFS level-of-nodes report for \\\"{}\\\": {}\\n\".format(e1, level))\n",
    "                return len([nested for nested in level if nested]) - 1\n",
    "            if neighbour not in visited:\n",
    "                level[[currentEmotion in x for x in level].index(True) + 1].append(neighbour) # get parent's level to set neighbour to a proper pos\n",
    "                visited.append(neighbour)\n",
    "                queue.append(neighbour)\n",
    "            \n",
    "    return sys.maxsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20772c1f-ba83-47e8-aa8c-9ce6b5086035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected: 1, get: 1\n",
      "expected: sys max int, get: 9223372036854775807\n",
      "expected: 0, get: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"expected: {}, get: {}\".format(1, calculateRelavancyUsingWordNet(\"happy\", \"glad\", 3)))\n",
    "print(\"expected: {}, get: {}\".format(\"sys max int\", calculateRelavancyUsingWordNet(\"unhappy\", \"happy\", 3)))\n",
    "print(\"expected: {}, get: {}\".format(0, calculateRelavancyUsingWordNet(\"sad\", \"sad\", 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa07aeb-88f7-47b6-b306-faf57fe6b30b",
   "metadata": {},
   "source": [
    "# 1. Modify processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "889a9c6b-b2d2-46dc-bb0c-b34ee0b3fb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>storyid</th>\n",
       "      <th>linenum</th>\n",
       "      <th>char</th>\n",
       "      <th>emotionworkerid</th>\n",
       "      <th>context</th>\n",
       "      <th>sentence</th>\n",
       "      <th>affected</th>\n",
       "      <th>emotion</th>\n",
       "      <th>plutchik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>1</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>ann0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I began making fish curry for my boyfriend and I.</td>\n",
       "      <td>yes</td>\n",
       "      <td>[joy, excited]</td>\n",
       "      <td>{'joy': 3, 'trust': 3, 'surprise': 3, 'anticip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>1</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>ann1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I began making fish curry for my boyfriend and I.</td>\n",
       "      <td>yes</td>\n",
       "      <td>[content]</td>\n",
       "      <td>{'joy': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>1</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>ann2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I began making fish curry for my boyfriend and I.</td>\n",
       "      <td>yes</td>\n",
       "      <td>[hungry, anticipation]</td>\n",
       "      <td>{'joy': 2, 'anticipation': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>2</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>ann1</td>\n",
       "      <td>I began making fish curry for my boyfriend and I.</td>\n",
       "      <td>I decided not to read a recipe since I've made...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[excited]</td>\n",
       "      <td>{'joy': 3, 'trust': 3, 'anticipation': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>2</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>ann2</td>\n",
       "      <td>I began making fish curry for my boyfriend and I.</td>\n",
       "      <td>I decided not to read a recipe since I've made...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[confident]</td>\n",
       "      <td>{'joy': 2, 'trust': 3, 'anticipation': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42947</th>\n",
       "      <td>42947</td>\n",
       "      <td>2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e</td>\n",
       "      <td>4</td>\n",
       "      <td>Marcus</td>\n",
       "      <td>ann1</td>\n",
       "      <td>Marcus was collecting shells on the beach.|He ...</td>\n",
       "      <td>Suddenly he felt a sharp pinch.</td>\n",
       "      <td>yes</td>\n",
       "      <td>[sore]</td>\n",
       "      <td>{'joy': 2, 'trust': 2, 'fear': 2, 'sadness': 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42948</th>\n",
       "      <td>42948</td>\n",
       "      <td>2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e</td>\n",
       "      <td>4</td>\n",
       "      <td>Marcus</td>\n",
       "      <td>ann2</td>\n",
       "      <td>Marcus was collecting shells on the beach.|He ...</td>\n",
       "      <td>Suddenly he felt a sharp pinch.</td>\n",
       "      <td>yes</td>\n",
       "      <td>[surprised]</td>\n",
       "      <td>{'joy': 2, 'fear': 2, 'surprise': 3, 'anticipa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42949</th>\n",
       "      <td>42949</td>\n",
       "      <td>2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e</td>\n",
       "      <td>5</td>\n",
       "      <td>Marcus</td>\n",
       "      <td>ann0</td>\n",
       "      <td>Marcus was collecting shells on the beach.|He ...</td>\n",
       "      <td>A crab was inside the shell pinching his leg.</td>\n",
       "      <td>yes</td>\n",
       "      <td>[shocked]</td>\n",
       "      <td>{'fear': 2, 'surprise': 3, 'anticipation': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42950</th>\n",
       "      <td>42950</td>\n",
       "      <td>2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e</td>\n",
       "      <td>5</td>\n",
       "      <td>Marcus</td>\n",
       "      <td>ann1</td>\n",
       "      <td>Marcus was collecting shells on the beach.|He ...</td>\n",
       "      <td>A crab was inside the shell pinching his leg.</td>\n",
       "      <td>yes</td>\n",
       "      <td>[surprised]</td>\n",
       "      <td>{'fear': 2, 'surprise': 3, 'anticipation': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42951</th>\n",
       "      <td>42951</td>\n",
       "      <td>2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e</td>\n",
       "      <td>5</td>\n",
       "      <td>Marcus</td>\n",
       "      <td>ann2</td>\n",
       "      <td>Marcus was collecting shells on the beach.|He ...</td>\n",
       "      <td>A crab was inside the shell pinching his leg.</td>\n",
       "      <td>yes</td>\n",
       "      <td>[pained]</td>\n",
       "      <td>{'fear': 3, 'surprise': 3, 'anticipation': 3}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42952 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                               storyid  linenum        char  \\\n",
       "0          0  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        1  I (myself)   \n",
       "1          1  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        1  I (myself)   \n",
       "2          2  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        1  I (myself)   \n",
       "3          3  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        2  I (myself)   \n",
       "4          4  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        2  I (myself)   \n",
       "...      ...                                   ...      ...         ...   \n",
       "42947  42947  2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e        4      Marcus   \n",
       "42948  42948  2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e        4      Marcus   \n",
       "42949  42949  2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e        5      Marcus   \n",
       "42950  42950  2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e        5      Marcus   \n",
       "42951  42951  2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e        5      Marcus   \n",
       "\n",
       "      emotionworkerid                                            context  \\\n",
       "0                ann0                                                NaN   \n",
       "1                ann1                                                NaN   \n",
       "2                ann2                                                NaN   \n",
       "3                ann1  I began making fish curry for my boyfriend and I.   \n",
       "4                ann2  I began making fish curry for my boyfriend and I.   \n",
       "...               ...                                                ...   \n",
       "42947            ann1  Marcus was collecting shells on the beach.|He ...   \n",
       "42948            ann2  Marcus was collecting shells on the beach.|He ...   \n",
       "42949            ann0  Marcus was collecting shells on the beach.|He ...   \n",
       "42950            ann1  Marcus was collecting shells on the beach.|He ...   \n",
       "42951            ann2  Marcus was collecting shells on the beach.|He ...   \n",
       "\n",
       "                                                sentence affected  \\\n",
       "0      I began making fish curry for my boyfriend and I.      yes   \n",
       "1      I began making fish curry for my boyfriend and I.      yes   \n",
       "2      I began making fish curry for my boyfriend and I.      yes   \n",
       "3      I decided not to read a recipe since I've made...      yes   \n",
       "4      I decided not to read a recipe since I've made...      yes   \n",
       "...                                                  ...      ...   \n",
       "42947                    Suddenly he felt a sharp pinch.      yes   \n",
       "42948                    Suddenly he felt a sharp pinch.      yes   \n",
       "42949      A crab was inside the shell pinching his leg.      yes   \n",
       "42950      A crab was inside the shell pinching his leg.      yes   \n",
       "42951      A crab was inside the shell pinching his leg.      yes   \n",
       "\n",
       "                      emotion  \\\n",
       "0              [joy, excited]   \n",
       "1                   [content]   \n",
       "2      [hungry, anticipation]   \n",
       "3                   [excited]   \n",
       "4                 [confident]   \n",
       "...                       ...   \n",
       "42947                  [sore]   \n",
       "42948             [surprised]   \n",
       "42949               [shocked]   \n",
       "42950             [surprised]   \n",
       "42951                [pained]   \n",
       "\n",
       "                                                plutchik  \n",
       "0      {'joy': 3, 'trust': 3, 'surprise': 3, 'anticip...  \n",
       "1                                             {'joy': 2}  \n",
       "2                          {'joy': 2, 'anticipation': 3}  \n",
       "3              {'joy': 3, 'trust': 3, 'anticipation': 3}  \n",
       "4              {'joy': 2, 'trust': 3, 'anticipation': 2}  \n",
       "...                                                  ...  \n",
       "42947  {'joy': 2, 'trust': 2, 'fear': 2, 'sadness': 3...  \n",
       "42948  {'joy': 2, 'fear': 2, 'surprise': 3, 'anticipa...  \n",
       "42949      {'fear': 2, 'surprise': 3, 'anticipation': 3}  \n",
       "42950      {'fear': 2, 'surprise': 3, 'anticipation': 2}  \n",
       "42951      {'fear': 3, 'surprise': 3, 'anticipation': 3}  \n",
       "\n",
       "[42952 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDevEmotionMultipleSentence = pd.read_csv('dev/emotion/allcharlinepairs-withoutPlutchikVoting-v1.csv')\n",
    "dataDevEmotionMultipleSentence['emotion'] = [list(x.strip('[').strip(']').strip('\\\"').strip().replace(\"\\\", \\\"\", \", \").replace(\"\\'\", \"\").split(', ')) \n",
    "                              for x in dataDevEmotionMultipleSentence['emotion']]\n",
    "dataDevEmotionMultipleSentence['plutchik'] = [ast.literal_eval(x) for x in dataDevEmotionMultipleSentence['plutchik']]\n",
    "\n",
    "dataDevEmotionMultipleSentence = dataDevEmotionMultipleSentence.drop(labels='Unnamed: 0',axis=1)\n",
    "dataDevEmotionMultipleSentence.index.names = ['index']\n",
    "dataDevEmotionMultipleSentence = dataDevEmotionMultipleSentence.reset_index()\n",
    "dataDevEmotionMultipleSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26465d2d-2372-47ce-a45d-c6af3d7d0a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the dataframe going to analyzed\n",
    "currentAnalyze = dataDevEmotionMultipleSentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b8f8f4-f305-4cc0-848a-5bfa16dfc7b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Modified plutchik analyze\n",
    "## 2.1 Standard plutchik(including no emotion case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2cfcf2e-663a-4c5e-ad0b-7e7e6be8cf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JAM_0\\AppData\\Local\\Temp/ipykernel_45800/2464059937.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  currentAnalyze['plutchik'][index] = tempalteOrder.copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1 Standard plutchik(including no emotion case) -> start conversion, current progress: 42952/42952 "
     ]
    }
   ],
   "source": [
    "for index, row in currentAnalyze.iterrows():\n",
    "    tempalteOrder = {'joy' : 0, 'trust' : 0, 'fear' : 0, 'surprise' : 0, 'sadness' : 0, 'disgust' : 0, 'anger' : 0, 'anticipation' : 0}\n",
    "    for key, value in row['plutchik'].items():\n",
    "        tempalteOrder[key] = value\n",
    "    currentAnalyze['plutchik'][index] = tempalteOrder.copy()\n",
    "    print(\"\\r\", end=\"\")\n",
    "    print(\"2.1 Standard plutchik(including no emotion case) -> start conversion, current progress: {}/{} \".format(index+1, currentAnalyze.shape[0]), end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec5d80f-a261-4173-83f5-aa5291ee229e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2 Modify emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12a80921-ff7a-4893-b0dd-7667f0e7ee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "currentAnalyze['emotion'] = currentAnalyze.emotion.map(lambda x: {emotion : 1 for emotion in x })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb76e996-e792-437a-926b-04a479b3547a",
   "metadata": {},
   "source": [
    "### 2.3 Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e81c7f3a-3510-4f5b-a907-4bfb7ad7df51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2 Voting -> start voting, current progress: 42952/42952 "
     ]
    }
   ],
   "source": [
    "# EMOTION Âä†‰∏Ä‰∏™weightÔºåË°®ËææÁ®ãÂ∫¶\n",
    "# Á°ÆËÆ§Âêå‰πâËØçÁöÑÂÆö‰πâÔºà‰∏Ä‰∏™‰∫∫ÊòØÂê¶ÂêåÊó∂ËØ¥happy, glad...Ôºâ\n",
    "mainPosIndex = pd.Series(False, index = currentAnalyze.index)\n",
    "for index, row in currentAnalyze.iterrows():\n",
    "    if (index == 0 or currentEditting['sentence'] != row['sentence']): # case: new sentence, update CURRENT adding\n",
    "        if (index != 0):\n",
    "            for key in currentEditting['plutchik']:\n",
    "                # print(index - currentEditting[0], \"previous: \", currentEditting[1]['plutchik'][key])\n",
    "                currentEditting['plutchik'][key] //= index - currentEditting[0]\n",
    "            for i in range(currentEditting['index'] + 1, index):\n",
    "                for emotion in currentAnalyze['emotion'][i]:\n",
    "                    currentAnalyze['emotion'][currentEditting['index']][emotion] = currentAnalyze['emotion'][currentEditting['index']].get(emotion, 0) + 1 \n",
    "        currentEditting = currentAnalyze.iloc[index]\n",
    "        mainPosIndex[currentEditting['index']] = True\n",
    "    else: # case: same as previous sentence, do voting\n",
    "        for key, value in currentAnalyze['plutchik'][index].items():\n",
    "            currentAnalyze['plutchik'][currentEditting['index']][key] += value\n",
    "    print(\"\\r\", end=\"\")\n",
    "    print(\"2.2 Voting -> start voting, current progress: {}/{} \".format(index+1, currentAnalyze.shape[0]), end=\"\")\n",
    "    \n",
    "# dealing last case\n",
    "for key in currentEditting['plutchik']:\n",
    "    # print(index - currentEditting[0], \"previous: \", currentEditting[1]['plutchik'][key])\n",
    "    currentEditting['plutchik'][key] //= index - currentEditting[0]\n",
    "for i in range(currentEditting['index'] + 1, index):\n",
    "    for emotion in currentAnalyze['emotion'][i]:\n",
    "        currentAnalyze['emotion'][currentEditting['index']][emotion] = currentAnalyze['emotion'][currentEditting['index']].get(emotion, 0) + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ac0c623-e086-4376-b9f2-0cfea732b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "currentAnalyze = currentAnalyze[mainPosIndex]\n",
    "currentAnalyze = currentAnalyze.drop(labels='index',axis=1)\n",
    "currentAnalyze = currentAnalyze.reset_index(drop=True)\n",
    "currentAnalyze.index.names = ['index']\n",
    "currentAnalyze = currentAnalyze.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fcef243-04a9-4354-a03d-192f211b2e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>storyid</th>\n",
       "      <th>linenum</th>\n",
       "      <th>char</th>\n",
       "      <th>emotionworkerid</th>\n",
       "      <th>context</th>\n",
       "      <th>sentence</th>\n",
       "      <th>affected</th>\n",
       "      <th>emotion</th>\n",
       "      <th>plutchik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>1</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>ann0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I began making fish curry for my boyfriend and I.</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'joy': 1, 'excited': 1, 'content': 1, 'hungry...</td>\n",
       "      <td>{'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>2</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>ann1</td>\n",
       "      <td>I began making fish curry for my boyfriend and I.</td>\n",
       "      <td>I decided not to read a recipe since I've made...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'excited': 1, 'confident': 1}</td>\n",
       "      <td>{'joy': 2, 'trust': 3, 'fear': 0, 'surprise': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>3</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>ann0</td>\n",
       "      <td>I began making fish curry for my boyfriend and...</td>\n",
       "      <td>I let the curry sit before tasting.</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'anxious': 1, 'confident': 1, 'positive': 1}</td>\n",
       "      <td>{'joy': 1, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>4</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>ann1</td>\n",
       "      <td>I began making fish curry for my boyfriend and...</td>\n",
       "      <td>When it was time to taste, I was disgusted.</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'upset': 1, 'sick': 1}</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>5</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>ann1</td>\n",
       "      <td>I began making fish curry for my boyfriend and...</td>\n",
       "      <td>I accidentally used a whole garlic instead of ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'disgusted': 1, 'cretinous': 1}</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11605</th>\n",
       "      <td>11605</td>\n",
       "      <td>2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e</td>\n",
       "      <td>1</td>\n",
       "      <td>Marcus</td>\n",
       "      <td>ann0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marcus was collecting shells on the beach.</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'intrigued': 1, 'happy': 1, 'contemplative': 1}</td>\n",
       "      <td>{'joy': 3, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11606</th>\n",
       "      <td>11606</td>\n",
       "      <td>2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e</td>\n",
       "      <td>2</td>\n",
       "      <td>Marcus</td>\n",
       "      <td>ann0</td>\n",
       "      <td>Marcus was collecting shells on the beach.</td>\n",
       "      <td>He picked up a large beautiful shell.</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'awestruck': 1, 'moved': 1, 'joy': 1}</td>\n",
       "      <td>{'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11607</th>\n",
       "      <td>11607</td>\n",
       "      <td>2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e</td>\n",
       "      <td>3</td>\n",
       "      <td>Marcus</td>\n",
       "      <td>ann0</td>\n",
       "      <td>Marcus was collecting shells on the beach.|He ...</td>\n",
       "      <td>He put it in his pocket to save for later.</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'satisfied': 1, 'excited': 1, 'curiosity': 1}</td>\n",
       "      <td>{'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11608</th>\n",
       "      <td>11608</td>\n",
       "      <td>2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e</td>\n",
       "      <td>4</td>\n",
       "      <td>Marcus</td>\n",
       "      <td>ann0</td>\n",
       "      <td>Marcus was collecting shells on the beach.|He ...</td>\n",
       "      <td>Suddenly he felt a sharp pinch.</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'pained': 1, 'sore': 1, 'surprised': 1}</td>\n",
       "      <td>{'joy': 1, 'trust': 0, 'fear': 2, 'surprise': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11609</th>\n",
       "      <td>11609</td>\n",
       "      <td>2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e</td>\n",
       "      <td>5</td>\n",
       "      <td>Marcus</td>\n",
       "      <td>ann0</td>\n",
       "      <td>Marcus was collecting shells on the beach.|He ...</td>\n",
       "      <td>A crab was inside the shell pinching his leg.</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'shocked': 1, 'surprised': 1}</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 3, 'surprise': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11610 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                               storyid  linenum        char  \\\n",
       "0          0  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        1  I (myself)   \n",
       "1          1  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        2  I (myself)   \n",
       "2          2  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        3  I (myself)   \n",
       "3          3  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        4  I (myself)   \n",
       "4          4  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        5  I (myself)   \n",
       "...      ...                                   ...      ...         ...   \n",
       "11605  11605  2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e        1      Marcus   \n",
       "11606  11606  2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e        2      Marcus   \n",
       "11607  11607  2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e        3      Marcus   \n",
       "11608  11608  2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e        4      Marcus   \n",
       "11609  11609  2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e        5      Marcus   \n",
       "\n",
       "      emotionworkerid                                            context  \\\n",
       "0                ann0                                                NaN   \n",
       "1                ann1  I began making fish curry for my boyfriend and I.   \n",
       "2                ann0  I began making fish curry for my boyfriend and...   \n",
       "3                ann1  I began making fish curry for my boyfriend and...   \n",
       "4                ann1  I began making fish curry for my boyfriend and...   \n",
       "...               ...                                                ...   \n",
       "11605            ann0                                                NaN   \n",
       "11606            ann0         Marcus was collecting shells on the beach.   \n",
       "11607            ann0  Marcus was collecting shells on the beach.|He ...   \n",
       "11608            ann0  Marcus was collecting shells on the beach.|He ...   \n",
       "11609            ann0  Marcus was collecting shells on the beach.|He ...   \n",
       "\n",
       "                                                sentence affected  \\\n",
       "0      I began making fish curry for my boyfriend and I.      yes   \n",
       "1      I decided not to read a recipe since I've made...      yes   \n",
       "2                    I let the curry sit before tasting.      yes   \n",
       "3            When it was time to taste, I was disgusted.      yes   \n",
       "4      I accidentally used a whole garlic instead of ...      yes   \n",
       "...                                                  ...      ...   \n",
       "11605         Marcus was collecting shells on the beach.      yes   \n",
       "11606              He picked up a large beautiful shell.      yes   \n",
       "11607         He put it in his pocket to save for later.      yes   \n",
       "11608                    Suddenly he felt a sharp pinch.      yes   \n",
       "11609      A crab was inside the shell pinching his leg.      yes   \n",
       "\n",
       "                                                 emotion  \\\n",
       "0      {'joy': 1, 'excited': 1, 'content': 1, 'hungry...   \n",
       "1                         {'excited': 1, 'confident': 1}   \n",
       "2          {'anxious': 1, 'confident': 1, 'positive': 1}   \n",
       "3                                {'upset': 1, 'sick': 1}   \n",
       "4                       {'disgusted': 1, 'cretinous': 1}   \n",
       "...                                                  ...   \n",
       "11605   {'intrigued': 1, 'happy': 1, 'contemplative': 1}   \n",
       "11606             {'awestruck': 1, 'moved': 1, 'joy': 1}   \n",
       "11607     {'satisfied': 1, 'excited': 1, 'curiosity': 1}   \n",
       "11608           {'pained': 1, 'sore': 1, 'surprised': 1}   \n",
       "11609                     {'shocked': 1, 'surprised': 1}   \n",
       "\n",
       "                                                plutchik  \n",
       "0      {'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...  \n",
       "1      {'joy': 2, 'trust': 3, 'fear': 0, 'surprise': ...  \n",
       "2      {'joy': 1, 'trust': 1, 'fear': 0, 'surprise': ...  \n",
       "3      {'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...  \n",
       "4      {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...  \n",
       "...                                                  ...  \n",
       "11605  {'joy': 3, 'trust': 1, 'fear': 0, 'surprise': ...  \n",
       "11606  {'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...  \n",
       "11607  {'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...  \n",
       "11608  {'joy': 1, 'trust': 0, 'fear': 2, 'surprise': ...  \n",
       "11609  {'joy': 0, 'trust': 0, 'fear': 3, 'surprise': ...  \n",
       "\n",
       "[11610 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currentAnalyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50b0935c-e906-4381-9bf1-25d15830f7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emoton counting and analyzing -> Start checking, current dict size: 1917 "
     ]
    }
   ],
   "source": [
    "# Áúã‰∏Ä‰∏ãÂÜÖÂÆπÁä∂ÊÄÅ\n",
    "# count related\n",
    "# ÊØè‰∏™emotion x Âú®ÊÄªÂ≠óÂÖ∏X[x]‰∏≠ÂÖàËÆ∞ÂΩï‰∏ÄÊ¨°freqÔºå\n",
    "# ÁÑ∂ÂêéÂêåcase‰∏ãÁöÑÂÖ∂ÂÆÉÊÉÖÊÑüyi \\in {[y1, ..., yn], s.t. yi != x}ËÆ∞ÂΩï‰∏Ä‰∏ãfreqÂà∞Y[x][yi]\n",
    "emotionSum = {}\n",
    "for dataRow in currentAnalyze['emotion']:\n",
    "    print(\"\\r\", end=\"\")\n",
    "    print(\"Emoton counting and analyzing -> Start checking, current dict size: {} \".format(len(emotionSum)), end=\"\")\n",
    "    # for emotion in dataRow.values(): # use for show freq distribution\n",
    "    for emotion in dataRow.keys():\n",
    "        if emotion in emotionSum:\n",
    "            relatedEmotionDict = emotionSum.get(emotion)[1];\n",
    "            for relatedEmotion in dataRow:\n",
    "                if relatedEmotion != emotion:\n",
    "                    relatedEmotionDict[relatedEmotion] = relatedEmotionDict.get(relatedEmotion, 0) + 1\n",
    "            emotionSum[emotion] = [emotionSum.get(emotion)[0]+1, relatedEmotionDict];\n",
    "        else:\n",
    "            emotionSum[emotion] = [1, {}];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a04df663-ff71-4a2f-808c-a1a18491dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionDF = pd.DataFrame(list(zip(emotionSum.keys(),[x[0] for x in emotionSum.values()], \n",
    "                        [list(z[0] for z in sorted(y[1].items(), key=lambda x: x[1], reverse=True))[0:5] for y in emotionSum.values()],\n",
    "                        [sorted(y[1].items(), key=lambda x: x[1], reverse=True) for y in emotionSum.values()])), \n",
    "                         columns = ['emotion','freq','highly related', 'all related info']).sort_values(by=['freq'], na_position='first', ascending=False)\n",
    "\n",
    "emotionDF = emotionDF.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85753f1c-cf27-4410-a67b-8e6d4fa726ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1917, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>freq</th>\n",
       "      <th>highly related</th>\n",
       "      <th>all related info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happy</td>\n",
       "      <td>3216</td>\n",
       "      <td>[excited, proud, relieved, satisfied, surprised]</td>\n",
       "      <td>[(excited, 934), (proud, 410), (relieved, 300)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>excited</td>\n",
       "      <td>1855</td>\n",
       "      <td>[happy, proud, nervous, surprised, anticipation]</td>\n",
       "      <td>[(happy, 934), (proud, 197), (nervous, 150), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sad</td>\n",
       "      <td>1396</td>\n",
       "      <td>[disappointed, angry, upset, happy, frustrated]</td>\n",
       "      <td>[(disappointed, 280), (angry, 220), (upset, 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>proud</td>\n",
       "      <td>944</td>\n",
       "      <td>[happy, excited, accomplished, satisfied, surp...</td>\n",
       "      <td>[(happy, 410), (excited, 197), (accomplished, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angry</td>\n",
       "      <td>821</td>\n",
       "      <td>[sad, upset, annoyed, frustrated, disappointed]</td>\n",
       "      <td>[(sad, 220), (upset, 185), (annoyed, 162), (fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>promiscuous</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>pretense</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>manic</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>insulting</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>exhilarant</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1917 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          emotion  freq                                     highly related  \\\n",
       "0           happy  3216   [excited, proud, relieved, satisfied, surprised]   \n",
       "1         excited  1855   [happy, proud, nervous, surprised, anticipation]   \n",
       "2             sad  1396    [disappointed, angry, upset, happy, frustrated]   \n",
       "3           proud   944  [happy, excited, accomplished, satisfied, surp...   \n",
       "4           angry   821    [sad, upset, annoyed, frustrated, disappointed]   \n",
       "...           ...   ...                                                ...   \n",
       "1912  promiscuous     1                                                 []   \n",
       "1913     pretense     1                                                 []   \n",
       "1914        manic     1                                                 []   \n",
       "1915    insulting     1                                                 []   \n",
       "1916   exhilarant     1                                                 []   \n",
       "\n",
       "                                       all related info  \n",
       "0     [(excited, 934), (proud, 410), (relieved, 300)...  \n",
       "1     [(happy, 934), (proud, 197), (nervous, 150), (...  \n",
       "2     [(disappointed, 280), (angry, 220), (upset, 21...  \n",
       "3     [(happy, 410), (excited, 197), (accomplished, ...  \n",
       "4     [(sad, 220), (upset, 185), (annoyed, 162), (fr...  \n",
       "...                                                 ...  \n",
       "1912                                                 []  \n",
       "1913                                                 []  \n",
       "1914                                                 []  \n",
       "1915                                                 []  \n",
       "1916                                                 []  \n",
       "\n",
       "[1917 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(emotionDF.shape)\n",
    "emotionDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c5c231-0dbe-49a9-b948-505a1b7b0a59",
   "metadata": {},
   "source": [
    "# Graph weight calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73ff6ddb-6a5a-4083-bc4a-f1da5c31da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionRelevanceWeight = pd.DataFrame(columns = ['from', 'to', 'weight'])\n",
    "emotionFreq = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54af1f3c-be14-4f40-b056-46d690c1b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def findGraphWeight(indexRange):\n",
    "    # print(\"start: \", indexRange)\n",
    "    global emotionRelevanceWeight\n",
    "    for indexFrom in indexRange:\n",
    "        emotionFreq[emotionDF['emotion'][indexFrom]] = emotionDF['freq'][indexFrom]\n",
    "        for indexTo in range(indexFrom+1, emotionDF.index.stop):\n",
    "            clear_output(wait=True)\n",
    "            print(\"\\r\", end=\"\")\n",
    "            print(\"Graph weight calculation -> Start analyzing, current process: {}/{}. Total process: {}/{}...\".format(indexTo, emotionDF.index.stop - 1, \n",
    "                                                                                                                     indexFrom, indexRange.stop - 1), end=\"\")\n",
    "            weight = min(calculateRelavancyUsingWordNet(emotionDF['emotion'][indexFrom], emotionDF['emotion'][indexTo], 3), \n",
    "                         calculateRelavancyUsingWordNet(emotionDF['emotion'][indexTo], emotionDF['emotion'][indexFrom], 3))\n",
    "            \n",
    "            if (weight < sys.maxsize):\n",
    "                emotionRelevanceWeight = emotionRelevanceWeight.append(pd.DataFrame([[emotionDF['emotion'][indexFrom], emotionDF['emotion'][indexTo], weight]], \n",
    "                                                                                    columns = ['from', 'to', 'weight']), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acba4c2-c70c-4263-a9f0-ef68a644646e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph weight calculation -> Start analyzing, current process: 1590/1916. Total process: 1455/1916..."
     ]
    }
   ],
   "source": [
    "findGraphWeight(range(emotionDF.index.stop))\n",
    "# import _thread\n",
    "# multithreadIndex = 50\n",
    "# try:\n",
    "#     for i in range(0, emotionDF.index.stop-emotionDF.index.stop//multithreadIndex, emotionDF.index.stop//multithreadIndex):\n",
    "#         _thread.start_new_thread( findGraphWeight, (range(i, i+100), ))\n",
    "#         print(\"start: \", range(i, i+100), emotionDF.index.stop)\n",
    "#     _thread.start_new_thread( findGraphWeight, (range(emotionDF.index.stop-emotionDF.index.stop//multithreadIndex, emotionDF.index.stop+1), ))\n",
    "#     print(\"start: \", range(emotionDF.index.stop-emotionDF.index.stop//10, emotionDF.index.stop+1), emotionDF.index.stop)\n",
    "# except Exception as e: print(\"FAIL!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32e245c-a51d-447a-9097-dd8440fdee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "range1 = range(10, 123)\n",
    "range1.stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "041595fc-0192-4efa-beb0-bbb347e2d8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [from, to, weight]\n",
       "Index: []"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotionRelevanceWeight[emotionRelevanceWeight['from'] == 'happy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71d9faec-dd60-470e-8288-e933a3681a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>power</td>\n",
       "      <td>purpose</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>power</td>\n",
       "      <td>recognized</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>culpable</td>\n",
       "      <td>blameful</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ordinary</td>\n",
       "      <td>sensitive</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ordinary</td>\n",
       "      <td>mediocre</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>spirit</td>\n",
       "      <td>objective</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>spirit</td>\n",
       "      <td>fancy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>vague</td>\n",
       "      <td>promiscuous</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>try</td>\n",
       "      <td>fancy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>objective</td>\n",
       "      <td>packed</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          from           to weight\n",
       "0        power      purpose      3\n",
       "1        power   recognized      3\n",
       "2     culpable     blameful      1\n",
       "3     ordinary    sensitive      3\n",
       "4     ordinary     mediocre      2\n",
       "..         ...          ...    ...\n",
       "324     spirit    objective      3\n",
       "325     spirit        fancy      3\n",
       "326      vague  promiscuous      3\n",
       "327        try        fancy      3\n",
       "328  objective       packed      3\n",
       "\n",
       "[329 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotionRelevanceWeight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48eec2bc-3ad0-4a2d-aa19-7084acf08ab1",
   "metadata": {},
   "source": [
    "# Visualization of synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fbbb5827-5e13-413a-8ab7-027644cf2eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionRelevanceWeight = pd.read_csv('./emotionRelevanceWeight-v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "13ca3a94-c9a6-4a01-92f8-1c157abc90fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>node0</th>\n",
       "      <th>node1</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>happy</td>\n",
       "      <td>glad</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>happy</td>\n",
       "      <td>happier</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>excited</td>\n",
       "      <td>upset</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>excited</td>\n",
       "      <td>worried</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>excited</td>\n",
       "      <td>fear</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26821</th>\n",
       "      <td>26821</td>\n",
       "      <td>represented</td>\n",
       "      <td>try</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26822</th>\n",
       "      <td>26822</td>\n",
       "      <td>spirit</td>\n",
       "      <td>objective</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26823</th>\n",
       "      <td>26823</td>\n",
       "      <td>vague</td>\n",
       "      <td>promiscuous</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26824</th>\n",
       "      <td>26824</td>\n",
       "      <td>objective</td>\n",
       "      <td>packed</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26825</th>\n",
       "      <td>26825</td>\n",
       "      <td>easygoing</td>\n",
       "      <td>promiscuous</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26826 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index        node0        node1  weight\n",
       "0          0        happy         glad       2\n",
       "1          1        happy      happier       2\n",
       "2          2      excited        upset       4\n",
       "3          3      excited      worried       4\n",
       "4          4      excited         fear       4\n",
       "...      ...          ...          ...     ...\n",
       "26821  26821  represented          try       4\n",
       "26822  26822       spirit    objective       4\n",
       "26823  26823        vague  promiscuous       4\n",
       "26824  26824    objective       packed       4\n",
       "26825  26825    easygoing  promiscuous       3\n",
       "\n",
       "[26826 rows x 4 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotionRelevanceWeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c147cce-b0b1-4c16-bc55-4d2040547b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "G = nx.from_pandas_edgelist(emotionRelevanceWeight[0:100], 'node0', 'node1', edge_attr = 'weight')\n",
    "\n",
    "nx.draw_shell(G, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03a917e-97cc-43f6-be98-9dceafdabd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = emotionRelevanceWeight\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec10d79-6ac0-4afb-bfc9-3802f4eb7a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(G)\n",
    "nx.draw_networkx(G, pos, with_labels=True, font_weight='bold')\n",
    "labels = nx.get_edge_attributes(G, 'weight')\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f6fc68-02d1-461c-8447-89c60c333e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df = emotionRelevanceWeight\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "# 1. Create the graph\n",
    "g = nx.from_pandas_edgelist(df, source='node0', target='node1') \n",
    "\n",
    "# g.nodes()\n",
    "# [g.degree(node) for node in g.nodes() if node in df.node1]\n",
    "g.degree('happy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c584a0-9089-42f5-bab3-c6a2759ae79a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "storyCloze",
   "language": "python",
   "name": "storycloze"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
