{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8533643b-5b68-4dec-8a8a-49852c237e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global var set\n",
    "import transformers\n",
    "\n",
    "# model info, change as needed\n",
    "model_checkpoint = \"roberta-base\"\n",
    "batch_size = 16\n",
    "num_epochs = 16\n",
    "\n",
    "fileTag = \"clean-v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa38989-ff76-4de1-a82e-6853a1e61687",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Convert dataset to suitable format\n",
    "IMPORTANT: please never run this section again if you have your dataset ready!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a93a9f46-6703-4535-af96-8be1b5b3407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "trainDatasetOriginal = pd.read_csv(f'../../data/csv_version/dev/emotion/allcharlinepairs-{fileTag}.csv')\n",
    "testDatasetOriginal = pd.read_csv(f'../../data/csv_version/test/emotion/allcharlinepairs-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7265a797-adc2-49ed-b237-19abf9e0569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatasetProcessed = DataFrame({'emotion' : trainDatasetOriginal['emotion'],\n",
    "                                   'plutchik' : trainDatasetOriginal['plutchik'],\n",
    "                                  'selection0': pd.concat([trainDatasetOriginal['sentence'][:trainDatasetOriginal.shape[0]//3], trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//3:]]), \n",
    "                                  'selection1': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//3], \n",
    "                                                pd.concat([trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//3 : trainDatasetOriginal.shape[0]//3*2], \n",
    "                                                           trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//3*2:]])]), \n",
    "                                  'selection2': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//3*2], \n",
    "                                                           trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//3*2:]]),\n",
    "                                  'label': pd.Series(0 if x < trainDatasetOriginal.shape[0]//3 else (1 if x < trainDatasetOriginal.shape[0]//3*2 else 2) for x in trainDatasetOriginal.index)}).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "testDatasetProcessed = DataFrame({'emotion' : testDatasetOriginal['emotion'],\n",
    "                                   'plutchik' : testDatasetOriginal['plutchik'],\n",
    "                                  'selection0': pd.concat([testDatasetOriginal['sentence'][:testDatasetOriginal.shape[0]//3], testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//3:]]), \n",
    "                                  'selection1': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//3], \n",
    "                                                pd.concat([testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//3 : testDatasetOriginal.shape[0]//3*2], \n",
    "                                                testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//3*2:]])]), \n",
    "                                  'selection2': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//3*2], \n",
    "                                                           testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//3*2:]]),\n",
    "                                  'label': pd.Series(0 if x < testDatasetOriginal.shape[0]//3 else (1 if x < testDatasetOriginal.shape[0]//3*2 else 2) for x in testDatasetOriginal.index)}).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19e3c334-b371-44ad-b6e1-7161f405b741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>plutchik</th>\n",
       "      <th>selection0</th>\n",
       "      <th>selection1</th>\n",
       "      <th>selection2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['uncomfortable', 'warm']</td>\n",
       "      <td>{'joy': 1, 'trust': 0, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>Everyone cheered him on.</td>\n",
       "      <td>The room was not air conditioned and Dan was w...</td>\n",
       "      <td>Sheena had always wanted to be a boxer.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['fear', 'afraid', 'anger', 'sadness', 'depres...</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...</td>\n",
       "      <td>Jen was sitting in her living room.</td>\n",
       "      <td>It was killed by a car.</td>\n",
       "      <td>On the way to the cinema we got into a car acc...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['embarrassed', 'clumsy', 'unprepared']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>Billy started posting list articles with broad...</td>\n",
       "      <td>They informed me that I had to leave.</td>\n",
       "      <td>I didn't keep my grip on one.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['studious', 'prepared', 'nervous']</td>\n",
       "      <td>{'joy': 1, 'trust': 1, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>William went to his school to pick up his clas...</td>\n",
       "      <td>They set up their kayaks and climbed in to beg...</td>\n",
       "      <td>Kate and her friends were at a restaurant.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['urgent', 'anxious', 'scared']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...</td>\n",
       "      <td>Dave wanted to bake a cake.</td>\n",
       "      <td>She met a man that lived in Europe.</td>\n",
       "      <td>He raced around the house trying to find it.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11605</th>\n",
       "      <td>['sad', 'afraid']</td>\n",
       "      <td>{'joy': 0, 'trust': 1, 'fear': 3, 'surprise': ...</td>\n",
       "      <td>He tracked himself doing this for two months.</td>\n",
       "      <td>A huge jackrabbit was caught, struggling to ge...</td>\n",
       "      <td>She was afraid she would have to feed the big ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11606</th>\n",
       "      <td>['happy', 'love', 'excited']</td>\n",
       "      <td>{'joy': 3, 'trust': 2, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>She looked from rack to rack searching.</td>\n",
       "      <td>The Smiths were out on a date night.</td>\n",
       "      <td>He got to take home the bowling pin trophy.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11607</th>\n",
       "      <td>['confused', 'disappointed', 'sad', 'angry']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>She went to Costco and returned all of her boo...</td>\n",
       "      <td>When he got to the doctor, he barely felt the ...</td>\n",
       "      <td>Sarah still can't understand why no one praise...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11608</th>\n",
       "      <td>['embarrassed', 'pain', 'injured', 'shocked', ...</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...</td>\n",
       "      <td>I played speed chess on the internet this morn...</td>\n",
       "      <td>The bartender knew this look very well.</td>\n",
       "      <td>When I went to do another one, I hurt my ankle.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11609</th>\n",
       "      <td>['shocked', 'scared', 'concerned', 'horrified'...</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...</td>\n",
       "      <td>He opened the window and London street noise w...</td>\n",
       "      <td>Then out of nowhere a snake struck at him!</td>\n",
       "      <td>Kate was grounded for a week as a result.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11610 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 emotion  \\\n",
       "0                              ['uncomfortable', 'warm']   \n",
       "1      ['fear', 'afraid', 'anger', 'sadness', 'depres...   \n",
       "2                ['embarrassed', 'clumsy', 'unprepared']   \n",
       "3                    ['studious', 'prepared', 'nervous']   \n",
       "4                        ['urgent', 'anxious', 'scared']   \n",
       "...                                                  ...   \n",
       "11605                                  ['sad', 'afraid']   \n",
       "11606                       ['happy', 'love', 'excited']   \n",
       "11607       ['confused', 'disappointed', 'sad', 'angry']   \n",
       "11608  ['embarrassed', 'pain', 'injured', 'shocked', ...   \n",
       "11609  ['shocked', 'scared', 'concerned', 'horrified'...   \n",
       "\n",
       "                                                plutchik  \\\n",
       "0      {'joy': 1, 'trust': 0, 'fear': 1, 'surprise': ...   \n",
       "1      {'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...   \n",
       "2      {'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...   \n",
       "3      {'joy': 1, 'trust': 1, 'fear': 1, 'surprise': ...   \n",
       "4      {'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...   \n",
       "...                                                  ...   \n",
       "11605  {'joy': 0, 'trust': 1, 'fear': 3, 'surprise': ...   \n",
       "11606  {'joy': 3, 'trust': 2, 'fear': 0, 'surprise': ...   \n",
       "11607  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "11608  {'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...   \n",
       "11609  {'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...   \n",
       "\n",
       "                                              selection0  \\\n",
       "0                               Everyone cheered him on.   \n",
       "1                    Jen was sitting in her living room.   \n",
       "2      Billy started posting list articles with broad...   \n",
       "3      William went to his school to pick up his clas...   \n",
       "4                            Dave wanted to bake a cake.   \n",
       "...                                                  ...   \n",
       "11605      He tracked himself doing this for two months.   \n",
       "11606            She looked from rack to rack searching.   \n",
       "11607  She went to Costco and returned all of her boo...   \n",
       "11608  I played speed chess on the internet this morn...   \n",
       "11609  He opened the window and London street noise w...   \n",
       "\n",
       "                                              selection1  \\\n",
       "0      The room was not air conditioned and Dan was w...   \n",
       "1                                It was killed by a car.   \n",
       "2                  They informed me that I had to leave.   \n",
       "3      They set up their kayaks and climbed in to beg...   \n",
       "4                    She met a man that lived in Europe.   \n",
       "...                                                  ...   \n",
       "11605  A huge jackrabbit was caught, struggling to ge...   \n",
       "11606               The Smiths were out on a date night.   \n",
       "11607  When he got to the doctor, he barely felt the ...   \n",
       "11608            The bartender knew this look very well.   \n",
       "11609         Then out of nowhere a snake struck at him!   \n",
       "\n",
       "                                              selection2  label  \n",
       "0                Sheena had always wanted to be a boxer.      1  \n",
       "1      On the way to the cinema we got into a car acc...      2  \n",
       "2                          I didn't keep my grip on one.      2  \n",
       "3             Kate and her friends were at a restaurant.      0  \n",
       "4           He raced around the house trying to find it.      2  \n",
       "...                                                  ...    ...  \n",
       "11605  She was afraid she would have to feed the big ...      2  \n",
       "11606        He got to take home the bowling pin trophy.      1  \n",
       "11607  Sarah still can't understand why no one praise...      2  \n",
       "11608    When I went to do another one, I hurt my ankle.      2  \n",
       "11609          Kate was grounded for a week as a result.      1  \n",
       "\n",
       "[11610 rows x 6 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDatasetProcessed.to_csv(f'./dataset/3Select-{fileTag}-train.csv')\n",
    "trainDatasetProcessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b770299d-567d-46e2-b928-8ee31a341c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>plutchik</th>\n",
       "      <th>selection0</th>\n",
       "      <th>selection1</th>\n",
       "      <th>selection2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['satisfied', 'excited', 'eager']</td>\n",
       "      <td>{'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Finally she was able to get the phone she wanted.</td>\n",
       "      <td>His roommate was a teammate from the high scho...</td>\n",
       "      <td>AJ broke his glasses.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['relieved', 'happy', 'cured']</td>\n",
       "      <td>{'joy': 3, 'trust': 2, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>He heads down to the track.</td>\n",
       "      <td>But Christina, who was white, made friends wit...</td>\n",
       "      <td>He actually enjoyed his flight.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['hopeful', 'sad', 'disappointed', 'competitive']</td>\n",
       "      <td>{'joy': 1, 'trust': 1, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>She tried her best to get better.</td>\n",
       "      <td>I was so disappointed.</td>\n",
       "      <td>Hannah went shopping.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['embarrassed', 'sad', 'failure']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>He gained a lot of weight.</td>\n",
       "      <td>His father told him if he was good, he would b...</td>\n",
       "      <td>Bruce married a woman named Kim.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['uncomfortable', 'mad', 'upset']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>I was still unable to find comfort and style.</td>\n",
       "      <td>Afterwards, I decided to go home and take the ...</td>\n",
       "      <td>It was her first visit.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11124</th>\n",
       "      <td>['relief', 'relieved']</td>\n",
       "      <td>{'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Inside was a dead body.</td>\n",
       "      <td>Emily didn't have any problems.</td>\n",
       "      <td>She said it was the best thing she'd ever tasted.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11125</th>\n",
       "      <td>['anxious', 'scared', 'apprehensive']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...</td>\n",
       "      <td>Kia had just packed herself a plate and a fork!</td>\n",
       "      <td>He stopped eating ice cream and got a girlfriend.</td>\n",
       "      <td>The approaching storm was a big one, and Max w...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11126</th>\n",
       "      <td>['confused', 'guilty', 'concern', 'calm']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>George sat on his bed and it collapsed to the ...</td>\n",
       "      <td>The officers said they were taking him home to...</td>\n",
       "      <td>But then she tried it.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11127</th>\n",
       "      <td>['excited', 'rebellious', 'bold']</td>\n",
       "      <td>{'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>He told her that it's impossible since there's...</td>\n",
       "      <td>Eventually she made friends and got better at ...</td>\n",
       "      <td>Sam and his friends decided to throw a hotel p...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>['sad', 'annoyed', 'disappointed']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>She ate about 20 of them one day.</td>\n",
       "      <td>Tom was a professional golfer.</td>\n",
       "      <td>Jane was upset a co-worker had let her down.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11129 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 emotion  \\\n",
       "0                      ['satisfied', 'excited', 'eager']   \n",
       "1                         ['relieved', 'happy', 'cured']   \n",
       "2      ['hopeful', 'sad', 'disappointed', 'competitive']   \n",
       "3                      ['embarrassed', 'sad', 'failure']   \n",
       "4                      ['uncomfortable', 'mad', 'upset']   \n",
       "...                                                  ...   \n",
       "11124                             ['relief', 'relieved']   \n",
       "11125              ['anxious', 'scared', 'apprehensive']   \n",
       "11126          ['confused', 'guilty', 'concern', 'calm']   \n",
       "11127                  ['excited', 'rebellious', 'bold']   \n",
       "11128                 ['sad', 'annoyed', 'disappointed']   \n",
       "\n",
       "                                                plutchik  \\\n",
       "0      {'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...   \n",
       "1      {'joy': 3, 'trust': 2, 'fear': 0, 'surprise': ...   \n",
       "2      {'joy': 1, 'trust': 1, 'fear': 1, 'surprise': ...   \n",
       "3      {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "4      {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "...                                                  ...   \n",
       "11124  {'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...   \n",
       "11125  {'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...   \n",
       "11126  {'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...   \n",
       "11127  {'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...   \n",
       "11128  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "\n",
       "                                              selection0  \\\n",
       "0      Finally she was able to get the phone she wanted.   \n",
       "1                            He heads down to the track.   \n",
       "2                      She tried her best to get better.   \n",
       "3                             He gained a lot of weight.   \n",
       "4          I was still unable to find comfort and style.   \n",
       "...                                                  ...   \n",
       "11124                            Inside was a dead body.   \n",
       "11125    Kia had just packed herself a plate and a fork!   \n",
       "11126  George sat on his bed and it collapsed to the ...   \n",
       "11127  He told her that it's impossible since there's...   \n",
       "11128                  She ate about 20 of them one day.   \n",
       "\n",
       "                                              selection1  \\\n",
       "0      His roommate was a teammate from the high scho...   \n",
       "1      But Christina, who was white, made friends wit...   \n",
       "2                                 I was so disappointed.   \n",
       "3      His father told him if he was good, he would b...   \n",
       "4      Afterwards, I decided to go home and take the ...   \n",
       "...                                                  ...   \n",
       "11124                    Emily didn't have any problems.   \n",
       "11125  He stopped eating ice cream and got a girlfriend.   \n",
       "11126  The officers said they were taking him home to...   \n",
       "11127  Eventually she made friends and got better at ...   \n",
       "11128                     Tom was a professional golfer.   \n",
       "\n",
       "                                              selection2  label  \n",
       "0                                  AJ broke his glasses.      0  \n",
       "1                        He actually enjoyed his flight.      2  \n",
       "2                                  Hannah went shopping.      0  \n",
       "3                       Bruce married a woman named Kim.      0  \n",
       "4                                It was her first visit.      0  \n",
       "...                                                  ...    ...  \n",
       "11124  She said it was the best thing she'd ever tasted.      1  \n",
       "11125  The approaching storm was a big one, and Max w...      2  \n",
       "11126                             But then she tried it.      1  \n",
       "11127  Sam and his friends decided to throw a hotel p...      2  \n",
       "11128       Jane was upset a co-worker had let her down.      2  \n",
       "\n",
       "[11129 rows x 6 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDatasetProcessed.to_csv(f'./dataset/3Select-{fileTag}-test.csv')\n",
    "testDatasetProcessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7283c1-d83e-4369-b5e4-6c2e09d654ac",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "828a5092-83e6-4580-99c9-bd9ec434708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "05151e3b-0bec-44f4-bf0a-ac58cddbf838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-6e66e58605373597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:\\Users\\JAM_0\\.cache\\huggingface\\datasets\\csv\\default-6e66e58605373597\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2563a6443b1b487398e9bc9ff633f1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21aedc7099904df4bec172145a8cd328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:\\Users\\JAM_0\\.cache\\huggingface\\datasets\\csv\\default-6e66e58605373597\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbfa8a3e9bc64914902bdefa80c8177d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('csv', data_files={'train': f'./dataset/3Select-{fileTag}-train.csv', \n",
    "                                           'test': f'./dataset/3Select-{fileTag}-test.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d776c270-7752-4445-ba6c-eb078f71eccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'emotion', 'plutchik', 'selection0', 'selection1', 'selection2', 'label'],\n",
       "        num_rows: 11610\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'emotion', 'plutchik', 'selection0', 'selection1', 'selection2', 'label'],\n",
       "        num_rows: 11129\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a1c79159-f795-4d02-b052-94f04286d53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 0,\n",
       " 'emotion': \"['satisfied', 'excited', 'eager']\",\n",
       " 'plutchik': \"{'joy': 2, 'trust': 1, 'fear': 0, 'surprise': 1, 'sadness': 0, 'disgust': 0, 'anger': 0, 'anticipation': 2}\",\n",
       " 'selection0': 'Finally she was able to get the phone she wanted.',\n",
       " 'selection1': 'His roommate was a teammate from the high school track team.',\n",
       " 'selection2': 'AJ broke his glasses.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1f6ad67d-b4cb-4f65-a9cb-d2d665deec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_one(example):\n",
    "    print(f\"Context: {example['plutchik']}\")\n",
    "    print(f\"  A - {example['selection0']}\")\n",
    "    print(f\"  B - {example['selection1']}\")\n",
    "    print(f\"  C - {example['selection2']}\")\n",
    "    print(f\"\\nGround truth: option {['A', 'B', 'C'][example['label']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "15cd7cfb-748a-4fe7-8152-7debf6a65ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: {'joy': 1, 'trust': 0, 'fear': 1, 'surprise': 1, 'sadness': 1, 'disgust': 1, 'anger': 1, 'anticipation': 1}\n",
      "  A - Everyone cheered him on.\n",
      "  B - The room was not air conditioned and Dan was warm.\n",
      "  C - Sheena had always wanted to be a boxer.\n",
      "\n",
      "Ground truth: option B\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da93346-1037-41ed-b67d-91877fa8c0ec",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3da78c12-9aff-4beb-a006-e287bbf61023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "caffe397-a65d-478f-b966-7b910fb2edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "selectionList = [\"selection0\", \"selection1\", \"selection2\"]\n",
    "weightRemap = [\"NOT \", \"LITTLE \", \"\", \"VERY \", \"ABSOLUTELY \"]\n",
    "def preprocess_function(examples):\n",
    "    # Repeat each first sentence four times to go with the four possibilities of second sentences.\n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(context.strip(\"[\").strip(\"]\").replace('\\'', '')) ]*2 for context in examples[\"emotion\"] ]\n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(context.strip(\"[\").strip(\"]\").replace('\\\"', '')) ]*2 for context in examples[\"plutchik\"] ]\n",
    "    first_sentences = [[\"The following sentences contain emotions: {}\".format(\", \".join([weightRemap[int(eachCaseWeight.replace(\"]\", \"\").replace(\"[\", \"\").replace(\"}\", \"\").replace(\"{\", \"\").replace(\"\\\"\", \"\").replace(\"\\'\", \"\"))] \n",
    "                                                        + eachCaseEmotionType.replace(\"]\", \"\").replace(\"[\", \"\").replace(\"}\", \"\").replace(\"{\", \"\").replace(\"\\\"\", \"\").replace(\"\\'\", \"\").strip()\n",
    "                        for eachCaseWeight, eachCaseEmotionType in \n",
    "                        zip([re.split(':|,',eachEmotionCombination)[1::2] for eachEmotionCombination in examples[\"plutchik\"]][eventIndex], \n",
    "                           [re.split(':|,',eachEmotionCombination)[::2] for eachEmotionCombination in examples[\"plutchik\"]][eventIndex])]))]*3 for eventIndex in \n",
    "                           range(len([re.split(':|,',eachEmotionCombination)[1::2] for eachEmotionCombination in examples[\"plutchik\"]]))]\n",
    "    \n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(', '.join([(weightRemap[eachEmotion[1]] + \" \" +eachEmotion[0]).strip() \n",
    "    #                    for eachEmotion in ast.literal_eval(context).items()]))]*2 \n",
    "    #                    for context in examples[\"plutchik\"]]\n",
    "    # Grab all second sentences possible for each context.\n",
    "    second_sentences = [[examples[selection][index] for selection in selectionList]for index in range(len(examples['selection0']))]\n",
    "\n",
    "    # Flatten everything\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "    \n",
    "    # Tokenize\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "    # Un-flatten\n",
    "    # print(tokenized_examples.items())\n",
    "    return {k: [v[i:i+3] for i in range(0, len(v), 3)] for k, v in tokenized_examples.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0afb4841-ab69-4b91-8859-fd249badb923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 3 [52, 58, 57]\n"
     ]
    }
   ],
   "source": [
    "examples = dataset[\"train\"][:5]\n",
    "features = preprocess_function(examples)\n",
    "print(len(features[\"input_ids\"]), len(features[\"input_ids\"][0]), [len(x) for x in features[\"input_ids\"][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "903e2891-0e3d-4e87-b98a-727eaf36417a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>The following sentences contain emotions: LITTLE joy, NOT trust, LITTLE fear, LITTLE surprise, LITTLE sadness, LITTLE disgust, LITTLE anger, LITTLE anticipation</s></s>Everyone cheered him on.</s>',\n",
       " '<s>The following sentences contain emotions: LITTLE joy, NOT trust, LITTLE fear, LITTLE surprise, LITTLE sadness, LITTLE disgust, LITTLE anger, LITTLE anticipation</s></s>The room was not air conditioned and Dan was warm.</s>',\n",
       " '<s>The following sentences contain emotions: LITTLE joy, NOT trust, LITTLE fear, LITTLE surprise, LITTLE sadness, LITTLE disgust, LITTLE anger, LITTLE anticipation</s></s>Sheena had always wanted to be a boxer.</s>',\n",
       " '<s>The following sentences contain emotions: NOT joy, NOT trust, fear, surprise, LITTLE sadness, NOT disgust, NOT anger, LITTLE anticipation</s></s>Jen was sitting in her living room.</s>',\n",
       " '<s>The following sentences contain emotions: NOT joy, NOT trust, fear, surprise, LITTLE sadness, NOT disgust, NOT anger, LITTLE anticipation</s></s>It was killed by a car.</s>',\n",
       " '<s>The following sentences contain emotions: NOT joy, NOT trust, fear, surprise, LITTLE sadness, NOT disgust, NOT anger, LITTLE anticipation</s></s>On the way to the cinema we got into a car accident.</s>',\n",
       " '<s>The following sentences contain emotions: NOT joy, NOT trust, LITTLE fear, NOT surprise, LITTLE sadness, LITTLE disgust, LITTLE anger, NOT anticipation</s></s>Billy started posting list articles with broad appeal.</s>',\n",
       " '<s>The following sentences contain emotions: NOT joy, NOT trust, LITTLE fear, NOT surprise, LITTLE sadness, LITTLE disgust, LITTLE anger, NOT anticipation</s></s>They informed me that I had to leave.</s>',\n",
       " \"<s>The following sentences contain emotions: NOT joy, NOT trust, LITTLE fear, NOT surprise, LITTLE sadness, LITTLE disgust, LITTLE anger, NOT anticipation</s></s>I didn't keep my grip on one.</s>\",\n",
       " '<s>The following sentences contain emotions: LITTLE joy, LITTLE trust, LITTLE fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, LITTLE anticipation</s></s>William went to his school to pick up his class schedule.</s>',\n",
       " '<s>The following sentences contain emotions: LITTLE joy, LITTLE trust, LITTLE fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, LITTLE anticipation</s></s>They set up their kayaks and climbed in to begin their trek.</s>',\n",
       " '<s>The following sentences contain emotions: LITTLE joy, LITTLE trust, LITTLE fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, LITTLE anticipation</s></s>Kate and her friends were at a restaurant.</s>',\n",
       " '<s>The following sentences contain emotions: NOT joy, NOT trust, fear, NOT surprise, sadness, NOT disgust, NOT anger, anticipation</s></s>Dave wanted to bake a cake.</s>',\n",
       " '<s>The following sentences contain emotions: NOT joy, NOT trust, fear, NOT surprise, sadness, NOT disgust, NOT anger, anticipation</s></s>She met a man that lived in Europe.</s>',\n",
       " '<s>The following sentences contain emotions: NOT joy, NOT trust, fear, NOT surprise, sadness, NOT disgust, NOT anger, anticipation</s></s>He raced around the house trying to find it.</s>']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(features[\"input_ids\"][a][i]) for a in range(5) for i in range(3) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4a286ba6-cb84-4619-b842-780124d26a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc3e18cafdc477a9a94e0a7f8c967d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c419160c069d4db08e264a3d07cfbd1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7706d875-3a89-4e52-9f08-c77256b621ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForMultipleChoice: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForMultipleChoice.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2cd7be65-ebd8-43db-bcbf-a87d7e2342e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-emotionCommonsense\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=5e-6, # for bert-base\n",
    "    # learning_rate=1e-3,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2737e04e-19c2-407d-8ce1-06b675f208c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [[{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        # Un-flatten\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        # Add back labels\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03a0ec05-de5e-434f-b07c-63212e7c7f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_keys = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "features = [{k: v for k, v in encoded_datasets[\"train\"][i].items() if k in accepted_keys} for i in range(10)]\n",
    "batch = DataCollatorForMultipleChoice(tokenizer)(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45f7f26c-04bb-42ae-8627-897ced69888e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>The following sentences contain emotions: anticipation</s></s>George sprained his ankle going down the stairs.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<s>The following sentences contain emotions: anticipation</s></s>He made a flyer asking for a strong helper.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<s>The following sentences contain emotions: anticipation</s></s>He hopped off the boat into the crystal clear water.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(batch[\"input_ids\"][8][i].tolist()) for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4b55256-30fa-4e30-a3a4-66fe1114b941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [\"anticipation:2\"]\n",
      "  A - George sprained his ankle going down the stairs.\n",
      "  B - He made a flyer asking for a strong helper.\n",
      "  C - He hopped off the boat into the crystal clear water.\n",
      "\n",
      "Ground truth: option B\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8305d3-8dc9-4d0f-8628-f51dc356c2d2",
   "metadata": {},
   "source": [
    "# Trainer Defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b707863a-bc16-43b0-b633-c7ffb4fa72e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "valStored = []\n",
    "def compute_metrics(eval_predictions):\n",
    "    predictions, label_ids = eval_predictions\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    valStored.append((preds != label_ids).astype(np.float32));\n",
    "    return {\"accuracy\": (preds == label_ids).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b115c1ba-323a-47d5-bb9d-55de985f13b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_datasets[\"train\"],\n",
    "    eval_dataset=encoded_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a5e3430-bbd6-484d-8a8d-9cbcdba37d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "C:\\Python\\miniconda3\\envs\\pytorchEnvWithDataSci\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 53234\n",
      "  Num Epochs = 16\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53248\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53248' max='53248' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53248/53248 2:26:59, Epoch 16/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.693800</td>\n",
       "      <td>0.693128</td>\n",
       "      <td>0.504018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.614600</td>\n",
       "      <td>0.594435</td>\n",
       "      <td>0.656838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.564700</td>\n",
       "      <td>0.571774</td>\n",
       "      <td>0.684685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.526300</td>\n",
       "      <td>0.572104</td>\n",
       "      <td>0.695053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.499500</td>\n",
       "      <td>0.586160</td>\n",
       "      <td>0.701162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.472300</td>\n",
       "      <td>0.586649</td>\n",
       "      <td>0.705170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.620333</td>\n",
       "      <td>0.704207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.444200</td>\n",
       "      <td>0.623844</td>\n",
       "      <td>0.704265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.415700</td>\n",
       "      <td>0.655308</td>\n",
       "      <td>0.705055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.394100</td>\n",
       "      <td>0.685141</td>\n",
       "      <td>0.703860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.375700</td>\n",
       "      <td>0.723962</td>\n",
       "      <td>0.702183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.371000</td>\n",
       "      <td>0.727208</td>\n",
       "      <td>0.702646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.339400</td>\n",
       "      <td>0.768802</td>\n",
       "      <td>0.702723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.327800</td>\n",
       "      <td>0.798015</td>\n",
       "      <td>0.701258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.320600</td>\n",
       "      <td>0.806652</td>\n",
       "      <td>0.700892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.310600</td>\n",
       "      <td>0.814122</td>\n",
       "      <td>0.700565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-53000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-53000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-53000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-53000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-53000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=53248, training_loss=0.4483006133769567, metrics={'train_runtime': 8821.4262, 'train_samples_per_second': 96.554, 'train_steps_per_second': 6.036, 'total_flos': 5.267817952412011e+16, 'train_loss': 0.4483006133769567, 'epoch': 16.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a17948-a8f7-4450-b2b0-8a7016e91391",
   "metadata": {},
   "source": [
    "出现validation loss 上升情况大多是训练集验证集数据分布不一致，或者训练集过小，未包含验证集中所有情况，\n",
    "也就是过拟合导致的。而解决这种现象可以尝试以下几种策略：\n",
    "1. 增加训练样本增加正则项系数权重，\n",
    "2. 减小过拟合加入早停机制，ValLoss上升几个epoch直接停止\n",
    "3. 采用Focal Loss\n",
    "4. 加入Label Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d6ab3-33ac-4e8e-99ee-3c3f17d71642",
   "metadata": {},
   "source": [
    "# Store Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c30271fe-7ce9-43e8-9e87-de8d6ae2c2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x23113595460>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "Z = np.transpose(valStored)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.pcolormesh(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e77d30e-e51a-45a6-9130-83a17c4d2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataLog = pd.DataFrame(trainer.state.log_history)\n",
    "dataLog.to_csv(f'./trainingMetric/[plutchik]trainingInfo-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c90cfec4-96ec-46c8-a99f-3c78b989b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluationIterationResult = pd.DataFrame(np.transpose(valStored))\n",
    "evaluationIterationResult.to_csv(f'./trainingMetric/[plutchik]evaluationSpecificInfo-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd7f330-1477-4119-a9dc-1ebb7acb7665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchEnvWithDataSci",
   "language": "python",
   "name": "pytorchenvwithdatasci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
