{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8533643b-5b68-4dec-8a8a-49852c237e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global var set\n",
    "import transformers\n",
    "\n",
    "# model info, change as needed\n",
    "model_checkpoint = \"roberta-base\"\n",
    "batch_size = 16\n",
    "num_epochs = 16\n",
    "\n",
    "fileTag = \"clean-v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa38989-ff76-4de1-a82e-6853a1e61687",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Convert dataset to suitable format\n",
    "IMPORTANT: please never run this section again if you have your dataset ready!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a93a9f46-6703-4535-af96-8be1b5b3407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "trainDatasetOriginal = pd.read_csv(f'../../data/csv_version/dev/emotion/allcharlinepairs-{fileTag}.csv')\n",
    "testDatasetOriginal = pd.read_csv(f'../../data/csv_version/test/emotion/allcharlinepairs-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7265a797-adc2-49ed-b237-19abf9e0569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatasetProcessed = DataFrame({'emotion' : trainDatasetOriginal['emotion'],\n",
    "                                   'plutchik' : trainDatasetOriginal['plutchik'],\n",
    "                                  'selection0': pd.concat([trainDatasetOriginal['sentence'][:trainDatasetOriginal.shape[0]//5], trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//5:]]), \n",
    "                                  'selection1': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//5], \n",
    "                                                pd.concat([trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//5:trainDatasetOriginal.shape[0]//5*2], \n",
    "                                                trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//5*2:]])]), \n",
    "                                  'selection2': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//5*2], \n",
    "                                                pd.concat([trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//5*2:trainDatasetOriginal.shape[0]//5*3], \n",
    "                                                trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//5*3:]])]), \n",
    "                                  'selection3': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//5*3], \n",
    "                                                pd.concat([trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//5*3:trainDatasetOriginal.shape[0]//5*4], \n",
    "                                                trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//5*4:]])]),\n",
    "                                  'selection4': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//5*4], \n",
    "                                                           trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//5*4:]]),\n",
    "                                  'label': pd.Series(0 if x < trainDatasetOriginal.shape[0]//5 else (1 if x < trainDatasetOriginal.shape[0]//5*2 \n",
    "                                                                                               else (2 if x < trainDatasetOriginal.shape[0]//5*3 \n",
    "                                                                                               else (3 if x < trainDatasetOriginal.shape[0]//5*4\n",
    "                                                                                               else  4))) for x in trainDatasetOriginal.index)}).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "testDatasetProcessed = DataFrame({'emotion' : testDatasetOriginal['emotion'],\n",
    "                                   'plutchik' : testDatasetOriginal['plutchik'],\n",
    "                                  'selection0': pd.concat([testDatasetOriginal['sentence'][:testDatasetOriginal.shape[0]//5], testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//5:]]), \n",
    "                                  'selection1': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//5], \n",
    "                                                pd.concat([testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//5:testDatasetOriginal.shape[0]//5*2], \n",
    "                                                testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//5*2:]])]), \n",
    "                                  'selection2': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//5*2], \n",
    "                                                pd.concat([testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//5*2:testDatasetOriginal.shape[0]//5*3], \n",
    "                                                testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//5*3:]])]), \n",
    "                                  'selection3': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//5*3], \n",
    "                                                pd.concat([testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//5*3:testDatasetOriginal.shape[0]//5*4], \n",
    "                                                testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//5*4:]])]),\n",
    "                                  'selection4': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//5*4], \n",
    "                                                           testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//5*4:]]),\n",
    "                                  'label': pd.Series(0 if x < testDatasetOriginal.shape[0]//5 else (1 if x < testDatasetOriginal.shape[0]//5*2 \n",
    "                                                                                               else (2 if x < testDatasetOriginal.shape[0]//5*3 \n",
    "                                                                                               else (3 if x < testDatasetOriginal.shape[0]//5*4\n",
    "                                                                                               else  4))) for x in testDatasetOriginal.index)}).sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19e3c334-b371-44ad-b6e1-7161f405b741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>plutchik</th>\n",
       "      <th>selection0</th>\n",
       "      <th>selection1</th>\n",
       "      <th>selection2</th>\n",
       "      <th>selection3</th>\n",
       "      <th>selection4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['curious', 'welcoming', 'happy', 'lucky', 'tr...</td>\n",
       "      <td>{'joy': 2, 'trust': 3, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>James rushed to finish his PowerPoint.</td>\n",
       "      <td>Breanna wants to lose some weight.</td>\n",
       "      <td>George was walking past a row of parked bikes.</td>\n",
       "      <td>He had to move away.</td>\n",
       "      <td>Once he got there the beekeeper asked if Mark ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['frightened', 'apprehensive', 'nervous']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...</td>\n",
       "      <td>She always gossiped about other people and sai...</td>\n",
       "      <td>My boyfriend took me to Amsterdam one year.</td>\n",
       "      <td>Dale is at his favorite bar having drinks</td>\n",
       "      <td>The trail took them through dark woods.</td>\n",
       "      <td>He decided to get it done at a charity instead...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['fulfilled', 'tired', 'happy']</td>\n",
       "      <td>{'joy': 1, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>The farmer woke up early everyday.</td>\n",
       "      <td>She had everyone dressed including herself.</td>\n",
       "      <td>He did this until he was 80 years old.</td>\n",
       "      <td>She decided to throw a big party.</td>\n",
       "      <td>Beth was angry that Sam didn't clean up after ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['anticipation', 'hungry', 'happy']</td>\n",
       "      <td>{'joy': 3, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>She would tell everyone that Alice lived in ca...</td>\n",
       "      <td>He can't because of his contract.</td>\n",
       "      <td>He looked inside and saw the Home Ec class had...</td>\n",
       "      <td>He found many of them and hung them on his shi...</td>\n",
       "      <td>I was so angry that I told her never to call m...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['sentimental', 'intrigued', 'reflective']</td>\n",
       "      <td>{'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Ronald had a bag that meant a lot to him.</td>\n",
       "      <td>Henry was walking while holding Stacy.</td>\n",
       "      <td>Judy went to her grandmother's on Saturday mor...</td>\n",
       "      <td>Jack and Diane tried to follow it but they wer...</td>\n",
       "      <td>She was annoying him all night long.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11605</th>\n",
       "      <td>['devious', 'happy', 'relaxed', 'grateful', 'c...</td>\n",
       "      <td>{'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Corry moved into a new apartment.</td>\n",
       "      <td>Andy smelled the milk and noticed it was spoiled.</td>\n",
       "      <td>Michael was having a daughter.</td>\n",
       "      <td>She paid for her drink and started sipping it.</td>\n",
       "      <td>He let her pick the music.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11606</th>\n",
       "      <td>['anticipation', 'centered']</td>\n",
       "      <td>{'joy': 2, 'trust': 2, 'fear': 2, 'surprise': ...</td>\n",
       "      <td>When I went to do another one, I hurt my ankle.</td>\n",
       "      <td>Sue decided to delete the story and try again.</td>\n",
       "      <td>Then a thaw came overnight!</td>\n",
       "      <td>The first night I tried it I slept like a baby!</td>\n",
       "      <td>He pulled the strings of his backpack and rele...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11607</th>\n",
       "      <td>['sad', 'uncomfortable']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...</td>\n",
       "      <td>All his roommates loved the smell.</td>\n",
       "      <td>Alice really needed to go to the bathroom.</td>\n",
       "      <td>They served all their guests delicious food in...</td>\n",
       "      <td>But he didn't become as good as he wanted to.</td>\n",
       "      <td>I decided to call in a professional to finish ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11608</th>\n",
       "      <td>['valued', 'happy', 'satisfied', 'helpful', 'c...</td>\n",
       "      <td>{'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Together they spent three hours in the garden ...</td>\n",
       "      <td>Judy was in a baking contest.</td>\n",
       "      <td>He needed his own money for things like gas an...</td>\n",
       "      <td>He saw the wet spot on the floor.</td>\n",
       "      <td>The kids were hungry after school.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11609</th>\n",
       "      <td>['shocked', 'stressed', 'alarmed', 'startled']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...</td>\n",
       "      <td>The phone rang two hours later, jolting him ou...</td>\n",
       "      <td>A woman who was afraid of snakes saw one outsi...</td>\n",
       "      <td>His computer froze up.</td>\n",
       "      <td>Jamie quit her job after that.</td>\n",
       "      <td>They tried for many years to conceive.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11610 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 emotion  \\\n",
       "0      ['curious', 'welcoming', 'happy', 'lucky', 'tr...   \n",
       "1              ['frightened', 'apprehensive', 'nervous']   \n",
       "2                        ['fulfilled', 'tired', 'happy']   \n",
       "3                    ['anticipation', 'hungry', 'happy']   \n",
       "4             ['sentimental', 'intrigued', 'reflective']   \n",
       "...                                                  ...   \n",
       "11605  ['devious', 'happy', 'relaxed', 'grateful', 'c...   \n",
       "11606                       ['anticipation', 'centered']   \n",
       "11607                           ['sad', 'uncomfortable']   \n",
       "11608  ['valued', 'happy', 'satisfied', 'helpful', 'c...   \n",
       "11609     ['shocked', 'stressed', 'alarmed', 'startled']   \n",
       "\n",
       "                                                plutchik  \\\n",
       "0      {'joy': 2, 'trust': 3, 'fear': 0, 'surprise': ...   \n",
       "1      {'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...   \n",
       "2      {'joy': 1, 'trust': 1, 'fear': 0, 'surprise': ...   \n",
       "3      {'joy': 3, 'trust': 1, 'fear': 0, 'surprise': ...   \n",
       "4      {'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "...                                                  ...   \n",
       "11605  {'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...   \n",
       "11606  {'joy': 2, 'trust': 2, 'fear': 2, 'surprise': ...   \n",
       "11607  {'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...   \n",
       "11608  {'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...   \n",
       "11609  {'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...   \n",
       "\n",
       "                                              selection0  \\\n",
       "0                 James rushed to finish his PowerPoint.   \n",
       "1      She always gossiped about other people and sai...   \n",
       "2                     The farmer woke up early everyday.   \n",
       "3      She would tell everyone that Alice lived in ca...   \n",
       "4              Ronald had a bag that meant a lot to him.   \n",
       "...                                                  ...   \n",
       "11605                  Corry moved into a new apartment.   \n",
       "11606    When I went to do another one, I hurt my ankle.   \n",
       "11607                 All his roommates loved the smell.   \n",
       "11608  Together they spent three hours in the garden ...   \n",
       "11609  The phone rang two hours later, jolting him ou...   \n",
       "\n",
       "                                              selection1  \\\n",
       "0                     Breanna wants to lose some weight.   \n",
       "1            My boyfriend took me to Amsterdam one year.   \n",
       "2            She had everyone dressed including herself.   \n",
       "3                      He can't because of his contract.   \n",
       "4                 Henry was walking while holding Stacy.   \n",
       "...                                                  ...   \n",
       "11605  Andy smelled the milk and noticed it was spoiled.   \n",
       "11606     Sue decided to delete the story and try again.   \n",
       "11607         Alice really needed to go to the bathroom.   \n",
       "11608                      Judy was in a baking contest.   \n",
       "11609  A woman who was afraid of snakes saw one outsi...   \n",
       "\n",
       "                                              selection2  \\\n",
       "0         George was walking past a row of parked bikes.   \n",
       "1              Dale is at his favorite bar having drinks   \n",
       "2                 He did this until he was 80 years old.   \n",
       "3      He looked inside and saw the Home Ec class had...   \n",
       "4      Judy went to her grandmother's on Saturday mor...   \n",
       "...                                                  ...   \n",
       "11605                     Michael was having a daughter.   \n",
       "11606                        Then a thaw came overnight!   \n",
       "11607  They served all their guests delicious food in...   \n",
       "11608  He needed his own money for things like gas an...   \n",
       "11609                             His computer froze up.   \n",
       "\n",
       "                                              selection3  \\\n",
       "0                                   He had to move away.   \n",
       "1                The trail took them through dark woods.   \n",
       "2                      She decided to throw a big party.   \n",
       "3      He found many of them and hung them on his shi...   \n",
       "4      Jack and Diane tried to follow it but they wer...   \n",
       "...                                                  ...   \n",
       "11605     She paid for her drink and started sipping it.   \n",
       "11606    The first night I tried it I slept like a baby!   \n",
       "11607      But he didn't become as good as he wanted to.   \n",
       "11608                  He saw the wet spot on the floor.   \n",
       "11609                     Jamie quit her job after that.   \n",
       "\n",
       "                                              selection4  label  \n",
       "0      Once he got there the beekeeper asked if Mark ...      4  \n",
       "1      He decided to get it done at a charity instead...      3  \n",
       "2      Beth was angry that Sam didn't clean up after ...      0  \n",
       "3      I was so angry that I told her never to call m...      2  \n",
       "4                   She was annoying him all night long.      0  \n",
       "...                                                  ...    ...  \n",
       "11605                         He let her pick the music.      4  \n",
       "11606  He pulled the strings of his backpack and rele...      4  \n",
       "11607  I decided to call in a professional to finish ...      1  \n",
       "11608                 The kids were hungry after school.      0  \n",
       "11609             They tried for many years to conceive.      0  \n",
       "\n",
       "[11610 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDatasetProcessed.to_csv(f'./dataset/5Select-{fileTag}-train.csv')\n",
    "trainDatasetProcessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b770299d-567d-46e2-b928-8ee31a341c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>plutchik</th>\n",
       "      <th>selection0</th>\n",
       "      <th>selection1</th>\n",
       "      <th>selection2</th>\n",
       "      <th>selection3</th>\n",
       "      <th>selection4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['honest', 'happy', 'proud']</td>\n",
       "      <td>{'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Since school is starting soon, I want to give ...</td>\n",
       "      <td>I wasn't allowed to have toys, so I played wit...</td>\n",
       "      <td>Mark was an honest soccer player who played by...</td>\n",
       "      <td>John desperately needed some money to pay bills.</td>\n",
       "      <td>It was good food and it was cheap.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['surprised', 'worried', 'puzzled', 'nervous',...</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...</td>\n",
       "      <td>Amber loved spicy food.</td>\n",
       "      <td>He sees his wife and gives her the biggest hug!</td>\n",
       "      <td>Rick sat down at his computer, about to do work.</td>\n",
       "      <td>I enjoyed swimming in the beach water during t...</td>\n",
       "      <td>He looked online to see what happened.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['happy', 'nervous', 'elated', 'small', 'peace...</td>\n",
       "      <td>{'joy': 1, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>We texted her our congratulations, as this wil...</td>\n",
       "      <td>She pulled out the kitchen stool and took a step.</td>\n",
       "      <td>He came out with so many great inventions.</td>\n",
       "      <td>He left the child unsupervised.</td>\n",
       "      <td>He was hoping this year to be tall enough for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['annoyed', 'surprised', 'sad']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Since my siblings were broke, my mom asked me ...</td>\n",
       "      <td>When she removed it the usb portion was broken.</td>\n",
       "      <td>They were having a ten dollar all you can eat ...</td>\n",
       "      <td>Alma called her boyfriend to stay with her.</td>\n",
       "      <td>The prankster who had hacked the sign enjoyed ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['irritated', 'weak', 'sad']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>They turned into chard.</td>\n",
       "      <td>They won third prize for best homemade float.</td>\n",
       "      <td>I was very thirsty.</td>\n",
       "      <td>He listened to it.</td>\n",
       "      <td>When she told John her feelings, John mirrored...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11124</th>\n",
       "      <td>['depressed', 'disillusioned', 'disappointment']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Roland noticed that his hair had gotten very l...</td>\n",
       "      <td>It looks and taste no different than any other...</td>\n",
       "      <td>She told me she was hungry.</td>\n",
       "      <td>She followed the recipe.</td>\n",
       "      <td>In time his circulation and respiratory health...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11125</th>\n",
       "      <td>['excitement', 'excited', 'fun', 'puzzled', 'a...</td>\n",
       "      <td>{'joy': 2, 'trust': 2, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Jamie got so carried away he forgot the pies w...</td>\n",
       "      <td>She was then sued in court and had to pay some...</td>\n",
       "      <td>Amanda was thrilled to finally be a big sister.</td>\n",
       "      <td>The judge asked him about his sweat.</td>\n",
       "      <td>Adam thought it was fascinating.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11126</th>\n",
       "      <td>['happy', 'content', 'glad', 'excited', 'eager...</td>\n",
       "      <td>{'joy': 2, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>The teacher heard the phone ring.</td>\n",
       "      <td>He was always picked for the first team.</td>\n",
       "      <td>He was driving much too fast for the road cond...</td>\n",
       "      <td>Oliver liked learning card tricks.</td>\n",
       "      <td>The kids were starving.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11127</th>\n",
       "      <td>['surprised', 'awe', 'surprise', 'horrified', ...</td>\n",
       "      <td>{'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Hannah decided to delete most of them.</td>\n",
       "      <td>They just told me it was soup.</td>\n",
       "      <td>A rabbit had started nesting on top of his bat...</td>\n",
       "      <td>He was very nervous that he wouldn't know anyo...</td>\n",
       "      <td>One day an older lady came in and told him how...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>['neglected', 'unwanted', 'heartbroken', 'sad']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>They had to cut the baby out.</td>\n",
       "      <td>I was not happy.</td>\n",
       "      <td>His house was covered in his artwork.</td>\n",
       "      <td>Spunks always gets passed up for adoption.</td>\n",
       "      <td>Erin had to go to the store and buy books on w...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11129 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 emotion  \\\n",
       "0                           ['honest', 'happy', 'proud']   \n",
       "1      ['surprised', 'worried', 'puzzled', 'nervous',...   \n",
       "2      ['happy', 'nervous', 'elated', 'small', 'peace...   \n",
       "3                        ['annoyed', 'surprised', 'sad']   \n",
       "4                           ['irritated', 'weak', 'sad']   \n",
       "...                                                  ...   \n",
       "11124   ['depressed', 'disillusioned', 'disappointment']   \n",
       "11125  ['excitement', 'excited', 'fun', 'puzzled', 'a...   \n",
       "11126  ['happy', 'content', 'glad', 'excited', 'eager...   \n",
       "11127  ['surprised', 'awe', 'surprise', 'horrified', ...   \n",
       "11128    ['neglected', 'unwanted', 'heartbroken', 'sad']   \n",
       "\n",
       "                                                plutchik  \\\n",
       "0      {'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...   \n",
       "1      {'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...   \n",
       "2      {'joy': 1, 'trust': 1, 'fear': 0, 'surprise': ...   \n",
       "3      {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "4      {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "...                                                  ...   \n",
       "11124  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "11125  {'joy': 2, 'trust': 2, 'fear': 0, 'surprise': ...   \n",
       "11126  {'joy': 2, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "11127  {'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "11128  {'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...   \n",
       "\n",
       "                                              selection0  \\\n",
       "0      Since school is starting soon, I want to give ...   \n",
       "1                                Amber loved spicy food.   \n",
       "2      We texted her our congratulations, as this wil...   \n",
       "3      Since my siblings were broke, my mom asked me ...   \n",
       "4                                They turned into chard.   \n",
       "...                                                  ...   \n",
       "11124  Roland noticed that his hair had gotten very l...   \n",
       "11125  Jamie got so carried away he forgot the pies w...   \n",
       "11126                  The teacher heard the phone ring.   \n",
       "11127             Hannah decided to delete most of them.   \n",
       "11128                      They had to cut the baby out.   \n",
       "\n",
       "                                              selection1  \\\n",
       "0      I wasn't allowed to have toys, so I played wit...   \n",
       "1        He sees his wife and gives her the biggest hug!   \n",
       "2      She pulled out the kitchen stool and took a step.   \n",
       "3        When she removed it the usb portion was broken.   \n",
       "4          They won third prize for best homemade float.   \n",
       "...                                                  ...   \n",
       "11124  It looks and taste no different than any other...   \n",
       "11125  She was then sued in court and had to pay some...   \n",
       "11126           He was always picked for the first team.   \n",
       "11127                     They just told me it was soup.   \n",
       "11128                                   I was not happy.   \n",
       "\n",
       "                                              selection2  \\\n",
       "0      Mark was an honest soccer player who played by...   \n",
       "1       Rick sat down at his computer, about to do work.   \n",
       "2             He came out with so many great inventions.   \n",
       "3      They were having a ten dollar all you can eat ...   \n",
       "4                                    I was very thirsty.   \n",
       "...                                                  ...   \n",
       "11124                        She told me she was hungry.   \n",
       "11125    Amanda was thrilled to finally be a big sister.   \n",
       "11126  He was driving much too fast for the road cond...   \n",
       "11127  A rabbit had started nesting on top of his bat...   \n",
       "11128              His house was covered in his artwork.   \n",
       "\n",
       "                                              selection3  \\\n",
       "0       John desperately needed some money to pay bills.   \n",
       "1      I enjoyed swimming in the beach water during t...   \n",
       "2                        He left the child unsupervised.   \n",
       "3            Alma called her boyfriend to stay with her.   \n",
       "4                                     He listened to it.   \n",
       "...                                                  ...   \n",
       "11124                           She followed the recipe.   \n",
       "11125               The judge asked him about his sweat.   \n",
       "11126                 Oliver liked learning card tricks.   \n",
       "11127  He was very nervous that he wouldn't know anyo...   \n",
       "11128         Spunks always gets passed up for adoption.   \n",
       "\n",
       "                                              selection4  label  \n",
       "0                     It was good food and it was cheap.      2  \n",
       "1                 He looked online to see what happened.      4  \n",
       "2      He was hoping this year to be tall enough for ...      0  \n",
       "3      The prankster who had hacked the sign enjoyed ...      1  \n",
       "4      When she told John her feelings, John mirrored...      2  \n",
       "...                                                  ...    ...  \n",
       "11124  In time his circulation and respiratory health...      1  \n",
       "11125                   Adam thought it was fascinating.      0  \n",
       "11126                            The kids were starving.      3  \n",
       "11127  One day an older lady came in and told him how...      2  \n",
       "11128  Erin had to go to the store and buy books on w...      3  \n",
       "\n",
       "[11129 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDatasetProcessed.to_csv(f'./dataset/5Select-{fileTag}-test.csv')\n",
    "testDatasetProcessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7283c1-d83e-4369-b5e4-6c2e09d654ac",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "828a5092-83e6-4580-99c9-bd9ec434708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05151e3b-0bec-44f4-bf0a-ac58cddbf838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-16041a9da5e70933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:\\Users\\JAM_0\\.cache\\huggingface\\datasets\\csv\\default-16041a9da5e70933\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f6b35990d44a56b81418ad1e187e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b434b43e75394c50aae9e3892913e79a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:\\Users\\JAM_0\\.cache\\huggingface\\datasets\\csv\\default-16041a9da5e70933\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012f646245f542e2809326278aae65f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('csv', data_files={'train': f'./dataset/5Select-{fileTag}-train.csv', \n",
    "                                           'test': f'./dataset/5Select-{fileTag}-test.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d776c270-7752-4445-ba6c-eb078f71eccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'emotion', 'plutchik', 'selection0', 'selection1', 'selection2', 'selection3', 'selection4', 'label'],\n",
       "        num_rows: 11610\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'emotion', 'plutchik', 'selection0', 'selection1', 'selection2', 'selection3', 'selection4', 'label'],\n",
       "        num_rows: 11129\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1c79159-f795-4d02-b052-94f04286d53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 0,\n",
       " 'emotion': \"['honest', 'happy', 'proud']\",\n",
       " 'plutchik': \"{'joy': 2, 'trust': 1, 'fear': 0, 'surprise': 0, 'sadness': 0, 'disgust': 0, 'anger': 0, 'anticipation': 0}\",\n",
       " 'selection0': 'Since school is starting soon, I want to give her time to adjust.',\n",
       " 'selection1': \"I wasn't allowed to have toys, so I played with my brother's.\",\n",
       " 'selection2': 'Mark was an honest soccer player who played by the rules.',\n",
       " 'selection3': 'John desperately needed some money to pay bills.',\n",
       " 'selection4': 'It was good food and it was cheap.',\n",
       " 'label': 2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f6ad67d-b4cb-4f65-a9cb-d2d665deec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_one(example):\n",
    "    print(f\"Context: {example['plutchik']}\")\n",
    "    print(f\"  A - {example['selection0']}\")\n",
    "    print(f\"  B - {example['selection1']}\")\n",
    "    print(f\"  C - {example['selection2']}\")\n",
    "    print(f\"  D - {example['selection3']}\")\n",
    "    print(f\"  E - {example['selection4']}\")\n",
    "    print(f\"\\nGround truth: option {['A', 'B', 'C', 'D', 'E'][example['label']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15cd7cfb-748a-4fe7-8152-7debf6a65ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: {'joy': 2, 'trust': 3, 'fear': 0, 'surprise': 0, 'sadness': 0, 'disgust': 0, 'anger': 0, 'anticipation': 2}\n",
      "  A - James rushed to finish his PowerPoint.\n",
      "  B - Breanna wants to lose some weight.\n",
      "  C - George was walking past a row of parked bikes.\n",
      "  D - He had to move away.\n",
      "  E - Once he got there the beekeeper asked if Mark would like a tour.\n",
      "\n",
      "Ground truth: option E\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da93346-1037-41ed-b67d-91877fa8c0ec",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3da78c12-9aff-4beb-a006-e287bbf61023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caffe397-a65d-478f-b966-7b910fb2edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "selectionList = [\"selection0\", \"selection1\", \"selection2\", \"selection3\", \"selection4\"]\n",
    "weightRemap = [\"NOT \", \"LITTLE \", \"\", \"VERY \", \"ABSOLUTELY \"]\n",
    "def preprocess_function(examples):\n",
    "    # Repeat each first sentence four times to go with the four possibilities of second sentences.\n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(context.strip(\"[\").strip(\"]\").replace('\\'', '')) ]*2 for context in examples[\"emotion\"] ]\n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(context.strip(\"[\").strip(\"]\").replace('\\\"', '')) ]*2 for context in examples[\"plutchik\"] ]\n",
    "    first_sentences = [[\"The following sentences contain emotions: {}\".format(\", \".join([weightRemap[int(eachCaseWeight.replace(\"]\", \"\").replace(\"[\", \"\").replace(\"}\", \"\").replace(\"{\", \"\").replace(\"\\\"\", \"\").replace(\"\\'\", \"\"))] \n",
    "                                                        + eachCaseEmotionType.replace(\"]\", \"\").replace(\"[\", \"\").replace(\"}\", \"\").replace(\"{\", \"\").replace(\"\\\"\", \"\").replace(\"\\'\", \"\").strip()\n",
    "                        for eachCaseWeight, eachCaseEmotionType in \n",
    "                        zip([re.split(':|,',eachEmotionCombination)[1::2] for eachEmotionCombination in examples[\"plutchik\"]][eventIndex], \n",
    "                           [re.split(':|,',eachEmotionCombination)[::2] for eachEmotionCombination in examples[\"plutchik\"]][eventIndex])]))]*5 for eventIndex in \n",
    "                           range(len([re.split(':|,',eachEmotionCombination)[1::2] for eachEmotionCombination in examples[\"plutchik\"]]))]\n",
    "    \n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(', '.join([(weightRemap[eachEmotion[1]] + \" \" +eachEmotion[0]).strip() \n",
    "    #                    for eachEmotion in ast.literal_eval(context).items()]))]*2 \n",
    "    #                    for context in examples[\"plutchik\"]]\n",
    "    # Grab all second sentences possible for each context.\n",
    "    second_sentences = [[examples[selection][index] for selection in selectionList]for index in range(len(examples['selection0']))]\n",
    "\n",
    "    # Flatten everything\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "    \n",
    "    # Tokenize\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "    # Un-flatten\n",
    "    # print(tokenized_examples.items())\n",
    "    return {k: [v[i:i+5] for i in range(0, len(v), 5)] for k, v in tokenized_examples.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0afb4841-ab69-4b91-8859-fd249badb923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5 [38, 39, 41, 37, 46]\n"
     ]
    }
   ],
   "source": [
    "examples = dataset[\"train\"][:5]\n",
    "features = preprocess_function(examples)\n",
    "print(len(features[\"input_ids\"]), len(features[\"input_ids\"][0]), [len(x) for x in features[\"input_ids\"][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "903e2891-0e3d-4e87-b98a-727eaf36417a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>The following sentences contain emotions: joy, VERY trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, anticipation</s></s>James rushed to finish his PowerPoint.</s>',\n",
       " '<s>The following sentences contain emotions: joy, VERY trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, anticipation</s></s>Breanna wants to lose some weight.</s>',\n",
       " '<s>The following sentences contain emotions: joy, VERY trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, anticipation</s></s>George was walking past a row of parked bikes.</s>',\n",
       " '<s>The following sentences contain emotions: joy, VERY trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, anticipation</s></s>He had to move away.</s>',\n",
       " '<s>The following sentences contain emotions: NOT joy, NOT trust, fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, anticipation</s></s>She always gossiped about other people and said ugly things.</s>',\n",
       " '<s>The following sentences contain emotions: NOT joy, NOT trust, fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, anticipation</s></s>My boyfriend took me to Amsterdam one year.</s>',\n",
       " '<s>The following sentences contain emotions: NOT joy, NOT trust, fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, anticipation</s></s>Dale is at his favorite bar having drinks</s>',\n",
       " '<s>The following sentences contain emotions: NOT joy, NOT trust, fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, anticipation</s></s>The trail took them through dark woods.</s>',\n",
       " '<s>The following sentences contain emotions: LITTLE joy, LITTLE trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation</s></s>The farmer woke up early everyday.</s>',\n",
       " '<s>The following sentences contain emotions: LITTLE joy, LITTLE trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation</s></s>She had everyone dressed including herself.</s>',\n",
       " '<s>The following sentences contain emotions: LITTLE joy, LITTLE trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation</s></s>He did this until he was 80 years old.</s>',\n",
       " '<s>The following sentences contain emotions: LITTLE joy, LITTLE trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation</s></s>She decided to throw a big party.</s>',\n",
       " '<s>The following sentences contain emotions: VERY joy, LITTLE trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, anticipation</s></s>She would tell everyone that Alice lived in cardboard box.</s>',\n",
       " \"<s>The following sentences contain emotions: VERY joy, LITTLE trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, anticipation</s></s>He can't because of his contract.</s>\",\n",
       " '<s>The following sentences contain emotions: VERY joy, LITTLE trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, anticipation</s></s>He looked inside and saw the Home Ec class had baked pies.</s>',\n",
       " '<s>The following sentences contain emotions: VERY joy, LITTLE trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, anticipation</s></s>He found many of them and hung them on his shirt like decorations.</s>',\n",
       " '<s>The following sentences contain emotions: LITTLE joy, NOT trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation</s></s>Ronald had a bag that meant a lot to him.</s>',\n",
       " '<s>The following sentences contain emotions: LITTLE joy, NOT trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation</s></s>Henry was walking while holding Stacy.</s>',\n",
       " \"<s>The following sentences contain emotions: LITTLE joy, NOT trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation</s></s>Judy went to her grandmother's on Saturday morning.</s>\",\n",
       " '<s>The following sentences contain emotions: LITTLE joy, NOT trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation</s></s>Jack and Diane tried to follow it but they were not able to find him.</s>']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(features[\"input_ids\"][a][i]) for a in range(5) for i in range(4) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a286ba6-cb84-4619-b842-780124d26a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c7acc7a510d461890fb7fdac01dedac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05491584bc0a442083439dcff47e00f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7706d875-3a89-4e52-9f08-c77256b621ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForMultipleChoice: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForMultipleChoice.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2cd7be65-ebd8-43db-bcbf-a87d7e2342e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-emotionCommonsense\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=5e-6, # for bert-base\n",
    "    # learning_rate=1e-3,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2737e04e-19c2-407d-8ce1-06b675f208c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [[{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        # Un-flatten\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        # Add back labels\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03a0ec05-de5e-434f-b07c-63212e7c7f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_keys = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "features = [{k: v for k, v in encoded_datasets[\"train\"][i].items() if k in accepted_keys} for i in range(10)]\n",
    "batch = DataCollatorForMultipleChoice(tokenizer)(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45f7f26c-04bb-42ae-8627-897ced69888e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>The following sentences contain emotions: anticipation</s></s>George sprained his ankle going down the stairs.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<s>The following sentences contain emotions: anticipation</s></s>He made a flyer asking for a strong helper.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<s>The following sentences contain emotions: anticipation</s></s>He hopped off the boat into the crystal clear water.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(batch[\"input_ids\"][8][i].tolist()) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4b55256-30fa-4e30-a3a4-66fe1114b941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [\"anticipation:2\"]\n",
      "  A - George sprained his ankle going down the stairs.\n",
      "  B - He made a flyer asking for a strong helper.\n",
      "  C - He hopped off the boat into the crystal clear water.\n",
      "\n",
      "Ground truth: option B\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8305d3-8dc9-4d0f-8628-f51dc356c2d2",
   "metadata": {},
   "source": [
    "# Trainer Defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b707863a-bc16-43b0-b633-c7ffb4fa72e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "valStored = []\n",
    "def compute_metrics(eval_predictions):\n",
    "    predictions, label_ids = eval_predictions\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    valStored.append((preds != label_ids).astype(np.float32));\n",
    "    return {\"accuracy\": (preds == label_ids).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b115c1ba-323a-47d5-bb9d-55de985f13b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_datasets[\"train\"],\n",
    "    eval_dataset=encoded_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a5e3430-bbd6-484d-8a8d-9cbcdba37d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "C:\\Python\\miniconda3\\envs\\pytorchEnvWithDataSci\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 53234\n",
      "  Num Epochs = 16\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53248\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53248' max='53248' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53248/53248 2:26:59, Epoch 16/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.693800</td>\n",
       "      <td>0.693128</td>\n",
       "      <td>0.504018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.614600</td>\n",
       "      <td>0.594435</td>\n",
       "      <td>0.656838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.564700</td>\n",
       "      <td>0.571774</td>\n",
       "      <td>0.684685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.526300</td>\n",
       "      <td>0.572104</td>\n",
       "      <td>0.695053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.499500</td>\n",
       "      <td>0.586160</td>\n",
       "      <td>0.701162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.472300</td>\n",
       "      <td>0.586649</td>\n",
       "      <td>0.705170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.620333</td>\n",
       "      <td>0.704207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.444200</td>\n",
       "      <td>0.623844</td>\n",
       "      <td>0.704265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.415700</td>\n",
       "      <td>0.655308</td>\n",
       "      <td>0.705055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.394100</td>\n",
       "      <td>0.685141</td>\n",
       "      <td>0.703860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.375700</td>\n",
       "      <td>0.723962</td>\n",
       "      <td>0.702183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.371000</td>\n",
       "      <td>0.727208</td>\n",
       "      <td>0.702646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.339400</td>\n",
       "      <td>0.768802</td>\n",
       "      <td>0.702723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.327800</td>\n",
       "      <td>0.798015</td>\n",
       "      <td>0.701258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.320600</td>\n",
       "      <td>0.806652</td>\n",
       "      <td>0.700892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.310600</td>\n",
       "      <td>0.814122</td>\n",
       "      <td>0.700565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-53000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-53000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-53000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-53000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-53000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=53248, training_loss=0.4483006133769567, metrics={'train_runtime': 8821.4262, 'train_samples_per_second': 96.554, 'train_steps_per_second': 6.036, 'total_flos': 5.267817952412011e+16, 'train_loss': 0.4483006133769567, 'epoch': 16.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a17948-a8f7-4450-b2b0-8a7016e91391",
   "metadata": {},
   "source": [
    "出现validation loss 上升情况大多是训练集验证集数据分布不一致，或者训练集过小，未包含验证集中所有情况，\n",
    "也就是过拟合导致的。而解决这种现象可以尝试以下几种策略：\n",
    "1. 增加训练样本增加正则项系数权重，\n",
    "2. 减小过拟合加入早停机制，ValLoss上升几个epoch直接停止\n",
    "3. 采用Focal Loss\n",
    "4. 加入Label Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d6ab3-33ac-4e8e-99ee-3c3f17d71642",
   "metadata": {},
   "source": [
    "# Store Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c30271fe-7ce9-43e8-9e87-de8d6ae2c2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x23113595460>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "Z = np.transpose(valStored)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.pcolormesh(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e77d30e-e51a-45a6-9130-83a17c4d2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataLog = pd.DataFrame(trainer.state.log_history)\n",
    "dataLog.to_csv(f'./trainingMetric/[plutchik]trainingInfo-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c90cfec4-96ec-46c8-a99f-3c78b989b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluationIterationResult = pd.DataFrame(np.transpose(valStored))\n",
    "evaluationIterationResult.to_csv(f'./trainingMetric/[plutchik]evaluationSpecificInfo-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd7f330-1477-4119-a9dc-1ebb7acb7665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchEnvWithDataSci",
   "language": "python",
   "name": "pytorchenvwithdatasci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
