{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8533643b-5b68-4dec-8a8a-49852c237e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global var set\n",
    "import transformers\n",
    "\n",
    "# model info, change as needed\n",
    "model_checkpoint = \"bert-base-uncased\"\n",
    "batch_size = 16\n",
    "num_epochs = 16\n",
    "\n",
    "fileTag = \"original\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa38989-ff76-4de1-a82e-6853a1e61687",
   "metadata": {},
   "source": [
    "# Convert dataset to suitable format\n",
    "IMPORTANT: please never run this section again if you have your dataset ready!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a93a9f46-6703-4535-af96-8be1b5b3407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "trainDatasetOriginal = pd.read_csv(f'../../data/csv_version/dev/emotion/allcharlinepairs-{fileTag}.csv')\n",
    "testDatasetOriginal = pd.read_csv(f'../../data/csv_version/test/emotion/allcharlinepairs-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7265a797-adc2-49ed-b237-19abf9e0569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatasetProcessed = DataFrame({'emotion' : trainDatasetOriginal['emotion'], \n",
    "                                  'selection0': pd.concat([trainDatasetOriginal['sentence'][:trainDatasetOriginal.shape[0]//2], trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//2:]]), \n",
    "                                  'selection1': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//2], trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//2:]]), \n",
    "                                  'label': pd.Series(0 if x < trainDatasetOriginal.shape[0]//2 else 1 for x in trainDatasetOriginal.index)}).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "testDatasetProcessed = DataFrame({'emotion' : testDatasetOriginal['emotion'], \n",
    "                                  'selection0': pd.concat([testDatasetOriginal['sentence'][:testDatasetOriginal.shape[0]//2], testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//2:]]), \n",
    "                                  'selection1': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//2], testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//2:]]), \n",
    "                                  'label': pd.Series(0 if x < testDatasetOriginal.shape[0]//2 else 1 for x in testDatasetOriginal.index)}).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19e3c334-b371-44ad-b6e1-7161f405b741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>selection0</th>\n",
       "      <th>selection1</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"satisfied\"]</td>\n",
       "      <td>Laurie was unemployed and Jessie decided to he...</td>\n",
       "      <td>John puts cream and sugar in his cup and thermos.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"alarmed\"]</td>\n",
       "      <td>Dottie looked closer and saw lots of shiny bea...</td>\n",
       "      <td>When she looked at his hands he threw the spid...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"useful\"]</td>\n",
       "      <td>Nana chased her down, caught her, and tickled ...</td>\n",
       "      <td>Tom appreciated the hard work and dedication.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"excited and happy\"]</td>\n",
       "      <td>He asked her on a date.</td>\n",
       "      <td>She loves the letter W.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"boring\"]</td>\n",
       "      <td>Anna got the same lunch every day - bologna an...</td>\n",
       "      <td>It was too late to drive to a store to buy som...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53229</th>\n",
       "      <td>[\"sad\"]</td>\n",
       "      <td>When the hygienist flossed for her, Delia's gu...</td>\n",
       "      <td>The hosts offered the kids cake and ice cream.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53230</th>\n",
       "      <td>[\"excited\"]</td>\n",
       "      <td>To strengthen his position he took managerial ...</td>\n",
       "      <td>His dad explained that they were tide pools wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53231</th>\n",
       "      <td>[\"content\"]</td>\n",
       "      <td>Cora called her friend Maya.</td>\n",
       "      <td>Camden and his brother loved going to the park.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53232</th>\n",
       "      <td>[\"annoyed\"]</td>\n",
       "      <td>Now Nelly can knit and Emma can sew.</td>\n",
       "      <td>Grandma had forgotten to pick up the noodles f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53233</th>\n",
       "      <td>[\"sorry\"]</td>\n",
       "      <td>I sat up partway using lots of pillows.</td>\n",
       "      <td>His roommates were disappointed.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53234 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     emotion  \\\n",
       "0              [\"satisfied\"]   \n",
       "1                [\"alarmed\"]   \n",
       "2                 [\"useful\"]   \n",
       "3      [\"excited and happy\"]   \n",
       "4                 [\"boring\"]   \n",
       "...                      ...   \n",
       "53229                [\"sad\"]   \n",
       "53230            [\"excited\"]   \n",
       "53231            [\"content\"]   \n",
       "53232            [\"annoyed\"]   \n",
       "53233              [\"sorry\"]   \n",
       "\n",
       "                                              selection0  \\\n",
       "0      Laurie was unemployed and Jessie decided to he...   \n",
       "1      Dottie looked closer and saw lots of shiny bea...   \n",
       "2      Nana chased her down, caught her, and tickled ...   \n",
       "3                                He asked her on a date.   \n",
       "4      Anna got the same lunch every day - bologna an...   \n",
       "...                                                  ...   \n",
       "53229  When the hygienist flossed for her, Delia's gu...   \n",
       "53230  To strengthen his position he took managerial ...   \n",
       "53231                       Cora called her friend Maya.   \n",
       "53232               Now Nelly can knit and Emma can sew.   \n",
       "53233            I sat up partway using lots of pillows.   \n",
       "\n",
       "                                              selection1  label  \n",
       "0      John puts cream and sugar in his cup and thermos.      0  \n",
       "1      When she looked at his hands he threw the spid...      1  \n",
       "2          Tom appreciated the hard work and dedication.      1  \n",
       "3                                She loves the letter W.      1  \n",
       "4      It was too late to drive to a store to buy som...      0  \n",
       "...                                                  ...    ...  \n",
       "53229     The hosts offered the kids cake and ice cream.      0  \n",
       "53230  His dad explained that they were tide pools wi...      1  \n",
       "53231    Camden and his brother loved going to the park.      0  \n",
       "53232  Grandma had forgotten to pick up the noodles f...      1  \n",
       "53233                   His roommates were disappointed.      1  \n",
       "\n",
       "[53234 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDatasetProcessed.to_csv(f'./multiSelect-{fileTag}-train.csv')\n",
    "trainDatasetProcessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b770299d-567d-46e2-b928-8ee31a341c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>selection0</th>\n",
       "      <th>selection1</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"guilty\"]</td>\n",
       "      <td>Jordan's mother saw this and brought his frien...</td>\n",
       "      <td>Jim and Janie Jones had a cat named Vixen.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"none\"]</td>\n",
       "      <td>It is her husband's sister's kid.</td>\n",
       "      <td>He wrote a book about it.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"none\"]</td>\n",
       "      <td>The movie had sold out before we got there.</td>\n",
       "      <td>He saw the most beautiful cat there.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"proud\", \"happy\"]</td>\n",
       "      <td>She told all her coworkers about it as she hea...</td>\n",
       "      <td>I was in shape and ready for my upcoming wedding.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"frustrated and angry\"]</td>\n",
       "      <td>Everyone had an amazing time thanks to Carla's...</td>\n",
       "      <td>Jay couldn't find a job.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51886</th>\n",
       "      <td>[\"distrustful of roommate\"]</td>\n",
       "      <td>The food was amazing there.</td>\n",
       "      <td>The roommate admitted to borrowing it.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51887</th>\n",
       "      <td>[\"none\"]</td>\n",
       "      <td>Megan brought her little children to the park.</td>\n",
       "      <td>After a nail biting game, the young child was ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51888</th>\n",
       "      <td>[\"scare\", \"surprise\"]</td>\n",
       "      <td>The next day, Kayla saw someone wearing her ne...</td>\n",
       "      <td>Felicia smiled too but her heart was still bea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51889</th>\n",
       "      <td>[\"hard working\"]</td>\n",
       "      <td>Gina's crush had smiled at her in the morning.</td>\n",
       "      <td>Jean went back home and continued tilling.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51890</th>\n",
       "      <td>[\"happy with excitement\"]</td>\n",
       "      <td>He counted them himself, twelve slimy slugs.</td>\n",
       "      <td>Tiffany loved shredded cheese and crackers in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51891 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           emotion  \\\n",
       "0                       [\"guilty\"]   \n",
       "1                         [\"none\"]   \n",
       "2                         [\"none\"]   \n",
       "3               [\"proud\", \"happy\"]   \n",
       "4         [\"frustrated and angry\"]   \n",
       "...                            ...   \n",
       "51886  [\"distrustful of roommate\"]   \n",
       "51887                     [\"none\"]   \n",
       "51888        [\"scare\", \"surprise\"]   \n",
       "51889             [\"hard working\"]   \n",
       "51890    [\"happy with excitement\"]   \n",
       "\n",
       "                                              selection0  \\\n",
       "0      Jordan's mother saw this and brought his frien...   \n",
       "1                      It is her husband's sister's kid.   \n",
       "2            The movie had sold out before we got there.   \n",
       "3      She told all her coworkers about it as she hea...   \n",
       "4      Everyone had an amazing time thanks to Carla's...   \n",
       "...                                                  ...   \n",
       "51886                        The food was amazing there.   \n",
       "51887     Megan brought her little children to the park.   \n",
       "51888  The next day, Kayla saw someone wearing her ne...   \n",
       "51889     Gina's crush had smiled at her in the morning.   \n",
       "51890       He counted them himself, twelve slimy slugs.   \n",
       "\n",
       "                                              selection1  label  \n",
       "0             Jim and Janie Jones had a cat named Vixen.      0  \n",
       "1                              He wrote a book about it.      1  \n",
       "2                   He saw the most beautiful cat there.      1  \n",
       "3      I was in shape and ready for my upcoming wedding.      1  \n",
       "4                               Jay couldn't find a job.      1  \n",
       "...                                                  ...    ...  \n",
       "51886             The roommate admitted to borrowing it.      1  \n",
       "51887  After a nail biting game, the young child was ...      0  \n",
       "51888  Felicia smiled too but her heart was still bea...      1  \n",
       "51889         Jean went back home and continued tilling.      1  \n",
       "51890  Tiffany loved shredded cheese and crackers in ...      1  \n",
       "\n",
       "[51891 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDatasetProcessed.to_csv(f'./multiSelect-{fileTag}-test.csv')\n",
    "testDatasetProcessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7283c1-d83e-4369-b5e4-6c2e09d654ac",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "828a5092-83e6-4580-99c9-bd9ec434708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05151e3b-0bec-44f4-bf0a-ac58cddbf838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-ec8ac5ec3770a4ef\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:\\Users\\JAM_0\\.cache\\huggingface\\datasets\\csv\\default-ec8ac5ec3770a4ef\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8728797ba5204a1bbc09ef1d18eb5231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89afc28622b24881ac24d054ec4bd663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:\\Users\\JAM_0\\.cache\\huggingface\\datasets\\csv\\default-ec8ac5ec3770a4ef\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f5b294cc18e47178b315f2c237d0ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('csv', data_files={'train': f'./multiSelect-{fileTag}-train.csv', \n",
    "                                           'test': f'./multiSelect-{fileTag}-test.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d776c270-7752-4445-ba6c-eb078f71eccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'emotion', 'selection0', 'selection1', 'label'],\n",
       "        num_rows: 53234\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'emotion', 'selection0', 'selection1', 'label'],\n",
       "        num_rows: 51891\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1c79159-f795-4d02-b052-94f04286d53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 0,\n",
       " 'emotion': '[\"guilty\"]',\n",
       " 'selection0': \"Jordan's mother saw this and brought his friend cake, but not Jordan.\",\n",
       " 'selection1': 'Jim and Janie Jones had a cat named Vixen.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f6ad67d-b4cb-4f65-a9cb-d2d665deec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_one(example):\n",
    "    print(f\"Context: {example['emotion']}\")\n",
    "    print(f\"  A - {example['selection0']}\")\n",
    "    print(f\"  B - {example['selection1']}\")\n",
    "    print(f\"\\nGround truth: option {['A', 'B'][example['label']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15cd7cfb-748a-4fe7-8152-7debf6a65ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [\"satisfied\"]\n",
      "  A - Laurie was unemployed and Jessie decided to help her out.\n",
      "  B - John puts cream and sugar in his cup and thermos.\n",
      "\n",
      "Ground truth: option A\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da93346-1037-41ed-b67d-91877fa8c0ec",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3da78c12-9aff-4beb-a006-e287bbf61023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caffe397-a65d-478f-b966-7b910fb2edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectionList = [\"selection0\", \"selection1\"]\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Repeat each first sentence four times to go with the four possibilities of second sentences.\n",
    "    first_sentences = [[\"The following sentences contain emotions: {}\".format(context.strip(\"[\").strip(\"]\").replace('\\'', '')) ]*2 for context in examples[\"emotion\"] ]\n",
    "    # Grab all second sentences possible for each context.\n",
    "    second_sentences = [[examples[selection][index] for selection in selectionList]for index in range(len(examples['selection0']))]\n",
    "\n",
    "    # Flatten everything\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "    \n",
    "    # Tokenize\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "    # Un-flatten\n",
    "    # print(tokenized_examples.items())\n",
    "    return {k: [v[i:i+2] for i in range(0, len(v), 2)] for k, v in tokenized_examples.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0afb4841-ab69-4b91-8859-fd249badb923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2 [23, 25]\n"
     ]
    }
   ],
   "source": [
    "examples = dataset[\"train\"][:5]\n",
    "features = preprocess_function(examples)\n",
    "print(len(features[\"input_ids\"]), len(features[\"input_ids\"][0]), [len(x) for x in features[\"input_ids\"][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "903e2891-0e3d-4e87-b98a-727eaf36417a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] the following sentences contain emotions : \" satisfied \" [SEP] laurie was unemployed and jessie decided to help her out. [SEP]',\n",
       " '[CLS] the following sentences contain emotions : \" alarmed \" [SEP] dottie looked closer and saw lots of shiny beatles on the leaves. [SEP]',\n",
       " '[CLS] the following sentences contain emotions : \" useful \" [SEP] nana chased her down, caught her, and tickled her until she laughed. [SEP]',\n",
       " '[CLS] the following sentences contain emotions : \" excited and happy \" [SEP] he asked her on a date. [SEP]',\n",
       " '[CLS] the following sentences contain emotions : \" boring \" [SEP] anna got the same lunch every day - bologna and carrots. [SEP]']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(features[\"input_ids\"][a][i]) for a in range(5) for i in range(1) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a286ba6-cb84-4619-b842-780124d26a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836bc5d6679842e9a15a2ee444ec85c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a08ebd6bdf64a118e342a7ecada3c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f496be7-4673-4520-b30e-656cd5640b34",
   "metadata": {},
   "source": [
    "# Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7706d875-3a89-4e52-9f08-c77256b621ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultipleChoice: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForMultipleChoice.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cd7be65-ebd8-43db-bcbf-a87d7e2342e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-emotionCommonsense\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=5e-5, # for bert-base\n",
    "    # learning_rate=1e-3,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2737e04e-19c2-407d-8ce1-06b675f208c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [[{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        # Un-flatten\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        # Add back labels\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03a0ec05-de5e-434f-b07c-63212e7c7f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_keys = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "features = [{k: v for k, v in encoded_datasets[\"train\"][i].items() if k in accepted_keys} for i in range(10)]\n",
    "batch = DataCollatorForMultipleChoice(tokenizer)(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45f7f26c-04bb-42ae-8627-897ced69888e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] the following sentences contain emotions : \" none \" [SEP] she really enjoyed the book. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] the following sentences contain emotions : \" none \" [SEP] the dog\\'s owner yelled for it to stop but it ran faster. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(batch[\"input_ids\"][8][i].tolist()) for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4b55256-30fa-4e30-a3a4-66fe1114b941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [\"none\"]\n",
      "  A - She really enjoyed the book.\n",
      "  B - The dog's owner yelled for it to stop but it ran faster.\n",
      "\n",
      "Ground truth: option B\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8305d3-8dc9-4d0f-8628-f51dc356c2d2",
   "metadata": {},
   "source": [
    "# Trainer Defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b707863a-bc16-43b0-b633-c7ffb4fa72e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "valStored = []\n",
    "def compute_metrics(eval_predictions):\n",
    "    predictions, label_ids = eval_predictions\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    valStored.append((preds != label_ids).astype(np.float32));\n",
    "    return {\"accuracy\": (preds == label_ids).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b115c1ba-323a-47d5-bb9d-55de985f13b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_datasets[\"train\"],\n",
    "    eval_dataset=encoded_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a5e3430-bbd6-484d-8a8d-9cbcdba37d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: Unnamed: 0, selection1, selection0, emotion. If Unnamed: 0, selection1, selection0, emotion are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "C:\\Python\\miniconda3\\envs\\pytorchEnvWithDataSci\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 53234\n",
      "  Num Epochs = 16\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53248\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53248' max='53248' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53248/53248 1:43:16, Epoch 16/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.490400</td>\n",
       "      <td>0.498158</td>\n",
       "      <td>0.754023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.401900</td>\n",
       "      <td>0.512455</td>\n",
       "      <td>0.756027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.309800</td>\n",
       "      <td>0.689945</td>\n",
       "      <td>0.753599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.257800</td>\n",
       "      <td>0.989739</td>\n",
       "      <td>0.745004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.204300</td>\n",
       "      <td>1.182847</td>\n",
       "      <td>0.742711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.173400</td>\n",
       "      <td>1.452443</td>\n",
       "      <td>0.743192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.137900</td>\n",
       "      <td>1.432687</td>\n",
       "      <td>0.743270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.119100</td>\n",
       "      <td>1.727167</td>\n",
       "      <td>0.738972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>1.866841</td>\n",
       "      <td>0.736794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.090700</td>\n",
       "      <td>1.835119</td>\n",
       "      <td>0.739068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>2.150190</td>\n",
       "      <td>0.738163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.059700</td>\n",
       "      <td>2.246275</td>\n",
       "      <td>0.742306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.058000</td>\n",
       "      <td>2.201069</td>\n",
       "      <td>0.740109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.034600</td>\n",
       "      <td>2.383447</td>\n",
       "      <td>0.740071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>2.644301</td>\n",
       "      <td>0.739531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>2.763536</td>\n",
       "      <td>0.739165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: Unnamed: 0, selection1, selection0, emotion. If Unnamed: 0, selection1, selection0, emotion are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: Unnamed: 0, selection1, selection0, emotion. If Unnamed: 0, selection1, selection0, emotion are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: Unnamed: 0, selection1, selection0, emotion. If Unnamed: 0, selection1, selection0, emotion are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: Unnamed: 0, selection1, selection0, emotion. If Unnamed: 0, selection1, selection0, emotion are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: Unnamed: 0, selection1, selection0, emotion. If Unnamed: 0, selection1, selection0, emotion are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: Unnamed: 0, selection1, selection0, emotion. If Unnamed: 0, selection1, selection0, emotion are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: Unnamed: 0, selection1, selection0, emotion. If Unnamed: 0, selection1, selection0, emotion are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: Unnamed: 0, selection1, selection0, emotion. If Unnamed: 0, selection1, selection0, emotion are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: Unnamed: 0, selection1, selection0, emotion. If Unnamed: 0, selection1, selection0, emotion are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: Unnamed: 0, selection1, selection0, emotion. If Unnamed: 0, selection1, selection0, emotion are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: Unnamed: 0, selection1, selection0, emotion. If Unnamed: 0, selection1, selection0, emotion are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: Unnamed: 0, selection1, selection0, emotion. If Unnamed: 0, selection1, selection0, emotion are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: Unnamed: 0, selection1, selection0, emotion. If Unnamed: 0, selection1, selection0, emotion are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: Unnamed: 0, selection1, selection0, emotion. If Unnamed: 0, selection1, selection0, emotion are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: Unnamed: 0, selection1, selection0, emotion. If Unnamed: 0, selection1, selection0, emotion are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-53000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-53000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-53000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-53000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-53000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: Unnamed: 0, selection1, selection0, emotion. If Unnamed: 0, selection1, selection0, emotion are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=53248, training_loss=0.15332539356313646, metrics={'train_runtime': 6198.6757, 'train_samples_per_second': 137.407, 'train_steps_per_second': 8.59, 'total_flos': 2.757340458466877e+16, 'train_loss': 0.15332539356313646, 'epoch': 16.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a17948-a8f7-4450-b2b0-8a7016e91391",
   "metadata": {},
   "source": [
    "出现validation loss 上升情况大多是训练集验证集数据分布不一致，或者训练集过小，未包含验证集中所有情况，\n",
    "也就是过拟合导致的。而解决这种现象可以尝试以下几种策略：\n",
    "1. 增加训练样本增加正则项系数权重，\n",
    "2. 减小过拟合加入早停机制，ValLoss上升几个epoch直接停止\n",
    "3. 采用Focal Loss\n",
    "4. 加入Label Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d6ab3-33ac-4e8e-99ee-3c3f17d71642",
   "metadata": {},
   "source": [
    "# Store Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c30271fe-7ce9-43e8-9e87-de8d6ae2c2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x2adbe240400>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "Z = np.transpose(valStored)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.pcolormesh(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e77d30e-e51a-45a6-9130-83a17c4d2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataLog = pd.DataFrame(trainer.state.log_history)\n",
    "dataLog.to_csv(f'./trainingMetric/trainingInfo-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c90cfec4-96ec-46c8-a99f-3c78b989b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluationIterationResult = pd.DataFrame(np.transpose(valStored))\n",
    "evaluationIterationResult.to_csv(f'./trainingMetric/evaluationSpecificInfo-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd7f330-1477-4119-a9dc-1ebb7acb7665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchEnvWithDataSci",
   "language": "python",
   "name": "pytorchenvwithdatasci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
