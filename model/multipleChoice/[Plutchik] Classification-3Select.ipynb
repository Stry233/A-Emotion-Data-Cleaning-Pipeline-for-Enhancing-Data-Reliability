{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8533643b-5b68-4dec-8a8a-49852c237e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global var set\n",
    "import transformers\n",
    "\n",
    "# model info, change as needed\n",
    "batch_size = 16\n",
    "num_epochs = 16\n",
    "\n",
    "model_checkpoint = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "# model_checkpoint = 'bert-base-uncased'\n",
    "# fileTag = \"original-plutchik-noCombin-v1\"   # original - no Combine    - pure raw\n",
    "fileTag = \"original-plutchik-v1\"             # original - w/ Combine\n",
    "# fileTag = \"clean-noCombin-v1\"                # clean    - no Combine\n",
    "# fileTag = \"clean-v1\"                         # clean    - w/ Combine    - pure clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa38989-ff76-4de1-a82e-6853a1e61687",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Convert dataset to suitable format\n",
    "IMPORTANT: please never run this section again if you have your dataset ready!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a93a9f46-6703-4535-af96-8be1b5b3407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "trainDatasetOriginal = pd.read_csv(f'../../data/csv_version/dev/emotion/allcharlinepairs-{fileTag}.csv')\n",
    "testDatasetOriginal = pd.read_csv(f'../../data/csv_version/test/emotion/allcharlinepairs-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7265a797-adc2-49ed-b237-19abf9e0569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatasetProcessed = DataFrame({'emotion' : trainDatasetOriginal['emotion'],\n",
    "                                   'plutchik' : trainDatasetOriginal['plutchik'],\n",
    "                                  'selection0': pd.concat([trainDatasetOriginal['sentence'][:trainDatasetOriginal.shape[0]//3], trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//3:]]), \n",
    "                                  'selection1': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//3], \n",
    "                                                pd.concat([trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//3 : trainDatasetOriginal.shape[0]//3*2], \n",
    "                                                           trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//3*2:]])]), \n",
    "                                  'selection2': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//3*2], \n",
    "                                                           trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//3*2:]]),\n",
    "                                  'label': pd.Series(0 if x < trainDatasetOriginal.shape[0]//3 else (1 if x < trainDatasetOriginal.shape[0]//3*2 else 2) for x in trainDatasetOriginal.index)}).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "testDatasetProcessed = DataFrame({'emotion' : testDatasetOriginal['emotion'],\n",
    "                                   'plutchik' : testDatasetOriginal['plutchik'],\n",
    "                                  'selection0': pd.concat([testDatasetOriginal['sentence'][:testDatasetOriginal.shape[0]//3], testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//3:]]), \n",
    "                                  'selection1': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//3], \n",
    "                                                pd.concat([testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//3 : testDatasetOriginal.shape[0]//3*2], \n",
    "                                                testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//3*2:]])]), \n",
    "                                  'selection2': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//3*2], \n",
    "                                                           testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//3*2:]]),\n",
    "                                  'label': pd.Series(0 if x < testDatasetOriginal.shape[0]//3 else (1 if x < testDatasetOriginal.shape[0]//3*2 else 2) for x in testDatasetOriginal.index)}).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19e3c334-b371-44ad-b6e1-7161f405b741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>plutchik</th>\n",
       "      <th>selection0</th>\n",
       "      <th>selection1</th>\n",
       "      <th>selection2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['angry', 'impatient', 'none']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Everyday after school we would all get togethe...</td>\n",
       "      <td>Jake was annoyed by it.</td>\n",
       "      <td>It was Remy's first day of college.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['curious', 'content', 'secretative', 'fun', '...</td>\n",
       "      <td>{'joy': 2, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>But security stopped him.</td>\n",
       "      <td>Kim was preparing to go to a gala that night.</td>\n",
       "      <td>Tom called him.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['none', 'compassionate', 'kind', 'Relieved', ...</td>\n",
       "      <td>{'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>He has a tv now but uses it only to watch dvds.</td>\n",
       "      <td>The clerk said yes and Missy was able to go.</td>\n",
       "      <td>Anna slid the eggs onto a plate.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['none', 'annoyed', 'happy', 'failure', 'intri...</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>She planted new ones.</td>\n",
       "      <td>One day a guy she liked said he played piano.</td>\n",
       "      <td>Kija has been researching methods of healthy e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['happy', 'unprepared', 'accomplished', 'none']</td>\n",
       "      <td>{'joy': 1, 'trust': 1, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>The luggage requirement meant Dan had to pack ...</td>\n",
       "      <td>He went on to run for an hour around his neigh...</td>\n",
       "      <td>While watching the news, they heard there was ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12410</th>\n",
       "      <td>['anxious', 'safe', 'relieved', 'none']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Luckily she had her phone and she used the GPS...</td>\n",
       "      <td>It was brown and white.</td>\n",
       "      <td>Jenny never loved to study.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12411</th>\n",
       "      <td>['gluttonous', 'remorse', 'guilty', 'stupid']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Jason ate an entire carton of ice cream.</td>\n",
       "      <td>The beef upset her intestines.</td>\n",
       "      <td>Henry is at work.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12412</th>\n",
       "      <td>['excited', 'none', 'Happy']</td>\n",
       "      <td>{'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>My friend Zach decided to take us to a race tr...</td>\n",
       "      <td>We were staying at my Pop's house on vacation.</td>\n",
       "      <td>She was eating salsa while wearing a beautiful...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12413</th>\n",
       "      <td>['none', 'nervous', 'anxious']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>He was scared of playing his first game.</td>\n",
       "      <td>But she did not let me because she wants me to...</td>\n",
       "      <td>Unfortunately it was past 11 AM.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12414</th>\n",
       "      <td>['excited', 'elated', 'none']</td>\n",
       "      <td>{'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>She thought she was going to be a hockey star ...</td>\n",
       "      <td>Eric loved ice cream.</td>\n",
       "      <td>I used to cook but am now disabled.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12415 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 emotion  \\\n",
       "0                         ['angry', 'impatient', 'none']   \n",
       "1      ['curious', 'content', 'secretative', 'fun', '...   \n",
       "2      ['none', 'compassionate', 'kind', 'Relieved', ...   \n",
       "3      ['none', 'annoyed', 'happy', 'failure', 'intri...   \n",
       "4        ['happy', 'unprepared', 'accomplished', 'none']   \n",
       "...                                                  ...   \n",
       "12410            ['anxious', 'safe', 'relieved', 'none']   \n",
       "12411      ['gluttonous', 'remorse', 'guilty', 'stupid']   \n",
       "12412                       ['excited', 'none', 'Happy']   \n",
       "12413                     ['none', 'nervous', 'anxious']   \n",
       "12414                      ['excited', 'elated', 'none']   \n",
       "\n",
       "                                                plutchik  \\\n",
       "0      {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "1      {'joy': 2, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "2      {'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "3      {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "4      {'joy': 1, 'trust': 1, 'fear': 1, 'surprise': ...   \n",
       "...                                                  ...   \n",
       "12410  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "12411  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "12412  {'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "12413  {'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...   \n",
       "12414  {'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "\n",
       "                                              selection0  \\\n",
       "0      Everyday after school we would all get togethe...   \n",
       "1                              But security stopped him.   \n",
       "2        He has a tv now but uses it only to watch dvds.   \n",
       "3                                  She planted new ones.   \n",
       "4      The luggage requirement meant Dan had to pack ...   \n",
       "...                                                  ...   \n",
       "12410  Luckily she had her phone and she used the GPS...   \n",
       "12411           Jason ate an entire carton of ice cream.   \n",
       "12412  My friend Zach decided to take us to a race tr...   \n",
       "12413           He was scared of playing his first game.   \n",
       "12414  She thought she was going to be a hockey star ...   \n",
       "\n",
       "                                              selection1  \\\n",
       "0                                Jake was annoyed by it.   \n",
       "1          Kim was preparing to go to a gala that night.   \n",
       "2           The clerk said yes and Missy was able to go.   \n",
       "3          One day a guy she liked said he played piano.   \n",
       "4      He went on to run for an hour around his neigh...   \n",
       "...                                                  ...   \n",
       "12410                            It was brown and white.   \n",
       "12411                     The beef upset her intestines.   \n",
       "12412     We were staying at my Pop's house on vacation.   \n",
       "12413  But she did not let me because she wants me to...   \n",
       "12414                              Eric loved ice cream.   \n",
       "\n",
       "                                              selection2  label  \n",
       "0                    It was Remy's first day of college.      1  \n",
       "1                                        Tom called him.      2  \n",
       "2                       Anna slid the eggs onto a plate.      1  \n",
       "3      Kija has been researching methods of healthy e...      1  \n",
       "4      While watching the news, they heard there was ...      0  \n",
       "...                                                  ...    ...  \n",
       "12410                        Jenny never loved to study.      0  \n",
       "12411                                  Henry is at work.      0  \n",
       "12412  She was eating salsa while wearing a beautiful...      0  \n",
       "12413                   Unfortunately it was past 11 AM.      0  \n",
       "12414                I used to cook but am now disabled.      1  \n",
       "\n",
       "[12415 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDatasetProcessed.to_csv(f'./dataset/3Select-{fileTag}-train.csv')\n",
    "trainDatasetProcessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b770299d-567d-46e2-b928-8ee31a341c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>plutchik</th>\n",
       "      <th>selection0</th>\n",
       "      <th>selection1</th>\n",
       "      <th>selection2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['none', 'unhappy', 'responsible', 'confused']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>Her amateur record wasn't that good.</td>\n",
       "      <td>Cindy was being noisy in her apartment.</td>\n",
       "      <td>Unfortunately it worked too well for they neve...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['none', 'determined', 'confident']</td>\n",
       "      <td>{'joy': 0, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Jessie didn't buy her mother a gift.</td>\n",
       "      <td>Lamie Mcramie knew it had to be done.</td>\n",
       "      <td>The woman hushed the man.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['irritated', 'angry', 'sad', 'annoyed', 'impa...</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Candy had finally burned a ham.</td>\n",
       "      <td>Andy no longer has back problems after a few w...</td>\n",
       "      <td>She was on the highway and getting kind of irr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Worried', 'hopeful', 'nervous', 'surprised',...</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>She was nervous to ask for money.</td>\n",
       "      <td>He didn't think he was getting paid fairly.</td>\n",
       "      <td>He ended up signing up for tennis instead.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['energetic', 'happy']</td>\n",
       "      <td>{'joy': 3, 'trust': 3, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Gary built a stronger chicken coop to keep the...</td>\n",
       "      <td>She would post pictures on social media whenev...</td>\n",
       "      <td>Rick stood in front of the oven watching the p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11845</th>\n",
       "      <td>['resentment', 'angry', 'content']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>I haven't gone back to Virginia Beach since.</td>\n",
       "      <td>Aubrey's grandmother had sent her a gift.</td>\n",
       "      <td>After a few hours, snow began to fill my yard ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11846</th>\n",
       "      <td>['curious', 'none', 'surprised', 'embaressed',...</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>His cat came inside and jumped into his lap.</td>\n",
       "      <td>I went near to her and ask where does she lives.</td>\n",
       "      <td>Emily was fascinated with the stamp on the let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11847</th>\n",
       "      <td>['curious', 'Curious', 'hungry']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>He got a shovel and started digging.</td>\n",
       "      <td>He wanted to have a taste.</td>\n",
       "      <td>We were very hot and not pleased with the serv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11848</th>\n",
       "      <td>['none', 'great and happy', 'talented', 'compe...</td>\n",
       "      <td>{'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Debbie was a devout vegetarian.</td>\n",
       "      <td>She really, really, really had to go pee.</td>\n",
       "      <td>Tom was a professional golfer.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11849</th>\n",
       "      <td>['scared', 'Excited', 'excited']</td>\n",
       "      <td>{'joy': 2, 'trust': 0, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>Everyone else pitched in for gas.</td>\n",
       "      <td>He persuaded his parents to let him go on the ...</td>\n",
       "      <td>Bill let go of his baby and sold his Mustang.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11850 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 emotion  \\\n",
       "0         ['none', 'unhappy', 'responsible', 'confused']   \n",
       "1                    ['none', 'determined', 'confident']   \n",
       "2      ['irritated', 'angry', 'sad', 'annoyed', 'impa...   \n",
       "3      ['Worried', 'hopeful', 'nervous', 'surprised',...   \n",
       "4                                 ['energetic', 'happy']   \n",
       "...                                                  ...   \n",
       "11845                 ['resentment', 'angry', 'content']   \n",
       "11846  ['curious', 'none', 'surprised', 'embaressed',...   \n",
       "11847                   ['curious', 'Curious', 'hungry']   \n",
       "11848  ['none', 'great and happy', 'talented', 'compe...   \n",
       "11849                   ['scared', 'Excited', 'excited']   \n",
       "\n",
       "                                                plutchik  \\\n",
       "0      {'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...   \n",
       "1      {'joy': 0, 'trust': 1, 'fear': 0, 'surprise': ...   \n",
       "2      {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "3      {'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...   \n",
       "4      {'joy': 3, 'trust': 3, 'fear': 0, 'surprise': ...   \n",
       "...                                                  ...   \n",
       "11845  {'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...   \n",
       "11846  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "11847  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "11848  {'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...   \n",
       "11849  {'joy': 2, 'trust': 0, 'fear': 1, 'surprise': ...   \n",
       "\n",
       "                                              selection0  \\\n",
       "0                   Her amateur record wasn't that good.   \n",
       "1                   Jessie didn't buy her mother a gift.   \n",
       "2                        Candy had finally burned a ham.   \n",
       "3                      She was nervous to ask for money.   \n",
       "4      Gary built a stronger chicken coop to keep the...   \n",
       "...                                                  ...   \n",
       "11845       I haven't gone back to Virginia Beach since.   \n",
       "11846       His cat came inside and jumped into his lap.   \n",
       "11847               He got a shovel and started digging.   \n",
       "11848                    Debbie was a devout vegetarian.   \n",
       "11849                  Everyone else pitched in for gas.   \n",
       "\n",
       "                                              selection1  \\\n",
       "0                Cindy was being noisy in her apartment.   \n",
       "1                  Lamie Mcramie knew it had to be done.   \n",
       "2      Andy no longer has back problems after a few w...   \n",
       "3            He didn't think he was getting paid fairly.   \n",
       "4      She would post pictures on social media whenev...   \n",
       "...                                                  ...   \n",
       "11845          Aubrey's grandmother had sent her a gift.   \n",
       "11846   I went near to her and ask where does she lives.   \n",
       "11847                         He wanted to have a taste.   \n",
       "11848          She really, really, really had to go pee.   \n",
       "11849  He persuaded his parents to let him go on the ...   \n",
       "\n",
       "                                              selection2  label  \n",
       "0      Unfortunately it worked too well for they neve...      2  \n",
       "1                              The woman hushed the man.      1  \n",
       "2      She was on the highway and getting kind of irr...      2  \n",
       "3             He ended up signing up for tennis instead.      0  \n",
       "4      Rick stood in front of the oven watching the p...      1  \n",
       "...                                                  ...    ...  \n",
       "11845  After a few hours, snow began to fill my yard ...      0  \n",
       "11846  Emily was fascinated with the stamp on the let...      1  \n",
       "11847  We were very hot and not pleased with the serv...      1  \n",
       "11848                     Tom was a professional golfer.      2  \n",
       "11849      Bill let go of his baby and sold his Mustang.      1  \n",
       "\n",
       "[11850 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDatasetProcessed.to_csv(f'./dataset/3Select-{fileTag}-test.csv')\n",
    "testDatasetProcessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7283c1-d83e-4369-b5e4-6c2e09d654ac",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "828a5092-83e6-4580-99c9-bd9ec434708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "05151e3b-0bec-44f4-bf0a-ac58cddbf838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-db1979088de98320\n",
      "Reusing dataset csv (C:\\Users\\JAM_0\\.cache\\huggingface\\datasets\\csv\\default-db1979088de98320\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a741756c0a014c6cae71d7dc54b9209e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('csv', data_files={'train': f'./dataset/3Select-{fileTag}-train.csv', \n",
    "                                           'test': f'./dataset/3Select-{fileTag}-test.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d776c270-7752-4445-ba6c-eb078f71eccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'emotion', 'plutchik', 'selection0', 'selection1', 'selection2', 'label'],\n",
       "        num_rows: 12415\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'emotion', 'plutchik', 'selection0', 'selection1', 'selection2', 'label'],\n",
       "        num_rows: 11850\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a1c79159-f795-4d02-b052-94f04286d53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 0,\n",
       " 'emotion': \"['none', 'unhappy', 'responsible', 'confused']\",\n",
       " 'plutchik': \"{'joy': 0, 'trust': 0, 'fear': 1, 'surprise': 0, 'sadness': 0, 'disgust': 0, 'anger': 0, 'anticipation': 1}\",\n",
       " 'selection0': \"Her amateur record wasn't that good.\",\n",
       " 'selection1': 'Cindy was being noisy in her apartment.',\n",
       " 'selection2': 'Unfortunately it worked too well for they never found the volunteer!',\n",
       " 'label': 2}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1f6ad67d-b4cb-4f65-a9cb-d2d665deec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_one(example):\n",
    "    print(f\"Context: {example['plutchik']}\")\n",
    "    print(f\"  A - {example['selection0']}\")\n",
    "    print(f\"  B - {example['selection1']}\")\n",
    "    print(f\"  C - {example['selection2']}\")\n",
    "    print(f\"\\nGround truth: option {['A', 'B', 'C'][example['label']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "15cd7cfb-748a-4fe7-8152-7debf6a65ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': 0, 'sadness': 0, 'disgust': 1, 'anger': 2, 'anticipation': 0}\n",
      "  A - Everyday after school we would all get together and play football.\n",
      "  B - Jake was annoyed by it.\n",
      "  C - It was Remy's first day of college.\n",
      "\n",
      "Ground truth: option B\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da93346-1037-41ed-b67d-91877fa8c0ec",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3da78c12-9aff-4beb-a006-e287bbf61023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/vocab.txt from cache at C:\\Users\\JAM_0/.cache\\huggingface\\transformers\\ba377304984dc63e3ede0e23a938bbbf04d5c3835b66d5bb48343aecca188429.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/tokenizer_config.json from cache at C:\\Users\\JAM_0/.cache\\huggingface\\transformers\\81e970e5e6ec68be12da0f8f3b2f2469c78d579282299a2ea65b4b7441719107.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/distilbert-base-cased/resolve/main/config.json from cache at C:\\Users\\JAM_0/.cache\\huggingface\\transformers\\ebe1ea24d11aa664488b8de5b21e33989008ca78f207d4e30ec6350b693f073f.302bfd1b5e031cc1b17796e0b6e5b242ba2045d31d00f97589e12b458ebff27a\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if model_checkpoint != 'distilbert-base-uncased-finetuned-sst-2-english':\n",
    "    from transformers import AutoTokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "else:\n",
    "    from transformers import DistilBertTokenizer, DistilBertForMultipleChoice\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "caffe397-a65d-478f-b966-7b910fb2edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "selectionList = [\"selection0\", \"selection1\", \"selection2\"]\n",
    "weightRemap = [\"NOT \", \"LITTLE \", \"\", \"VERY \", \"ABSOLUTELY \"]\n",
    "def preprocess_function(examples):\n",
    "    # Repeat each first sentence four times to go with the four possibilities of second sentences.\n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(context.strip(\"[\").strip(\"]\").replace('\\'', '')) ]*2 for context in examples[\"emotion\"] ]\n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(context.strip(\"[\").strip(\"]\").replace('\\\"', '')) ]*2 for context in examples[\"plutchik\"] ]\n",
    "    first_sentences = [[\"The following sentences contain emotions: {}\".format(\", \".join([weightRemap[int(eachCaseWeight.replace(\"]\", \"\").replace(\"[\", \"\").replace(\"}\", \"\").replace(\"{\", \"\").replace(\"\\\"\", \"\").replace(\"\\'\", \"\"))] \n",
    "                                                        + eachCaseEmotionType.replace(\"]\", \"\").replace(\"[\", \"\").replace(\"}\", \"\").replace(\"{\", \"\").replace(\"\\\"\", \"\").replace(\"\\'\", \"\").strip()\n",
    "                        for eachCaseWeight, eachCaseEmotionType in \n",
    "                        zip([re.split(':|,',eachEmotionCombination)[1::2] for eachEmotionCombination in examples[\"plutchik\"]][eventIndex], \n",
    "                           [re.split(':|,',eachEmotionCombination)[::2] for eachEmotionCombination in examples[\"plutchik\"]][eventIndex])]))]*3 for eventIndex in \n",
    "                           range(len([re.split(':|,',eachEmotionCombination)[1::2] for eachEmotionCombination in examples[\"plutchik\"]]))]\n",
    "    \n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(', '.join([(weightRemap[eachEmotion[1]] + \" \" +eachEmotion[0]).strip() \n",
    "    #                    for eachEmotion in ast.literal_eval(context).items()]))]*2 \n",
    "    #                    for context in examples[\"plutchik\"]]\n",
    "    # Grab all second sentences possible for each context.\n",
    "    second_sentences = [[examples[selection][index] for selection in selectionList]for index in range(len(examples['selection0']))]\n",
    "\n",
    "    # Flatten everything\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "    \n",
    "    # Tokenize\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "    # Un-flatten\n",
    "    # print(tokenized_examples.items())\n",
    "    return {k: [v[i:i+3] for i in range(0, len(v), 3)] for k, v in tokenized_examples.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0afb4841-ab69-4b91-8859-fd249badb923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 3 [53, 46, 51]\n"
     ]
    }
   ],
   "source": [
    "examples = dataset[\"train\"][:5]\n",
    "features = preprocess_function(examples)\n",
    "print(len(features[\"input_ids\"]), len(features[\"input_ids\"][0]), [len(x) for x in features[\"input_ids\"][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "903e2891-0e3d-4e87-b98a-727eaf36417a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] The following sentences contain emotions : NOT joy, NOT trust, NOT fear, NOT surprise, NOT sadness, LITTLE disgust, anger, NOT anticipation [SEP] Everyday after school we would all get together and play football. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : NOT joy, NOT trust, NOT fear, NOT surprise, NOT sadness, LITTLE disgust, anger, NOT anticipation [SEP] Jake was annoyed by it. [SEP]',\n",
       " \"[CLS] The following sentences contain emotions : NOT joy, NOT trust, NOT fear, NOT surprise, NOT sadness, LITTLE disgust, anger, NOT anticipation [SEP] It was Remy's first day of college. [SEP]\",\n",
       " '[CLS] The following sentences contain emotions : joy, NOT trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, anticipation [SEP] But security stopped him. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : joy, NOT trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, anticipation [SEP] Kim was preparing to go to a gala that night. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : joy, NOT trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, anticipation [SEP] Tom called him. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : LITTLE joy, NOT trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation [SEP] He has a tv now but uses it only to watch dvds. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : LITTLE joy, NOT trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation [SEP] The clerk said yes and Missy was able to go. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : LITTLE joy, NOT trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation [SEP] Anna slid the eggs onto a plate. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : NOT joy, NOT trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, LITTLE anticipation [SEP] She planted new ones. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : NOT joy, NOT trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, LITTLE anticipation [SEP] One day a guy she liked said he played piano. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : NOT joy, NOT trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, LITTLE anticipation [SEP] Kija has been researching methods of healthy eating. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : LITTLE joy, LITTLE trust, LITTLE fear, NOT surprise, LITTLE sadness, NOT disgust, NOT anger, NOT anticipation [SEP] The luggage requirement meant Dan had to pack light. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : LITTLE joy, LITTLE trust, LITTLE fear, NOT surprise, LITTLE sadness, NOT disgust, NOT anger, NOT anticipation [SEP] He went on to run for an hour around his neighborhood. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : LITTLE joy, LITTLE trust, LITTLE fear, NOT surprise, LITTLE sadness, NOT disgust, NOT anger, NOT anticipation [SEP] While watching the news, they heard there was a tornado coming. [SEP]']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(features[\"input_ids\"][a][i]) for a in range(5) for i in range(3) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a286ba6-cb84-4619-b842-780124d26a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d81729abb7e47e680cb34f8728ceade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01bdf6652564947a75c1afbb143e668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7706d875-3a89-4e52-9f08-c77256b621ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-cased/resolve/main/config.json from cache at C:\\Users\\JAM_0/.cache\\huggingface\\transformers\\ebe1ea24d11aa664488b8de5b21e33989008ca78f207d4e30ec6350b693f073f.302bfd1b5e031cc1b17796e0b6e5b242ba2045d31d00f97589e12b458ebff27a\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-cased/resolve/main/pytorch_model.bin from cache at C:\\Users\\JAM_0/.cache\\huggingface\\transformers\\9c9f39769dba4c5fe379b4bc82973eb01297bd607954621434eb9f1bc85a23a0.06b428c87335c1bb22eae46fdab31c8286efa0aa09e898a7ac42ddf5c3f5dc19\n",
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForMultipleChoice: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForMultipleChoice were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "if model_checkpoint != 'distilbert-base-uncased-finetuned-sst-2-english':\n",
    "    from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "    model = AutoModelForMultipleChoice.from_pretrained(model_checkpoint)\n",
    "else:\n",
    "    from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "    from transformers import DistilBertTokenizer, DistilBertForMultipleChoice\n",
    "    import torch\n",
    "    model = DistilBertForMultipleChoice.from_pretrained(\"distilbert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2cd7be65-ebd8-43db-bcbf-a87d7e2342e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-emotionCommonsense\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=5e-6, # for bert-base\n",
    "    # learning_rate=1e-3,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2737e04e-19c2-407d-8ce1-06b675f208c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [[{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        # Un-flatten\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        # Add back labels\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03a0ec05-de5e-434f-b07c-63212e7c7f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_keys = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "features = [{k: v for k, v in encoded_datasets[\"train\"][i].items() if k in accepted_keys} for i in range(10)]\n",
    "batch = DataCollatorForMultipleChoice(tokenizer)(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45f7f26c-04bb-42ae-8627-897ced69888e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] The following sentences contain emotions : LITTLE joy, NOT trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation [SEP] I had to carry around a lot of cash, but I enjoyed myself. [SEP] [PAD] [PAD] [PAD] [PAD]',\n",
       " \"[CLS] The following sentences contain emotions : LITTLE joy, NOT trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation [SEP] Lou's big brother always beat him at backgammon. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\",\n",
       " '[CLS] The following sentences contain emotions : LITTLE joy, NOT trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation [SEP] Liz had runny mashed potatoes and ate them anyway. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(batch[\"input_ids\"][8][i].tolist()) for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4b55256-30fa-4e30-a3a4-66fe1114b941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: {'joy': 1, 'trust': 0, 'fear': 0, 'surprise': 0, 'sadness': 0, 'disgust': 0, 'anger': 0, 'anticipation': 0}\n",
      "  A - I had to carry around a lot of cash, but I enjoyed myself.\n",
      "  B - Lou's big brother always beat him at backgammon.\n",
      "  C - Liz had runny mashed potatoes and ate them anyway.\n",
      "\n",
      "Ground truth: option A\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8305d3-8dc9-4d0f-8628-f51dc356c2d2",
   "metadata": {},
   "source": [
    "# Trainer Defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b707863a-bc16-43b0-b633-c7ffb4fa72e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "valStored = []\n",
    "def compute_metrics(eval_predictions):\n",
    "    predictions, label_ids = eval_predictions\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    valStored.append((preds != label_ids).astype(np.float32));\n",
    "    return {\"accuracy\": (preds == label_ids).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b115c1ba-323a-47d5-bb9d-55de985f13b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_datasets[\"train\"],\n",
    "    eval_dataset=encoded_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a5e3430-bbd6-484d-8a8d-9cbcdba37d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, selection1, selection0, plutchik, Unnamed: 0, selection2. If emotion, selection1, selection0, plutchik, Unnamed: 0, selection2 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "C:\\Python\\miniconda3\\envs\\pytorchEnvWithDataSci\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 12415\n",
      "  Num Epochs = 16\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12416\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12416' max='12416' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12416/12416 24:22, Epoch 16/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.099700</td>\n",
       "      <td>1.098473</td>\n",
       "      <td>0.342194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.097800</td>\n",
       "      <td>1.096641</td>\n",
       "      <td>0.345823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.081000</td>\n",
       "      <td>0.983222</td>\n",
       "      <td>0.481857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.961000</td>\n",
       "      <td>0.932494</td>\n",
       "      <td>0.516203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.925400</td>\n",
       "      <td>0.915431</td>\n",
       "      <td>0.543207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.878100</td>\n",
       "      <td>0.901640</td>\n",
       "      <td>0.548186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.849700</td>\n",
       "      <td>0.890571</td>\n",
       "      <td>0.565148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.812000</td>\n",
       "      <td>0.898224</td>\n",
       "      <td>0.565063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.784600</td>\n",
       "      <td>0.886715</td>\n",
       "      <td>0.573840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.753200</td>\n",
       "      <td>0.891210</td>\n",
       "      <td>0.579747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.735700</td>\n",
       "      <td>0.896998</td>\n",
       "      <td>0.581941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.710100</td>\n",
       "      <td>0.917884</td>\n",
       "      <td>0.583460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.707100</td>\n",
       "      <td>0.913085</td>\n",
       "      <td>0.585401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.673000</td>\n",
       "      <td>0.925758</td>\n",
       "      <td>0.583207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.675300</td>\n",
       "      <td>0.930610</td>\n",
       "      <td>0.587511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.654000</td>\n",
       "      <td>0.933409</td>\n",
       "      <td>0.588523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, selection1, selection0, plutchik, Unnamed: 0, selection2. If emotion, selection1, selection0, plutchik, Unnamed: 0, selection2 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11850\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, selection1, selection0, plutchik, Unnamed: 0, selection2. If emotion, selection1, selection0, plutchik, Unnamed: 0, selection2 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11850\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, selection1, selection0, plutchik, Unnamed: 0, selection2. If emotion, selection1, selection0, plutchik, Unnamed: 0, selection2 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11850\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, selection1, selection0, plutchik, Unnamed: 0, selection2. If emotion, selection1, selection0, plutchik, Unnamed: 0, selection2 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11850\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, selection1, selection0, plutchik, Unnamed: 0, selection2. If emotion, selection1, selection0, plutchik, Unnamed: 0, selection2 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11850\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, selection1, selection0, plutchik, Unnamed: 0, selection2. If emotion, selection1, selection0, plutchik, Unnamed: 0, selection2 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11850\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, selection1, selection0, plutchik, Unnamed: 0, selection2. If emotion, selection1, selection0, plutchik, Unnamed: 0, selection2 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11850\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, selection1, selection0, plutchik, Unnamed: 0, selection2. If emotion, selection1, selection0, plutchik, Unnamed: 0, selection2 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11850\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, selection1, selection0, plutchik, Unnamed: 0, selection2. If emotion, selection1, selection0, plutchik, Unnamed: 0, selection2 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11850\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, selection1, selection0, plutchik, Unnamed: 0, selection2. If emotion, selection1, selection0, plutchik, Unnamed: 0, selection2 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11850\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, selection1, selection0, plutchik, Unnamed: 0, selection2. If emotion, selection1, selection0, plutchik, Unnamed: 0, selection2 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11850\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, selection1, selection0, plutchik, Unnamed: 0, selection2. If emotion, selection1, selection0, plutchik, Unnamed: 0, selection2 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11850\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, selection1, selection0, plutchik, Unnamed: 0, selection2. If emotion, selection1, selection0, plutchik, Unnamed: 0, selection2 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11850\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, selection1, selection0, plutchik, Unnamed: 0, selection2. If emotion, selection1, selection0, plutchik, Unnamed: 0, selection2 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11850\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, selection1, selection0, plutchik, Unnamed: 0, selection2. If emotion, selection1, selection0, plutchik, Unnamed: 0, selection2 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11850\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-12000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-12000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-12000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-12000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-12000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, selection1, selection0, plutchik, Unnamed: 0, selection2. If emotion, selection1, selection0, plutchik, Unnamed: 0, selection2 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11850\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=12416, training_loss=0.8340606738611595, metrics={'train_runtime': 1462.9342, 'train_samples_per_second': 135.782, 'train_steps_per_second': 8.487, 'total_flos': 9777428537608368.0, 'train_loss': 0.8340606738611595, 'epoch': 16.0})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a17948-a8f7-4450-b2b0-8a7016e91391",
   "metadata": {},
   "source": [
    "出现validation loss 上升情况大多是训练集验证集数据分布不一致，或者训练集过小，未包含验证集中所有情况，\n",
    "也就是过拟合导致的。而解决这种现象可以尝试以下几种策略：\n",
    "1. 增加训练样本增加正则项系数权重，\n",
    "2. 减小过拟合加入早停机制，ValLoss上升几个epoch直接停止\n",
    "3. 采用Focal Loss\n",
    "4. 加入Label Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d6ab3-33ac-4e8e-99ee-3c3f17d71642",
   "metadata": {},
   "source": [
    "# Store Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c30271fe-7ce9-43e8-9e87-de8d6ae2c2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x1847431e100>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "Z = np.transpose(valStored)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.pcolormesh(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5e77d30e-e51a-45a6-9130-83a17c4d2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "if model_checkpoint == 'distilbert-base-uncased-finetuned-sst-2-english':\n",
    "    model_checkpoint = 'distilbert-base'\n",
    "dataLog = pd.DataFrame(trainer.state.log_history)\n",
    "dataLog.to_csv(f'./trainingMetric/[Plutchik] 3Select/TI-{model_checkpoint}-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c90cfec4-96ec-46c8-a99f-3c78b989b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluationIterationResult = pd.DataFrame(np.transpose(valStored))\n",
    "evaluationIterationResult.to_csv(f'./trainingMetric/[Plutchik] 3Select/ESI-{model_checkpoint}-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd7f330-1477-4119-a9dc-1ebb7acb7665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchEnvWithDataSci",
   "language": "python",
   "name": "pytorchenvwithdatasci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
