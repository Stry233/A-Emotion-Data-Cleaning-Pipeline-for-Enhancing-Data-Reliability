{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8533643b-5b68-4dec-8a8a-49852c237e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global var set\n",
    "import transformers\n",
    "\n",
    "# model info, change as needed\n",
    "batch_size = 16\n",
    "num_epochs = 16\n",
    "\n",
    "model_checkpoint = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "# model_checkpoint = 'bert-base-uncased'\n",
    "# fileTag = \"original-plutchik-noCombin-v1\"   # original - no Combine    - pure raw\n",
    "# fileTag = \"original-plutchik-v1\"             # original - w/ Combine\n",
    "# fileTag = \"clean-noCombin-v1\"                # clean    - no Combine\n",
    "fileTag = \"clean-v1\"                         # clean    - w/ Combine    - pure clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa38989-ff76-4de1-a82e-6853a1e61687",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Convert dataset to suitable format\n",
    "IMPORTANT: please never run this section again if you have your dataset ready!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a93a9f46-6703-4535-af96-8be1b5b3407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "trainDatasetOriginal = pd.read_csv(f'../../data/csv_version/dev/emotion/allcharlinepairs-{fileTag}.csv')\n",
    "testDatasetOriginal = pd.read_csv(f'../../data/csv_version/test/emotion/allcharlinepairs-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7265a797-adc2-49ed-b237-19abf9e0569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatasetProcessed = DataFrame({'emotion' : trainDatasetOriginal['emotion'],\n",
    "                                   'plutchik' : trainDatasetOriginal['plutchik'],\n",
    "                                  'selection0': pd.concat([trainDatasetOriginal['sentence'][:trainDatasetOriginal.shape[0]//3], trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//3:]]), \n",
    "                                  'selection1': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//3], \n",
    "                                                pd.concat([trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//3 : trainDatasetOriginal.shape[0]//3*2], \n",
    "                                                           trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//3*2:]])]), \n",
    "                                  'selection2': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//3*2], \n",
    "                                                           trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//3*2:]]),\n",
    "                                  'label': pd.Series(0 if x < trainDatasetOriginal.shape[0]//3 else (1 if x < trainDatasetOriginal.shape[0]//3*2 else 2) for x in trainDatasetOriginal.index)}).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "testDatasetProcessed = DataFrame({'emotion' : testDatasetOriginal['emotion'],\n",
    "                                   'plutchik' : testDatasetOriginal['plutchik'],\n",
    "                                  'selection0': pd.concat([testDatasetOriginal['sentence'][:testDatasetOriginal.shape[0]//3], testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//3:]]), \n",
    "                                  'selection1': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//3], \n",
    "                                                pd.concat([testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//3 : testDatasetOriginal.shape[0]//3*2], \n",
    "                                                testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//3*2:]])]), \n",
    "                                  'selection2': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//3*2], \n",
    "                                                           testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//3*2:]]),\n",
    "                                  'label': pd.Series(0 if x < testDatasetOriginal.shape[0]//3 else (1 if x < testDatasetOriginal.shape[0]//3*2 else 2) for x in testDatasetOriginal.index)}).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19e3c334-b371-44ad-b6e1-7161f405b741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>plutchik</th>\n",
       "      <th>selection0</th>\n",
       "      <th>selection1</th>\n",
       "      <th>selection2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['angry', 'impatient', 'none']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Everyday after school we would all get togethe...</td>\n",
       "      <td>Jake was annoyed by it.</td>\n",
       "      <td>It was Remy's first day of college.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['curious', 'content', 'secretative', 'fun', '...</td>\n",
       "      <td>{'joy': 2, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>But security stopped him.</td>\n",
       "      <td>Kim was preparing to go to a gala that night.</td>\n",
       "      <td>Tom called him.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['none', 'compassionate', 'kind', 'Relieved', ...</td>\n",
       "      <td>{'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>He has a tv now but uses it only to watch dvds.</td>\n",
       "      <td>The clerk said yes and Missy was able to go.</td>\n",
       "      <td>Anna slid the eggs onto a plate.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['none', 'annoyed', 'happy', 'failure', 'intri...</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>She planted new ones.</td>\n",
       "      <td>One day a guy she liked said he played piano.</td>\n",
       "      <td>Kija has been researching methods of healthy e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['happy', 'unprepared', 'accomplished', 'none']</td>\n",
       "      <td>{'joy': 1, 'trust': 1, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>The luggage requirement meant Dan had to pack ...</td>\n",
       "      <td>He went on to run for an hour around his neigh...</td>\n",
       "      <td>While watching the news, they heard there was ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12410</th>\n",
       "      <td>['anxious', 'safe', 'relieved', 'none']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Luckily she had her phone and she used the GPS...</td>\n",
       "      <td>It was brown and white.</td>\n",
       "      <td>Jenny never loved to study.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12411</th>\n",
       "      <td>['gluttonous', 'remorse', 'guilty', 'stupid']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Jason ate an entire carton of ice cream.</td>\n",
       "      <td>The beef upset her intestines.</td>\n",
       "      <td>Henry is at work.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12412</th>\n",
       "      <td>['excited', 'none', 'Happy']</td>\n",
       "      <td>{'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>My friend Zach decided to take us to a race tr...</td>\n",
       "      <td>We were staying at my Pop's house on vacation.</td>\n",
       "      <td>She was eating salsa while wearing a beautiful...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12413</th>\n",
       "      <td>['none', 'nervous', 'anxious']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>He was scared of playing his first game.</td>\n",
       "      <td>But she did not let me because she wants me to...</td>\n",
       "      <td>Unfortunately it was past 11 AM.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12414</th>\n",
       "      <td>['excited', 'elated', 'none']</td>\n",
       "      <td>{'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>She thought she was going to be a hockey star ...</td>\n",
       "      <td>Eric loved ice cream.</td>\n",
       "      <td>I used to cook but am now disabled.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12415 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 emotion  \\\n",
       "0                         ['angry', 'impatient', 'none']   \n",
       "1      ['curious', 'content', 'secretative', 'fun', '...   \n",
       "2      ['none', 'compassionate', 'kind', 'Relieved', ...   \n",
       "3      ['none', 'annoyed', 'happy', 'failure', 'intri...   \n",
       "4        ['happy', 'unprepared', 'accomplished', 'none']   \n",
       "...                                                  ...   \n",
       "12410            ['anxious', 'safe', 'relieved', 'none']   \n",
       "12411      ['gluttonous', 'remorse', 'guilty', 'stupid']   \n",
       "12412                       ['excited', 'none', 'Happy']   \n",
       "12413                     ['none', 'nervous', 'anxious']   \n",
       "12414                      ['excited', 'elated', 'none']   \n",
       "\n",
       "                                                plutchik  \\\n",
       "0      {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "1      {'joy': 2, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "2      {'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "3      {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "4      {'joy': 1, 'trust': 1, 'fear': 1, 'surprise': ...   \n",
       "...                                                  ...   \n",
       "12410  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "12411  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "12412  {'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "12413  {'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...   \n",
       "12414  {'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "\n",
       "                                              selection0  \\\n",
       "0      Everyday after school we would all get togethe...   \n",
       "1                              But security stopped him.   \n",
       "2        He has a tv now but uses it only to watch dvds.   \n",
       "3                                  She planted new ones.   \n",
       "4      The luggage requirement meant Dan had to pack ...   \n",
       "...                                                  ...   \n",
       "12410  Luckily she had her phone and she used the GPS...   \n",
       "12411           Jason ate an entire carton of ice cream.   \n",
       "12412  My friend Zach decided to take us to a race tr...   \n",
       "12413           He was scared of playing his first game.   \n",
       "12414  She thought she was going to be a hockey star ...   \n",
       "\n",
       "                                              selection1  \\\n",
       "0                                Jake was annoyed by it.   \n",
       "1          Kim was preparing to go to a gala that night.   \n",
       "2           The clerk said yes and Missy was able to go.   \n",
       "3          One day a guy she liked said he played piano.   \n",
       "4      He went on to run for an hour around his neigh...   \n",
       "...                                                  ...   \n",
       "12410                            It was brown and white.   \n",
       "12411                     The beef upset her intestines.   \n",
       "12412     We were staying at my Pop's house on vacation.   \n",
       "12413  But she did not let me because she wants me to...   \n",
       "12414                              Eric loved ice cream.   \n",
       "\n",
       "                                              selection2  label  \n",
       "0                    It was Remy's first day of college.      1  \n",
       "1                                        Tom called him.      2  \n",
       "2                       Anna slid the eggs onto a plate.      1  \n",
       "3      Kija has been researching methods of healthy e...      1  \n",
       "4      While watching the news, they heard there was ...      0  \n",
       "...                                                  ...    ...  \n",
       "12410                        Jenny never loved to study.      0  \n",
       "12411                                  Henry is at work.      0  \n",
       "12412  She was eating salsa while wearing a beautiful...      0  \n",
       "12413                   Unfortunately it was past 11 AM.      0  \n",
       "12414                I used to cook but am now disabled.      1  \n",
       "\n",
       "[12415 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDatasetProcessed.to_csv(f'./dataset/3Select-{fileTag}-train.csv')\n",
    "trainDatasetProcessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b770299d-567d-46e2-b928-8ee31a341c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>plutchik</th>\n",
       "      <th>selection0</th>\n",
       "      <th>selection1</th>\n",
       "      <th>selection2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['none', 'unhappy', 'responsible', 'confused']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>Her amateur record wasn't that good.</td>\n",
       "      <td>Cindy was being noisy in her apartment.</td>\n",
       "      <td>Unfortunately it worked too well for they neve...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['none', 'determined', 'confident']</td>\n",
       "      <td>{'joy': 0, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Jessie didn't buy her mother a gift.</td>\n",
       "      <td>Lamie Mcramie knew it had to be done.</td>\n",
       "      <td>The woman hushed the man.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['irritated', 'angry', 'sad', 'annoyed', 'impa...</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Candy had finally burned a ham.</td>\n",
       "      <td>Andy no longer has back problems after a few w...</td>\n",
       "      <td>She was on the highway and getting kind of irr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Worried', 'hopeful', 'nervous', 'surprised',...</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>She was nervous to ask for money.</td>\n",
       "      <td>He didn't think he was getting paid fairly.</td>\n",
       "      <td>He ended up signing up for tennis instead.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['energetic', 'happy']</td>\n",
       "      <td>{'joy': 3, 'trust': 3, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Gary built a stronger chicken coop to keep the...</td>\n",
       "      <td>She would post pictures on social media whenev...</td>\n",
       "      <td>Rick stood in front of the oven watching the p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11845</th>\n",
       "      <td>['resentment', 'angry', 'content']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>I haven't gone back to Virginia Beach since.</td>\n",
       "      <td>Aubrey's grandmother had sent her a gift.</td>\n",
       "      <td>After a few hours, snow began to fill my yard ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11846</th>\n",
       "      <td>['curious', 'none', 'surprised', 'embaressed',...</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>His cat came inside and jumped into his lap.</td>\n",
       "      <td>I went near to her and ask where does she lives.</td>\n",
       "      <td>Emily was fascinated with the stamp on the let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11847</th>\n",
       "      <td>['curious', 'Curious', 'hungry']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>He got a shovel and started digging.</td>\n",
       "      <td>He wanted to have a taste.</td>\n",
       "      <td>We were very hot and not pleased with the serv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11848</th>\n",
       "      <td>['none', 'great and happy', 'talented', 'compe...</td>\n",
       "      <td>{'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Debbie was a devout vegetarian.</td>\n",
       "      <td>She really, really, really had to go pee.</td>\n",
       "      <td>Tom was a professional golfer.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11849</th>\n",
       "      <td>['scared', 'Excited', 'excited']</td>\n",
       "      <td>{'joy': 2, 'trust': 0, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>Everyone else pitched in for gas.</td>\n",
       "      <td>He persuaded his parents to let him go on the ...</td>\n",
       "      <td>Bill let go of his baby and sold his Mustang.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11850 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 emotion  \\\n",
       "0         ['none', 'unhappy', 'responsible', 'confused']   \n",
       "1                    ['none', 'determined', 'confident']   \n",
       "2      ['irritated', 'angry', 'sad', 'annoyed', 'impa...   \n",
       "3      ['Worried', 'hopeful', 'nervous', 'surprised',...   \n",
       "4                                 ['energetic', 'happy']   \n",
       "...                                                  ...   \n",
       "11845                 ['resentment', 'angry', 'content']   \n",
       "11846  ['curious', 'none', 'surprised', 'embaressed',...   \n",
       "11847                   ['curious', 'Curious', 'hungry']   \n",
       "11848  ['none', 'great and happy', 'talented', 'compe...   \n",
       "11849                   ['scared', 'Excited', 'excited']   \n",
       "\n",
       "                                                plutchik  \\\n",
       "0      {'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...   \n",
       "1      {'joy': 0, 'trust': 1, 'fear': 0, 'surprise': ...   \n",
       "2      {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "3      {'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...   \n",
       "4      {'joy': 3, 'trust': 3, 'fear': 0, 'surprise': ...   \n",
       "...                                                  ...   \n",
       "11845  {'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...   \n",
       "11846  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "11847  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "11848  {'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...   \n",
       "11849  {'joy': 2, 'trust': 0, 'fear': 1, 'surprise': ...   \n",
       "\n",
       "                                              selection0  \\\n",
       "0                   Her amateur record wasn't that good.   \n",
       "1                   Jessie didn't buy her mother a gift.   \n",
       "2                        Candy had finally burned a ham.   \n",
       "3                      She was nervous to ask for money.   \n",
       "4      Gary built a stronger chicken coop to keep the...   \n",
       "...                                                  ...   \n",
       "11845       I haven't gone back to Virginia Beach since.   \n",
       "11846       His cat came inside and jumped into his lap.   \n",
       "11847               He got a shovel and started digging.   \n",
       "11848                    Debbie was a devout vegetarian.   \n",
       "11849                  Everyone else pitched in for gas.   \n",
       "\n",
       "                                              selection1  \\\n",
       "0                Cindy was being noisy in her apartment.   \n",
       "1                  Lamie Mcramie knew it had to be done.   \n",
       "2      Andy no longer has back problems after a few w...   \n",
       "3            He didn't think he was getting paid fairly.   \n",
       "4      She would post pictures on social media whenev...   \n",
       "...                                                  ...   \n",
       "11845          Aubrey's grandmother had sent her a gift.   \n",
       "11846   I went near to her and ask where does she lives.   \n",
       "11847                         He wanted to have a taste.   \n",
       "11848          She really, really, really had to go pee.   \n",
       "11849  He persuaded his parents to let him go on the ...   \n",
       "\n",
       "                                              selection2  label  \n",
       "0      Unfortunately it worked too well for they neve...      2  \n",
       "1                              The woman hushed the man.      1  \n",
       "2      She was on the highway and getting kind of irr...      2  \n",
       "3             He ended up signing up for tennis instead.      0  \n",
       "4      Rick stood in front of the oven watching the p...      1  \n",
       "...                                                  ...    ...  \n",
       "11845  After a few hours, snow began to fill my yard ...      0  \n",
       "11846  Emily was fascinated with the stamp on the let...      1  \n",
       "11847  We were very hot and not pleased with the serv...      1  \n",
       "11848                     Tom was a professional golfer.      2  \n",
       "11849      Bill let go of his baby and sold his Mustang.      1  \n",
       "\n",
       "[11850 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDatasetProcessed.to_csv(f'./dataset/3Select-{fileTag}-test.csv')\n",
    "testDatasetProcessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7283c1-d83e-4369-b5e4-6c2e09d654ac",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "828a5092-83e6-4580-99c9-bd9ec434708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05151e3b-0bec-44f4-bf0a-ac58cddbf838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b2ace42b034a282c\n",
      "Reusing dataset csv (C:\\Users\\JAM_0\\.cache\\huggingface\\datasets\\csv\\default-b2ace42b034a282c\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75c4b44d8f544908ed297e838032bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('csv', data_files={'train': f'./dataset/3Select-{fileTag}-train.csv', \n",
    "                                           'test': f'./dataset/3Select-{fileTag}-test.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d776c270-7752-4445-ba6c-eb078f71eccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'emotion', 'plutchik', 'selection0', 'selection1', 'selection2', 'label'],\n",
       "        num_rows: 11610\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'emotion', 'plutchik', 'selection0', 'selection1', 'selection2', 'label'],\n",
       "        num_rows: 11129\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1c79159-f795-4d02-b052-94f04286d53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 0,\n",
       " 'emotion': \"['proud', 'good', 'sad', 'angry', 'happy', 'excited']\",\n",
       " 'plutchik': \"{'joy': 2, 'trust': 1, 'fear': 0, 'surprise': 1, 'sadness': 0, 'disgust': 0, 'anger': 0, 'anticipation': 1}\",\n",
       " 'selection0': 'The ball rocketed past the keep scoring his team a 1-0 lead.',\n",
       " 'selection1': 'He quickly stopped in a local shoe store and looked around.',\n",
       " 'selection2': 'Jay and Sarah met in a hotel once a week.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f6ad67d-b4cb-4f65-a9cb-d2d665deec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_one(example):\n",
    "    print(f\"Context: {example['plutchik']}\")\n",
    "    print(f\"  A - {example['selection0']}\")\n",
    "    print(f\"  B - {example['selection1']}\")\n",
    "    print(f\"  C - {example['selection2']}\")\n",
    "    print(f\"\\nGround truth: option {['A', 'B', 'C'][example['label']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15cd7cfb-748a-4fe7-8152-7debf6a65ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: {'joy': 2, 'trust': 1, 'fear': 0, 'surprise': 1, 'sadness': 0, 'disgust': 0, 'anger': 0, 'anticipation': 2}\n",
      "  A - Tracy had a cousin that was looking for a car.\n",
      "  B - Peter had to get rid of the dog.\n",
      "  C - He painted his face and drank some beer.\n",
      "\n",
      "Ground truth: option C\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da93346-1037-41ed-b67d-91877fa8c0ec",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3da78c12-9aff-4beb-a006-e287bbf61023",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_checkpoint != 'distilbert-base-uncased-finetuned-sst-2-english':\n",
    "    from transformers import AutoTokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "else:\n",
    "    from transformers import DistilBertTokenizer, DistilBertForMultipleChoice\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caffe397-a65d-478f-b966-7b910fb2edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "selectionList = [\"selection0\", \"selection1\", \"selection2\"]\n",
    "weightRemap = [\"NOT \", \"LITTLE \", \"\", \"VERY \", \"ABSOLUTELY \"]\n",
    "def preprocess_function(examples):\n",
    "    # Repeat each first sentence four times to go with the four possibilities of second sentences.\n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(context.strip(\"[\").strip(\"]\").replace('\\'', '')) ]*2 for context in examples[\"emotion\"] ]\n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(context.strip(\"[\").strip(\"]\").replace('\\\"', '')) ]*2 for context in examples[\"plutchik\"] ]\n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(\", \".join([weightRemap[int(eachCaseWeight.replace(\"]\", \"\").replace(\"[\", \"\").replace(\"}\", \"\").replace(\"{\", \"\").replace(\"\\\"\", \"\").replace(\"\\'\", \"\"))] \n",
    "    #                                                                   + eachCaseEmotionType.replace(\"]\", \"\").replace(\"[\", \"\").replace(\"}\", \"\").replace(\"{\", \"\").replace(\"\\\"\", \"\").replace(\"\\'\", \"\").strip()\n",
    "    #                     for eachCaseWeight, eachCaseEmotionType in \n",
    "    #                     zip([re.split(':|,',eachEmotionCombination)[1::2] for eachEmotionCombination in examples[\"plutchik\"]][eventIndex], \n",
    "    #                        [re.split(':|,',eachEmotionCombination)[::2] for eachEmotionCombination in examples[\"plutchik\"]][eventIndex])]))]*2 for eventIndex in \n",
    "    #                        range(len([re.split(':|,',eachEmotionCombination)[1::2] for eachEmotionCombination in examples[\"plutchik\"]]))]\n",
    "    \n",
    "    first_sentences = [[\"The following sentences contain emotions: {}\".format(', '.join([(weightRemap[eachEmotion[1]] + \" \" +eachEmotion[0]).strip() \n",
    "                       for eachEmotion in ast.literal_eval(context).items()]))]*3\n",
    "                       for context in examples[\"plutchik\"]]\n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(context.strip(\"[\").strip(\"]\").replace('\\\"', '') \n",
    "    #                   if context in {\"[]\", \"[\\\"none\\\"]\"} \n",
    "    #                   else ', '.join([(weightRemap[eachEmotion[1]] + \" \" +eachEmotion[0]).strip() \n",
    "    #                                   for eachEmotion in ast.literal_eval(context.replace(\":\", \"\\\" : \").replace(\"\\\",\", \",\").replace(\"[\", \"{\").replace(\"\\\"]\", \"}\").replace(\"]\", \"}\")).items()]))]*2 \n",
    "    #                    for context in examples[\"plutchik\"]]\n",
    "    # Grab all second sentences possible for each context.\n",
    "    second_sentences = [[examples[selection][index] for selection in selectionList]for index in range(len(examples['selection0']))]\n",
    "\n",
    "    # Flatten everything\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "    \n",
    "    # Tokenize\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "    # Un-flatten\n",
    "    # print(tokenized_examples.items())\n",
    "    return {k: [v[i:i+3] for i in range(0, len(v), 3)] for k, v in tokenized_examples.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0afb4841-ab69-4b91-8859-fd249badb923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 3 [51, 49, 49]\n"
     ]
    }
   ],
   "source": [
    "examples = dataset[\"train\"][:5]\n",
    "features = preprocess_function(examples)\n",
    "print(len(features[\"input_ids\"]), len(features[\"input_ids\"][0]), [len(x) for x in features[\"input_ids\"][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "903e2891-0e3d-4e87-b98a-727eaf36417a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] The following sentences contain emotions : joy, LITTLE trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, anticipation [SEP] Tracy had a cousin that was looking for a car. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : joy, LITTLE trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, anticipation [SEP] Peter had to get rid of the dog. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : joy, LITTLE trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, anticipation [SEP] He painted his face and drank some beer. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : VERY joy, LITTLE trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation [SEP] The owners bought her a soft dog bed. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : VERY joy, LITTLE trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation [SEP] Just to put the picture on a Christmas card. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : VERY joy, LITTLE trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation [SEP] Stanley wondered if he would ever get out of prison. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : VERY joy, LITTLE trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, LITTLE anticipation [SEP] He hit his first home run. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : VERY joy, LITTLE trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, LITTLE anticipation [SEP] My phone battery got fried so I decided to buy a new one. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : VERY joy, LITTLE trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, LITTLE anticipation [SEP] When the game started, the opponents ran towards him. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : VERY joy, LITTLE trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, anticipation [SEP] Maple is having a few drinks. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : VERY joy, LITTLE trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, anticipation [SEP] I had not seen direct sunlight for many weeks. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : VERY joy, LITTLE trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, anticipation [SEP] He finally got an interview with a bank! [SEP]',\n",
       " '[CLS] The following sentences contain emotions : NOT joy, NOT trust, LITTLE fear, LITTLE surprise, LITTLE sadness, NOT disgust, NOT anger, NOT anticipation [SEP] Elizabeth decided to go to a furniture store to get a proper light. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : NOT joy, NOT trust, LITTLE fear, LITTLE surprise, LITTLE sadness, NOT disgust, NOT anger, NOT anticipation [SEP] When her dad helped, she got things going. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : NOT joy, NOT trust, LITTLE fear, LITTLE surprise, LITTLE sadness, NOT disgust, NOT anger, NOT anticipation [SEP] She had the dress hemmed based on the heels, so she had to wear them. [SEP]']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(features[\"input_ids\"][a][i]) for a in range(5) for i in range(3) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a286ba6-cb84-4619-b842-780124d26a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67ebc05a6fc4ed88b0cdb0210278b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c89e4fab9148189f7756e528118be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7706d875-3a89-4e52-9f08-c77256b621ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForMultipleChoice: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForMultipleChoice were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "if model_checkpoint != 'distilbert-base-uncased-finetuned-sst-2-english':\n",
    "    from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "    model = AutoModelForMultipleChoice.from_pretrained(model_checkpoint)\n",
    "else:\n",
    "    from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "    from transformers import DistilBertTokenizer, DistilBertForMultipleChoice\n",
    "    import torch\n",
    "    model = DistilBertForMultipleChoice.from_pretrained(\"distilbert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cd7be65-ebd8-43db-bcbf-a87d7e2342e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-emotionCommonsense\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=5e-6, # for bert-base\n",
    "    # learning_rate=1e-3,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2737e04e-19c2-407d-8ce1-06b675f208c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [[{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        # Un-flatten\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        # Add back labels\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03a0ec05-de5e-434f-b07c-63212e7c7f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_keys = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "features = [{k: v for k, v in encoded_datasets[\"train\"][i].items() if k in accepted_keys} for i in range(10)]\n",
    "batch = DataCollatorForMultipleChoice(tokenizer)(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45f7f26c-04bb-42ae-8627-897ced69888e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] The following sentences contain emotions : LITTLE joy, trust, LITTLE fear, NOT surprise, LITTLE sadness, NOT disgust, NOT anger, LITTLE anticipation [SEP] After she ate she went home to nap. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] The following sentences contain emotions : LITTLE joy, trust, LITTLE fear, NOT surprise, LITTLE sadness, NOT disgust, NOT anger, LITTLE anticipation [SEP] Tim was furious. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " \"[CLS] The following sentences contain emotions : LITTLE joy, trust, LITTLE fear, NOT surprise, LITTLE sadness, NOT disgust, NOT anger, LITTLE anticipation [SEP] She went to her best friend's birthday party. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(batch[\"input_ids\"][8][i].tolist()) for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4b55256-30fa-4e30-a3a4-66fe1114b941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: {'joy': 1, 'trust': 2, 'fear': 1, 'surprise': 0, 'sadness': 1, 'disgust': 0, 'anger': 0, 'anticipation': 1}\n",
      "  A - After she ate she went home to nap.\n",
      "  B - Tim was furious.\n",
      "  C - She went to her best friend's birthday party.\n",
      "\n",
      "Ground truth: option C\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8305d3-8dc9-4d0f-8628-f51dc356c2d2",
   "metadata": {},
   "source": [
    "# Trainer Defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b707863a-bc16-43b0-b633-c7ffb4fa72e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "valStored = []\n",
    "def compute_metrics(eval_predictions):\n",
    "    predictions, label_ids = eval_predictions\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    valStored.append((preds != label_ids).astype(np.float32));\n",
    "    return {\"accuracy\": (preds == label_ids).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b115c1ba-323a-47d5-bb9d-55de985f13b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_datasets[\"train\"],\n",
    "    eval_dataset=encoded_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a5e3430-bbd6-484d-8a8d-9cbcdba37d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, plutchik, selection2, Unnamed: 0, selection0, selection1. If emotion, plutchik, selection2, Unnamed: 0, selection0, selection1 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "C:\\Python\\miniconda3\\envs\\pytorchEnvWithDataSci\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 11610\n",
      "  Num Epochs = 16\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11616\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11616' max='11616' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11616/11616 21:05, Epoch 16/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.099600</td>\n",
       "      <td>1.098160</td>\n",
       "      <td>0.362836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.099000</td>\n",
       "      <td>1.022216</td>\n",
       "      <td>0.465540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.966600</td>\n",
       "      <td>0.903368</td>\n",
       "      <td>0.534370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.909900</td>\n",
       "      <td>0.870490</td>\n",
       "      <td>0.553868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.853900</td>\n",
       "      <td>0.876004</td>\n",
       "      <td>0.563663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.821200</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.566807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.783800</td>\n",
       "      <td>0.875368</td>\n",
       "      <td>0.567976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.762200</td>\n",
       "      <td>0.899239</td>\n",
       "      <td>0.574535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.731300</td>\n",
       "      <td>0.916781</td>\n",
       "      <td>0.575164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.708400</td>\n",
       "      <td>0.918930</td>\n",
       "      <td>0.570042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.930045</td>\n",
       "      <td>0.578309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.665300</td>\n",
       "      <td>0.956463</td>\n",
       "      <td>0.576871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.655300</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.575523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.640600</td>\n",
       "      <td>0.985652</td>\n",
       "      <td>0.576602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.637600</td>\n",
       "      <td>0.986062</td>\n",
       "      <td>0.575523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.630400</td>\n",
       "      <td>0.990738</td>\n",
       "      <td>0.575613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, plutchik, selection2, Unnamed: 0, selection0, selection1. If emotion, plutchik, selection2, Unnamed: 0, selection0, selection1 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, plutchik, selection2, Unnamed: 0, selection0, selection1. If emotion, plutchik, selection2, Unnamed: 0, selection0, selection1 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, plutchik, selection2, Unnamed: 0, selection0, selection1. If emotion, plutchik, selection2, Unnamed: 0, selection0, selection1 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, plutchik, selection2, Unnamed: 0, selection0, selection1. If emotion, plutchik, selection2, Unnamed: 0, selection0, selection1 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, plutchik, selection2, Unnamed: 0, selection0, selection1. If emotion, plutchik, selection2, Unnamed: 0, selection0, selection1 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, plutchik, selection2, Unnamed: 0, selection0, selection1. If emotion, plutchik, selection2, Unnamed: 0, selection0, selection1 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, plutchik, selection2, Unnamed: 0, selection0, selection1. If emotion, plutchik, selection2, Unnamed: 0, selection0, selection1 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, plutchik, selection2, Unnamed: 0, selection0, selection1. If emotion, plutchik, selection2, Unnamed: 0, selection0, selection1 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, plutchik, selection2, Unnamed: 0, selection0, selection1. If emotion, plutchik, selection2, Unnamed: 0, selection0, selection1 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, plutchik, selection2, Unnamed: 0, selection0, selection1. If emotion, plutchik, selection2, Unnamed: 0, selection0, selection1 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, plutchik, selection2, Unnamed: 0, selection0, selection1. If emotion, plutchik, selection2, Unnamed: 0, selection0, selection1 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, plutchik, selection2, Unnamed: 0, selection0, selection1. If emotion, plutchik, selection2, Unnamed: 0, selection0, selection1 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, plutchik, selection2, Unnamed: 0, selection0, selection1. If emotion, plutchik, selection2, Unnamed: 0, selection0, selection1 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, plutchik, selection2, Unnamed: 0, selection0, selection1. If emotion, plutchik, selection2, Unnamed: 0, selection0, selection1 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, plutchik, selection2, Unnamed: 0, selection0, selection1. If emotion, plutchik, selection2, Unnamed: 0, selection0, selection1 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: emotion, plutchik, selection2, Unnamed: 0, selection0, selection1. If emotion, plutchik, selection2, Unnamed: 0, selection0, selection1 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11616, training_loss=0.7855961920472873, metrics={'train_runtime': 1267.0635, 'train_samples_per_second': 146.607, 'train_steps_per_second': 9.168, 'total_flos': 9156017459368728.0, 'train_loss': 0.7855961920472873, 'epoch': 16.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a17948-a8f7-4450-b2b0-8a7016e91391",
   "metadata": {},
   "source": [
    "出现validation loss 上升情况大多是训练集验证集数据分布不一致，或者训练集过小，未包含验证集中所有情况，\n",
    "也就是过拟合导致的。而解决这种现象可以尝试以下几种策略：\n",
    "1. 增加训练样本增加正则项系数权重，\n",
    "2. 减小过拟合加入早停机制，ValLoss上升几个epoch直接停止\n",
    "3. 采用Focal Loss\n",
    "4. 加入Label Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d6ab3-33ac-4e8e-99ee-3c3f17d71642",
   "metadata": {},
   "source": [
    "# Store Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c30271fe-7ce9-43e8-9e87-de8d6ae2c2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x23113595460>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "Z = np.transpose(valStored)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.pcolormesh(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e77d30e-e51a-45a6-9130-83a17c4d2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataLog = pd.DataFrame(trainer.state.log_history)\n",
    "dataLog.to_csv(f'./trainingMetric/[Plutchik] 3Select/TI-{model_checkpoint}-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c90cfec4-96ec-46c8-a99f-3c78b989b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluationIterationResult = pd.DataFrame(np.transpose(valStored))\n",
    "evaluationIterationResult.to_csv(f'./trainingMetric/[Plutchik] 3Select/ESI-{model_checkpoint}-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd7f330-1477-4119-a9dc-1ebb7acb7665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchEnvWithDataSci",
   "language": "python",
   "name": "pytorchenvwithdatasci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
