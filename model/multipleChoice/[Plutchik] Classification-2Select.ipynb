{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8533643b-5b68-4dec-8a8a-49852c237e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global var set\n",
    "import transformers\n",
    "\n",
    "# model info, change as needed\n",
    "batch_size = 16\n",
    "num_epochs = 16\n",
    "\n",
    "model_checkpoint = \"bert-base-uncased\"\n",
    "# fileTag = \"original-plutchik-noCombin-v1\"   # original - no Combine    - pure raw\n",
    "# fileTag = \"original-plutchik-v1\"             # original - w/ Combine\n",
    "# fileTag = \"clean-noCombin-v1\"                # clean    - no Combine\n",
    "# fileTag = \"clean-v1\"                         # clean    - w/ Combine    - pure clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa38989-ff76-4de1-a82e-6853a1e61687",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Convert dataset to suitable format\n",
    "IMPORTANT: please never run this section again if you have your dataset ready!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a93a9f46-6703-4535-af96-8be1b5b3407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "trainDatasetOriginal = pd.read_csv(f'../../data/csv_version/dev/emotion/allcharlinepairs-{fileTag}.csv')\n",
    "testDatasetOriginal = pd.read_csv(f'../../data/csv_version/test/emotion/allcharlinepairs-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7265a797-adc2-49ed-b237-19abf9e0569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatasetProcessed = DataFrame({'emotion' : trainDatasetOriginal['emotion'],\n",
    "                                   'plutchik' : trainDatasetOriginal['emotion'],\n",
    "                                  'selection0': pd.concat([trainDatasetOriginal['sentence'][:trainDatasetOriginal.shape[0]//2], trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//2:]]), \n",
    "                                  'selection1': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//2], trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//2:]]), \n",
    "                                  'label': pd.Series(0 if x < trainDatasetOriginal.shape[0]//2 else 1 for x in trainDatasetOriginal.index)}).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "testDatasetProcessed = DataFrame({'emotion' : testDatasetOriginal['emotion'], \n",
    "                                  'plutchik' : testDatasetOriginal['emotion'],\n",
    "                                  'selection0': pd.concat([testDatasetOriginal['sentence'][:testDatasetOriginal.shape[0]//2], testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//2:]]), \n",
    "                                  'selection1': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//2], testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//2:]]), \n",
    "                                  'label': pd.Series(0 if x < testDatasetOriginal.shape[0]//2 else 1 for x in testDatasetOriginal.index)}).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19e3c334-b371-44ad-b6e1-7161f405b741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>plutchik</th>\n",
       "      <th>selection0</th>\n",
       "      <th>selection1</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['helpful']</td>\n",
       "      <td>['helpful']</td>\n",
       "      <td>She is playing very hard trying to win the game.</td>\n",
       "      <td>Her grandson went and picked up noodles from t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['saddened']</td>\n",
       "      <td>['saddened']</td>\n",
       "      <td>He was denied his parole for three straight Ye...</td>\n",
       "      <td>She took pictures of her meal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['sad']</td>\n",
       "      <td>['sad']</td>\n",
       "      <td>John bought it and tried it out.</td>\n",
       "      <td>Paul dropped his plate.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['excited']</td>\n",
       "      <td>['excited']</td>\n",
       "      <td>That night, Ralph saw her at a bar and they hi...</td>\n",
       "      <td>Matt climbed to the top of a small mountain wi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['happy']</td>\n",
       "      <td>['happy']</td>\n",
       "      <td>Sarah was happy that she was able to get a new...</td>\n",
       "      <td>I chose a purple galaxy phone case.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42949</th>\n",
       "      <td>['normal']</td>\n",
       "      <td>['normal']</td>\n",
       "      <td>My neighbor Steve went out for a walk today.</td>\n",
       "      <td>It's nice and fluffy but has one flaw.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42950</th>\n",
       "      <td>['special', 'loved', 'nice']</td>\n",
       "      <td>['special', 'loved', 'nice']</td>\n",
       "      <td>I started seeing someone a while ago.</td>\n",
       "      <td>Henry went to dinner at his friend's house one...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42951</th>\n",
       "      <td>['grateful']</td>\n",
       "      <td>['grateful']</td>\n",
       "      <td>He laughed at her and asked when dinner would ...</td>\n",
       "      <td>I thanked him and put it in my wallet.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42952</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>He put a potato in the oven.</td>\n",
       "      <td>Unfortunately he wasn't wearing eye protection.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42953</th>\n",
       "      <td>['mad']</td>\n",
       "      <td>['mad']</td>\n",
       "      <td>Tim is out of the band now and they are furious.</td>\n",
       "      <td>Everyday after school we would all get togethe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42954 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            emotion                      plutchik  \\\n",
       "0                       ['helpful']                   ['helpful']   \n",
       "1                      ['saddened']                  ['saddened']   \n",
       "2                           ['sad']                       ['sad']   \n",
       "3                       ['excited']                   ['excited']   \n",
       "4                         ['happy']                     ['happy']   \n",
       "...                             ...                           ...   \n",
       "42949                    ['normal']                    ['normal']   \n",
       "42950  ['special', 'loved', 'nice']  ['special', 'loved', 'nice']   \n",
       "42951                  ['grateful']                  ['grateful']   \n",
       "42952                            []                            []   \n",
       "42953                       ['mad']                       ['mad']   \n",
       "\n",
       "                                              selection0  \\\n",
       "0       She is playing very hard trying to win the game.   \n",
       "1      He was denied his parole for three straight Ye...   \n",
       "2                       John bought it and tried it out.   \n",
       "3      That night, Ralph saw her at a bar and they hi...   \n",
       "4      Sarah was happy that she was able to get a new...   \n",
       "...                                                  ...   \n",
       "42949       My neighbor Steve went out for a walk today.   \n",
       "42950              I started seeing someone a while ago.   \n",
       "42951  He laughed at her and asked when dinner would ...   \n",
       "42952                       He put a potato in the oven.   \n",
       "42953   Tim is out of the band now and they are furious.   \n",
       "\n",
       "                                              selection1  label  \n",
       "0      Her grandson went and picked up noodles from t...      1  \n",
       "1                         She took pictures of her meal.      0  \n",
       "2                                Paul dropped his plate.      1  \n",
       "3      Matt climbed to the top of a small mountain wi...      0  \n",
       "4                    I chose a purple galaxy phone case.      0  \n",
       "...                                                  ...    ...  \n",
       "42949             It's nice and fluffy but has one flaw.      0  \n",
       "42950  Henry went to dinner at his friend's house one...      0  \n",
       "42951             I thanked him and put it in my wallet.      1  \n",
       "42952    Unfortunately he wasn't wearing eye protection.      1  \n",
       "42953  Everyday after school we would all get togethe...      0  \n",
       "\n",
       "[42954 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDatasetProcessed.to_csv(f'./dataset/2Select-{fileTag}-train.csv')\n",
    "trainDatasetProcessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b770299d-567d-46e2-b928-8ee31a341c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>plutchik</th>\n",
       "      <th>selection0</th>\n",
       "      <th>selection1</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['happy']</td>\n",
       "      <td>['happy']</td>\n",
       "      <td>Soon the raccoon was coming over every day for...</td>\n",
       "      <td>She stopped to play with the puppy.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['disappointed']</td>\n",
       "      <td>['disappointed']</td>\n",
       "      <td>Then he decided he was very proud to have a li...</td>\n",
       "      <td>Lisa then had to switch the location.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['disgusted']</td>\n",
       "      <td>['disgusted']</td>\n",
       "      <td>Susie could not believe it.</td>\n",
       "      <td>Tim and Ben were playing ping pong.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['sad']</td>\n",
       "      <td>['sad']</td>\n",
       "      <td>He told them that he was lost.</td>\n",
       "      <td>Now, he lives debt free.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['surprised']</td>\n",
       "      <td>['surprised']</td>\n",
       "      <td>She said that my cousin was faking the results.</td>\n",
       "      <td>It was a hidden camera character test, and Joh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43190</th>\n",
       "      <td>['disgruntled']</td>\n",
       "      <td>['disgruntled']</td>\n",
       "      <td>Jack wanted to drive his father's car.</td>\n",
       "      <td>Red hates his boss.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43191</th>\n",
       "      <td>['irritated']</td>\n",
       "      <td>['irritated']</td>\n",
       "      <td>He laid the sandwich down.</td>\n",
       "      <td>Finally she was able to get the app she really...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43192</th>\n",
       "      <td>['helpful']</td>\n",
       "      <td>['helpful']</td>\n",
       "      <td>She told her that it was fine and Sasha was ab...</td>\n",
       "      <td>The bully caught up with Jed and started hitti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43193</th>\n",
       "      <td>['nervous']</td>\n",
       "      <td>['nervous']</td>\n",
       "      <td>It was in mint condition and at a great price.</td>\n",
       "      <td>She then got in trouble at work.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43194</th>\n",
       "      <td>['happy', 'proud', 'excited']</td>\n",
       "      <td>['happy', 'proud', 'excited']</td>\n",
       "      <td>Anna was not working.</td>\n",
       "      <td>It was their wedding anniversary.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43195 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             emotion                       plutchik  \\\n",
       "0                          ['happy']                      ['happy']   \n",
       "1                   ['disappointed']               ['disappointed']   \n",
       "2                      ['disgusted']                  ['disgusted']   \n",
       "3                            ['sad']                        ['sad']   \n",
       "4                      ['surprised']                  ['surprised']   \n",
       "...                              ...                            ...   \n",
       "43190                ['disgruntled']                ['disgruntled']   \n",
       "43191                  ['irritated']                  ['irritated']   \n",
       "43192                    ['helpful']                    ['helpful']   \n",
       "43193                    ['nervous']                    ['nervous']   \n",
       "43194  ['happy', 'proud', 'excited']  ['happy', 'proud', 'excited']   \n",
       "\n",
       "                                              selection0  \\\n",
       "0      Soon the raccoon was coming over every day for...   \n",
       "1      Then he decided he was very proud to have a li...   \n",
       "2                            Susie could not believe it.   \n",
       "3                         He told them that he was lost.   \n",
       "4        She said that my cousin was faking the results.   \n",
       "...                                                  ...   \n",
       "43190             Jack wanted to drive his father's car.   \n",
       "43191                         He laid the sandwich down.   \n",
       "43192  She told her that it was fine and Sasha was ab...   \n",
       "43193     It was in mint condition and at a great price.   \n",
       "43194                              Anna was not working.   \n",
       "\n",
       "                                              selection1  label  \n",
       "0                    She stopped to play with the puppy.      0  \n",
       "1                  Lisa then had to switch the location.      1  \n",
       "2                    Tim and Ben were playing ping pong.      0  \n",
       "3                               Now, he lives debt free.      0  \n",
       "4      It was a hidden camera character test, and Joh...      1  \n",
       "...                                                  ...    ...  \n",
       "43190                                Red hates his boss.      1  \n",
       "43191  Finally she was able to get the app she really...      1  \n",
       "43192  The bully caught up with Jed and started hitti...      0  \n",
       "43193                   She then got in trouble at work.      1  \n",
       "43194                  It was their wedding anniversary.      1  \n",
       "\n",
       "[43195 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDatasetProcessed.to_csv(f'./dataset/2Select-{fileTag}-test.csv')\n",
    "testDatasetProcessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7283c1-d83e-4369-b5e4-6c2e09d654ac",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "828a5092-83e6-4580-99c9-bd9ec434708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05151e3b-0bec-44f4-bf0a-ac58cddbf838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-14bceb07d21a026c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:\\Users\\JAM_0\\.cache\\huggingface\\datasets\\csv\\default-14bceb07d21a026c\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663676b9f8f846bd9bac34f5fb3516bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb2a6f0453c48b0b0e8a3f64c3df41d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:\\Users\\JAM_0\\.cache\\huggingface\\datasets\\csv\\default-14bceb07d21a026c\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9702266859104cc69dabb7e29e4e0567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('csv', data_files={'train': f'./dataset/multiSelect-{fileTag}-train.csv', \n",
    "                                           'test': f'./dataset/multiSelect-{fileTag}-test.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d776c270-7752-4445-ba6c-eb078f71eccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'emotion', 'plutchik', 'selection0', 'selection1', 'label'],\n",
       "        num_rows: 53234\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'emotion', 'plutchik', 'selection0', 'selection1', 'label'],\n",
       "        num_rows: 51891\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1c79159-f795-4d02-b052-94f04286d53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 0,\n",
       " 'emotion': \"['overjoyed']\",\n",
       " 'plutchik': \"{'joy': 3, 'trust': 0, 'fear': 0, 'surprise': 2, 'sadness': 0, 'disgust': 0, 'anger': 0, 'anticipation': 0}\",\n",
       " 'selection0': 'He found a vintage video game system.',\n",
       " 'selection1': 'Kayla has a pair of new shoes.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f6ad67d-b4cb-4f65-a9cb-d2d665deec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_one(example):\n",
    "    print(f\"Context: {example['plutchik']}\")\n",
    "    print(f\"  A - {example['selection0']}\")\n",
    "    print(f\"  B - {example['selection1']}\")\n",
    "    print(f\"\\nGround truth: option {['A', 'B'][example['label']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15cd7cfb-748a-4fe7-8152-7debf6a65ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': 2, 'sadness': 2, 'disgust': 0, 'anger': 0, 'anticipation': 0}\n",
      "  A - The squirrel ran away.\n",
      "  B - She was grateful now for her sandwich and vegetables.\n",
      "\n",
      "Ground truth: option A\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da93346-1037-41ed-b67d-91877fa8c0ec",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3da78c12-9aff-4beb-a006-e287bbf61023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caffe397-a65d-478f-b966-7b910fb2edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "selectionList = [\"selection0\", \"selection1\"]\n",
    "weightRemap = [\"NOT \", \"LITTLE \", \"\", \"VERY \", \"ABSOLUTELY \"]\n",
    "def preprocess_function(examples):\n",
    "    # Repeat each first sentence four times to go with the four possibilities of second sentences.\n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(context.strip(\"[\").strip(\"]\").replace('\\'', '')) ]*2 for context in examples[\"emotion\"] ]\n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(context.strip(\"[\").strip(\"]\").replace('\\\"', '')) ]*2 for context in examples[\"plutchik\"] ]\n",
    "    first_sentences = [[\"The following sentences contain emotions: {}\".format(\", \".join([weightRemap[int(eachCaseWeight.replace(\"]\", \"\").replace(\"[\", \"\").replace(\"}\", \"\").replace(\"{\", \"\").replace(\"\\\"\", \"\").replace(\"\\'\", \"\"))] \n",
    "                                                        + eachCaseEmotionType.replace(\"]\", \"\").replace(\"[\", \"\").replace(\"}\", \"\").replace(\"{\", \"\").replace(\"\\\"\", \"\").replace(\"\\'\", \"\").strip()\n",
    "                        for eachCaseWeight, eachCaseEmotionType in \n",
    "                        zip([re.split(':|,',eachEmotionCombination)[1::2] for eachEmotionCombination in examples[\"plutchik\"]][eventIndex], \n",
    "                           [re.split(':|,',eachEmotionCombination)[::2] for eachEmotionCombination in examples[\"plutchik\"]][eventIndex])]))]*2 for eventIndex in \n",
    "                           range(len([re.split(':|,',eachEmotionCombination)[1::2] for eachEmotionCombination in examples[\"plutchik\"]]))]\n",
    "    \n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(', '.join([(weightRemap[eachEmotion[1]] + \" \" +eachEmotion[0]).strip() \n",
    "    #                    for eachEmotion in ast.literal_eval(context).items()]))]*2 \n",
    "    #                    for context in examples[\"plutchik\"]]\n",
    "    # Grab all second sentences possible for each context.\n",
    "    second_sentences = [[examples[selection][index] for selection in selectionList]for index in range(len(examples['selection0']))]\n",
    "\n",
    "    # Flatten everything\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "    \n",
    "    # Tokenize\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "    # Un-flatten\n",
    "    # print(tokenized_examples.items())\n",
    "    return {k: [v[i:i+2] for i in range(0, len(v), 2)] for k, v in tokenized_examples.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0afb4841-ab69-4b91-8859-fd249badb923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2 [48, 53]\n"
     ]
    }
   ],
   "source": [
    "examples = dataset[\"train\"][:5]\n",
    "features = preprocess_function(examples)\n",
    "print(len(features[\"input_ids\"]), len(features[\"input_ids\"][0]), [len(x) for x in features[\"input_ids\"][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "903e2891-0e3d-4e87-b98a-727eaf36417a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"[CLS] the following sentences contain emotions : not joy : 0,'trust ', fear : 0,'surprise ', not sadness : 2,'disgust ', not anger : 0,'anticipation'[SEP] the squirrel ran away. [SEP]\",\n",
       " \"[CLS] the following sentences contain emotions : not joy : 0,'trust ', fear : 3,'surprise ', not sadness : 0,'disgust ', very anger : 2,'anticipation'[SEP] jill was so thrilled. [SEP]\",\n",
       " \"[CLS] the following sentences contain emotions : not joy : 0,'trust ', not fear : 0,'surprise ', not sadness : 0,'disgust ', not anger : 0,'anticipation'[SEP] jen was great at cooking biscuits. [SEP]\",\n",
       " \"[CLS] the following sentences contain emotions : not joy : 0,'trust ', not fear : 0,'surprise ', not sadness : 0,'disgust ', not anger : 0,'anticipation'[SEP] rob got the new position! [SEP]\",\n",
       " \"[CLS] the following sentences contain emotions : not joy : 0,'trust ', not fear : 0,'surprise ', not sadness : 0,'disgust ', anger : 3,'anticipation'[SEP] he ended up stealing the space quickly. [SEP]\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(features[\"input_ids\"][a][i]) for a in range(5) for i in range(1) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a286ba6-cb84-4619-b842-780124d26a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08fa0a68d3445dcba0bbea6e1256ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d899a552b8c5400ab58d2546c97fa5fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7706d875-3a89-4e52-9f08-c77256b621ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultipleChoice: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForMultipleChoice.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cd7be65-ebd8-43db-bcbf-a87d7e2342e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-emotionCommonsense\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=5e-6, # for bert-base\n",
    "    # learning_rate=1e-3,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2737e04e-19c2-407d-8ce1-06b675f208c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [[{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        # Un-flatten\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        # Add back labels\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03a0ec05-de5e-434f-b07c-63212e7c7f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_keys = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "features = [{k: v for k, v in encoded_datasets[\"train\"][i].items() if k in accepted_keys} for i in range(10)]\n",
    "batch = DataCollatorForMultipleChoice(tokenizer)(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45f7f26c-04bb-42ae-8627-897ced69888e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"[CLS] the following sentences contain emotions : joy : 3,'trust ', fear : 0,'surprise ', not sadness : 0,'disgust ', very anger : 0,'anticipation'[SEP] he reached third base. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\",\n",
       " \"[CLS] the following sentences contain emotions : joy : 3,'trust ', fear : 0,'surprise ', not sadness : 0,'disgust ', very anger : 0,'anticipation'[SEP] i had to build a catapult for high school. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(batch[\"input_ids\"][8][i].tolist()) for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4b55256-30fa-4e30-a3a4-66fe1114b941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: {'joy': 3, 'trust': 2, 'fear': 0, 'surprise': 2, 'sadness': 0, 'disgust': 0, 'anger': 0, 'anticipation': 3}\n",
      "  A - He reached third base.\n",
      "  B - I had to build a catapult for high school.\n",
      "\n",
      "Ground truth: option A\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8305d3-8dc9-4d0f-8628-f51dc356c2d2",
   "metadata": {},
   "source": [
    "# Trainer Defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b707863a-bc16-43b0-b633-c7ffb4fa72e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "valStored = []\n",
    "def compute_metrics(eval_predictions):\n",
    "    predictions, label_ids = eval_predictions\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    valStored.append((preds != label_ids).astype(np.float32));\n",
    "    return {\"accuracy\": (preds == label_ids).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b115c1ba-323a-47d5-bb9d-55de985f13b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_datasets[\"train\"],\n",
    "    eval_dataset=encoded_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a5e3430-bbd6-484d-8a8d-9cbcdba37d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "C:\\Python\\miniconda3\\envs\\pytorchEnvWithDataSci\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 53234\n",
      "  Num Epochs = 16\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53248\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53248' max='53248' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53248/53248 2:26:59, Epoch 16/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.693800</td>\n",
       "      <td>0.693128</td>\n",
       "      <td>0.504018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.614600</td>\n",
       "      <td>0.594435</td>\n",
       "      <td>0.656838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.564700</td>\n",
       "      <td>0.571774</td>\n",
       "      <td>0.684685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.526300</td>\n",
       "      <td>0.572104</td>\n",
       "      <td>0.695053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.499500</td>\n",
       "      <td>0.586160</td>\n",
       "      <td>0.701162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.472300</td>\n",
       "      <td>0.586649</td>\n",
       "      <td>0.705170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.620333</td>\n",
       "      <td>0.704207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.444200</td>\n",
       "      <td>0.623844</td>\n",
       "      <td>0.704265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.415700</td>\n",
       "      <td>0.655308</td>\n",
       "      <td>0.705055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.394100</td>\n",
       "      <td>0.685141</td>\n",
       "      <td>0.703860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.375700</td>\n",
       "      <td>0.723962</td>\n",
       "      <td>0.702183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.371000</td>\n",
       "      <td>0.727208</td>\n",
       "      <td>0.702646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.339400</td>\n",
       "      <td>0.768802</td>\n",
       "      <td>0.702723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.327800</td>\n",
       "      <td>0.798015</td>\n",
       "      <td>0.701258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.320600</td>\n",
       "      <td>0.806652</td>\n",
       "      <td>0.700892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.310600</td>\n",
       "      <td>0.814122</td>\n",
       "      <td>0.700565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-53000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-53000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-53000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-53000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-53000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=53248, training_loss=0.4483006133769567, metrics={'train_runtime': 8821.4262, 'train_samples_per_second': 96.554, 'train_steps_per_second': 6.036, 'total_flos': 5.267817952412011e+16, 'train_loss': 0.4483006133769567, 'epoch': 16.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a17948-a8f7-4450-b2b0-8a7016e91391",
   "metadata": {},
   "source": [
    "出现validation loss 上升情况大多是训练集验证集数据分布不一致，或者训练集过小，未包含验证集中所有情况，\n",
    "也就是过拟合导致的。而解决这种现象可以尝试以下几种策略：\n",
    "1. 增加训练样本增加正则项系数权重，\n",
    "2. 减小过拟合加入早停机制，ValLoss上升几个epoch直接停止\n",
    "3. 采用Focal Loss\n",
    "4. 加入Label Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d6ab3-33ac-4e8e-99ee-3c3f17d71642",
   "metadata": {},
   "source": [
    "# Store Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c30271fe-7ce9-43e8-9e87-de8d6ae2c2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x23113595460>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "Z = np.transpose(valStored)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.pcolormesh(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e77d30e-e51a-45a6-9130-83a17c4d2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataLog = pd.DataFrame(trainer.state.log_history)\n",
    "dataLog.to_csv(f'./trainingMetric/[Plutchik] 2Select/TI-{model_checkpoint}-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c90cfec4-96ec-46c8-a99f-3c78b989b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluationIterationResult = pd.DataFrame(np.transpose(valStored))\n",
    "evaluationIterationResult.to_csv(f'./trainingMetric/[Plutchik] 2Select/ESI-{model_checkpoint}-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd7f330-1477-4119-a9dc-1ebb7acb7665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchEnvWithDataSci",
   "language": "python",
   "name": "pytorchenvwithdatasci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
