{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8533643b-5b68-4dec-8a8a-49852c237e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global var set\n",
    "import transformers\n",
    "\n",
    "# model info, change as needed\n",
    "batch_size = 16\n",
    "num_epochs = 16\n",
    "\n",
    "# model_checkpoint = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "model_checkpoint = \"roberta-base\"\n",
    "# model_checkpoint = 'bert-base-uncased'\n",
    "fileTag = \"original-plutchik-noCombin-v1\"   # original - no Combine    - pure raw\n",
    "# fileTag = \"original-plutchik-v1\"             # original - w/ Combine\n",
    "# fileTag = \"clean-noCombin-v1\"                # clean    - no Combine\n",
    "# fileTag = \"clean-v1\"                         # clean    - w/ Combine    - pure clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa38989-ff76-4de1-a82e-6853a1e61687",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Convert dataset to suitable format\n",
    "IMPORTANT: please never run this section again if you have your dataset ready!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a93a9f46-6703-4535-af96-8be1b5b3407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "trainDatasetOriginal = pd.read_csv(f'../../data/csv_version/dev/emotion/allcharlinepairs-{fileTag}.csv')\n",
    "testDatasetOriginal = pd.read_csv(f'../../data/csv_version/test/emotion/allcharlinepairs-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7265a797-adc2-49ed-b237-19abf9e0569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatasetProcessed = DataFrame({'emotion' : trainDatasetOriginal['emotion'],\n",
    "                                   'plutchik' : trainDatasetOriginal['plutchik'],\n",
    "                                  'selection0': pd.concat([trainDatasetOriginal['sentence'][:trainDatasetOriginal.shape[0]//2], trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//2:]]), \n",
    "                                  'selection1': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//2], trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//2:]]), \n",
    "                                  'label': pd.Series(0 if x < trainDatasetOriginal.shape[0]//2 else 1 for x in trainDatasetOriginal.index)}).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "testDatasetProcessed = DataFrame({'emotion' : testDatasetOriginal['emotion'], \n",
    "                                  'plutchik' : testDatasetOriginal['plutchik'],\n",
    "                                  'selection0': pd.concat([testDatasetOriginal['sentence'][:testDatasetOriginal.shape[0]//2], testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//2:]]), \n",
    "                                  'selection1': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//2], testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//2:]]), \n",
    "                                  'label': pd.Series(0 if x < testDatasetOriginal.shape[0]//2 else 1 for x in testDatasetOriginal.index)}).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "19e3c334-b371-44ad-b6e1-7161f405b741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>plutchik</th>\n",
       "      <th>selection0</th>\n",
       "      <th>selection1</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['happy']</td>\n",
       "      <td>{'joy': 2, 'trust': 2, 'fear': 2, 'surprise': ...</td>\n",
       "      <td>James was asked to fill in.</td>\n",
       "      <td>June was always top of her class.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['exhausted']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...</td>\n",
       "      <td>Ali had really enjoyed the vineyard tour!</td>\n",
       "      <td>That evening, Sam's mom got a call from her we...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['sad', 'down']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>I wanted to be thin like the friends i associa...</td>\n",
       "      <td>Michelle didn't make the cheerleading squad.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['frustration']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>While playing, Sammy accidentally broke a vase!</td>\n",
       "      <td>He was diagnosed with laryngitis.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['anticipation']</td>\n",
       "      <td>{'joy': 2, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>They only had 5 days.</td>\n",
       "      <td>He eats it between classes at school.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42949</th>\n",
       "      <td>['happy', 'proud']</td>\n",
       "      <td>{'joy': 3, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>They all asked for the recipe but Dina refused.</td>\n",
       "      <td>He also built little people, and little pets.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42950</th>\n",
       "      <td>['afraid']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 3, 'surprise': ...</td>\n",
       "      <td>He stopped at Wendy's.</td>\n",
       "      <td>While in the crypt, Marissa asked constantly t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42951</th>\n",
       "      <td>['relieved', 'grateful']</td>\n",
       "      <td>{'joy': 2, 'trust': 0, 'fear': 2, 'surprise': ...</td>\n",
       "      <td>I replaced the roll of toilet paper.</td>\n",
       "      <td>One day she told her dad about the bullying.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42952</th>\n",
       "      <td>['calm']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>She would receive fresh vegetables and fruit f...</td>\n",
       "      <td>My piano instructor came over for my lessons.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42953</th>\n",
       "      <td>['sulky']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...</td>\n",
       "      <td>She wanted to sing but was very nervous about ...</td>\n",
       "      <td>I didn't have enough money to buy a plane ticket.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42954 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        emotion  \\\n",
       "0                     ['happy']   \n",
       "1                 ['exhausted']   \n",
       "2               ['sad', 'down']   \n",
       "3               ['frustration']   \n",
       "4              ['anticipation']   \n",
       "...                         ...   \n",
       "42949        ['happy', 'proud']   \n",
       "42950                ['afraid']   \n",
       "42951  ['relieved', 'grateful']   \n",
       "42952                  ['calm']   \n",
       "42953                 ['sulky']   \n",
       "\n",
       "                                                plutchik  \\\n",
       "0      {'joy': 2, 'trust': 2, 'fear': 2, 'surprise': ...   \n",
       "1      {'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...   \n",
       "2      {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "3      {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "4      {'joy': 2, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "...                                                  ...   \n",
       "42949  {'joy': 3, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "42950  {'joy': 0, 'trust': 0, 'fear': 3, 'surprise': ...   \n",
       "42951  {'joy': 2, 'trust': 0, 'fear': 2, 'surprise': ...   \n",
       "42952  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "42953  {'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...   \n",
       "\n",
       "                                              selection0  \\\n",
       "0                            James was asked to fill in.   \n",
       "1              Ali had really enjoyed the vineyard tour!   \n",
       "2      I wanted to be thin like the friends i associa...   \n",
       "3        While playing, Sammy accidentally broke a vase!   \n",
       "4                                  They only had 5 days.   \n",
       "...                                                  ...   \n",
       "42949    They all asked for the recipe but Dina refused.   \n",
       "42950                             He stopped at Wendy's.   \n",
       "42951               I replaced the roll of toilet paper.   \n",
       "42952  She would receive fresh vegetables and fruit f...   \n",
       "42953  She wanted to sing but was very nervous about ...   \n",
       "\n",
       "                                              selection1  label  \n",
       "0                      June was always top of her class.      0  \n",
       "1      That evening, Sam's mom got a call from her we...      1  \n",
       "2           Michelle didn't make the cheerleading squad.      1  \n",
       "3                      He was diagnosed with laryngitis.      1  \n",
       "4                  He eats it between classes at school.      0  \n",
       "...                                                  ...    ...  \n",
       "42949      He also built little people, and little pets.      0  \n",
       "42950  While in the crypt, Marissa asked constantly t...      1  \n",
       "42951       One day she told her dad about the bullying.      0  \n",
       "42952      My piano instructor came over for my lessons.      0  \n",
       "42953  I didn't have enough money to buy a plane ticket.      1  \n",
       "\n",
       "[42954 rows x 5 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDatasetProcessed.to_csv(f'./dataset/2Select-{fileTag}-train.csv')\n",
    "trainDatasetProcessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b770299d-567d-46e2-b928-8ee31a341c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>plutchik</th>\n",
       "      <th>selection0</th>\n",
       "      <th>selection1</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['satisfied']</td>\n",
       "      <td>{'joy': 2, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>He made sure to leave them perfect.</td>\n",
       "      <td>Sam went into his backyard to dig a hole for a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['nervous']</td>\n",
       "      <td>{'joy': 2, 'trust': 2, 'fear': 3, 'surprise': ...</td>\n",
       "      <td>She joined a relief organization and helped re...</td>\n",
       "      <td>Tim needed to take a large test to graduate fr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['scary']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>An old man came out of the house yelling causi...</td>\n",
       "      <td>They were in my mom's garden when I was a kid.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['relieved']</td>\n",
       "      <td>{'joy': 2, 'trust': 3, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>She took it to obedience class to learn to beh...</td>\n",
       "      <td>The photos ended up looking great.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['disgusted']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Searching through these dresses, one stood out...</td>\n",
       "      <td>It was far too sour and Suzy never wanted coff...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43190</th>\n",
       "      <td>['angry']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>She had become the bad guy of the office very ...</td>\n",
       "      <td>The teacher heard the phone ring.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43191</th>\n",
       "      <td>['irritated']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>One day he overheard others talking in spanish.</td>\n",
       "      <td>I wish people in the theatre weren't so rude.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43192</th>\n",
       "      <td>['helpful']</td>\n",
       "      <td>{'joy': 2, 'trust': 2, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>She asked the waiter for recommendations.</td>\n",
       "      <td>He then told everyone how cool and manly Theo ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43193</th>\n",
       "      <td>['proud']</td>\n",
       "      <td>{'joy': 3, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Alison stood on the podium, beaming as she rec...</td>\n",
       "      <td>When we were walking together, I noticed that ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43194</th>\n",
       "      <td>['annoyed']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Growing up we had this hideous couch at my mom...</td>\n",
       "      <td>A few weeks ago, our family went to Washington...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43195 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             emotion                                           plutchik  \\\n",
       "0      ['satisfied']  {'joy': 2, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "1        ['nervous']  {'joy': 2, 'trust': 2, 'fear': 3, 'surprise': ...   \n",
       "2          ['scary']  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "3       ['relieved']  {'joy': 2, 'trust': 3, 'fear': 0, 'surprise': ...   \n",
       "4      ['disgusted']  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "...              ...                                                ...   \n",
       "43190      ['angry']  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "43191  ['irritated']  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "43192    ['helpful']  {'joy': 2, 'trust': 2, 'fear': 0, 'surprise': ...   \n",
       "43193      ['proud']  {'joy': 3, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "43194    ['annoyed']  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "\n",
       "                                              selection0  \\\n",
       "0                    He made sure to leave them perfect.   \n",
       "1      She joined a relief organization and helped re...   \n",
       "2      An old man came out of the house yelling causi...   \n",
       "3      She took it to obedience class to learn to beh...   \n",
       "4      Searching through these dresses, one stood out...   \n",
       "...                                                  ...   \n",
       "43190  She had become the bad guy of the office very ...   \n",
       "43191    One day he overheard others talking in spanish.   \n",
       "43192          She asked the waiter for recommendations.   \n",
       "43193  Alison stood on the podium, beaming as she rec...   \n",
       "43194  Growing up we had this hideous couch at my mom...   \n",
       "\n",
       "                                              selection1  label  \n",
       "0      Sam went into his backyard to dig a hole for a...      0  \n",
       "1      Tim needed to take a large test to graduate fr...      1  \n",
       "2         They were in my mom's garden when I was a kid.      0  \n",
       "3                     The photos ended up looking great.      0  \n",
       "4      It was far too sour and Suzy never wanted coff...      1  \n",
       "...                                                  ...    ...  \n",
       "43190                  The teacher heard the phone ring.      0  \n",
       "43191      I wish people in the theatre weren't so rude.      1  \n",
       "43192  He then told everyone how cool and manly Theo ...      0  \n",
       "43193  When we were walking together, I noticed that ...      0  \n",
       "43194  A few weeks ago, our family went to Washington...      0  \n",
       "\n",
       "[43195 rows x 5 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDatasetProcessed.to_csv(f'./dataset/2Select-{fileTag}-test.csv')\n",
    "testDatasetProcessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7283c1-d83e-4369-b5e4-6c2e09d654ac",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "828a5092-83e6-4580-99c9-bd9ec434708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05151e3b-0bec-44f4-bf0a-ac58cddbf838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-52ca1ef45d27d0a7\n",
      "Reusing dataset csv (C:\\Users\\JAM_0\\.cache\\huggingface\\datasets\\csv\\default-52ca1ef45d27d0a7\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb26f6788d84ef1aea3e9977b2c3a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('csv', data_files={'train': f'./dataset/2Select-{fileTag}-train.csv', \n",
    "                                           'test': f'./dataset/2Select-{fileTag}-test.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d776c270-7752-4445-ba6c-eb078f71eccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'emotion', 'plutchik', 'selection0', 'selection1', 'label'],\n",
       "        num_rows: 53234\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'emotion', 'plutchik', 'selection0', 'selection1', 'label'],\n",
       "        num_rows: 51891\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1c79159-f795-4d02-b052-94f04286d53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 0,\n",
       " 'emotion': \"['upset']\",\n",
       " 'plutchik': \"{'joy': 0, 'trust': 0, 'fear': 3, 'surprise': 3, 'sadness': 3, 'disgust': 3, 'anger': 3, 'anticipation': 0}\",\n",
       " 'selection0': \"Yesterday, she found out she's going to have to work on Thanksgiving.\",\n",
       " 'selection1': 'Ben worked on a report late at night.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f6ad67d-b4cb-4f65-a9cb-d2d665deec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_one(example):\n",
    "    print(f\"Context: {example['plutchik']}\")\n",
    "    print(f\"  A - {example['selection0']}\")\n",
    "    print(f\"  B - {example['selection1']}\")\n",
    "    print(f\"\\nGround truth: option {['A', 'B'][example['label']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "15cd7cfb-748a-4fe7-8152-7debf6a65ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: {'joy': 0, 'trust': 3, 'fear': 0, 'surprise': 0, 'sadness': 0, 'disgust': 0, 'anger': 0, 'anticipation': 3}\n",
      "  A - Rob was really hoping to work on a new important project.\n",
      "  B - They dog's rarely barked at or jumped at her grandma.\n",
      "\n",
      "Ground truth: option A\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da93346-1037-41ed-b67d-91877fa8c0ec",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3da78c12-9aff-4beb-a006-e287bbf61023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at C:\\Users\\JAM_0/.cache\\huggingface\\transformers\\733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at C:\\Users\\JAM_0/.cache\\huggingface\\transformers\\d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at C:\\Users\\JAM_0/.cache\\huggingface\\transformers\\cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer.json from cache at C:\\Users\\JAM_0/.cache\\huggingface\\transformers\\d53fc0fa09b8342651efd4073d75e19617b3e51287c2a535becda5808a8db287.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at C:\\Users\\JAM_0/.cache\\huggingface\\transformers\\733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if model_checkpoint != 'distilbert-base-uncased-finetuned-sst-2-english':\n",
    "    from transformers import AutoTokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "else:\n",
    "    from transformers import DistilBertTokenizer, DistilBertForMultipleChoice\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "caffe397-a65d-478f-b966-7b910fb2edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "selectionList = [\"selection0\", \"selection1\"]\n",
    "weightRemap = [\"NOT \", \"LITTLE \", \"\", \"VERY \", \"ABSOLUTELY \"]\n",
    "def preprocess_function(examples):\n",
    "    # Repeat each first sentence four times to go with the four possibilities of second sentences.\n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(context.strip(\"[\").strip(\"]\").replace('\\'', '')) ]*2 for context in examples[\"emotion\"] ]\n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(context.strip(\"[\").strip(\"]\").replace('\\\"', '')) ]*2 for context in examples[\"plutchik\"] ]\n",
    "    first_sentences = [[\"The following sentences contain emotions: {}\".format(\", \".join([weightRemap[int(eachCaseWeight.replace(\"]\", \"\").replace(\"[\", \"\").replace(\"}\", \"\").replace(\"{\", \"\").replace(\"\\\"\", \"\").replace(\"\\'\", \"\"))] \n",
    "                                                        + eachCaseEmotionType.replace(\"]\", \"\").replace(\"[\", \"\").replace(\"}\", \"\").replace(\"{\", \"\").replace(\"\\\"\", \"\").replace(\"\\'\", \"\").strip()\n",
    "                        for eachCaseWeight, eachCaseEmotionType in \n",
    "                        zip([re.split(':|,',eachEmotionCombination)[1::2] for eachEmotionCombination in examples[\"plutchik\"]][eventIndex], \n",
    "                           [re.split(':|,',eachEmotionCombination)[::2] for eachEmotionCombination in examples[\"plutchik\"]][eventIndex])]))]*2 for eventIndex in \n",
    "                           range(len([re.split(':|,',eachEmotionCombination)[1::2] for eachEmotionCombination in examples[\"plutchik\"]]))]\n",
    "    \n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(', '.join([(weightRemap[eachEmotion[1]] + \" \" +eachEmotion[0]).strip() \n",
    "    #                    for eachEmotion in ast.literal_eval(context).items()]))]*2 \n",
    "    #                    for context in examples[\"plutchik\"]]\n",
    "    # Grab all second sentences possible for each context.\n",
    "    second_sentences = [[examples[selection][index] for selection in selectionList]for index in range(len(examples['selection0']))]\n",
    "\n",
    "    # Flatten everything\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "    \n",
    "    # Tokenize\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "    # Un-flatten\n",
    "    # print(tokenized_examples.items())\n",
    "    return {k: [v[i:i+2] for i in range(0, len(v), 2)] for k, v in tokenized_examples.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0afb4841-ab69-4b91-8859-fd249badb923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2 [45, 46]\n"
     ]
    }
   ],
   "source": [
    "examples = dataset[\"train\"][:5]\n",
    "features = preprocess_function(examples)\n",
    "print(len(features[\"input_ids\"]), len(features[\"input_ids\"][0]), [len(x) for x in features[\"input_ids\"][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "903e2891-0e3d-4e87-b98a-727eaf36417a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>The following sentences contain emotions: NOT joy, VERY trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, VERY anticipation</s></s>Rob was really hoping to work on a new important project.</s>',\n",
       " '<s>The following sentences contain emotions: NOT joy, NOT trust, NOT fear, surprise, VERY sadness, disgust, anger, NOT anticipation</s></s>Next morning i convinced my friend that i will copy her assignment.</s>',\n",
       " '<s>The following sentences contain emotions: NOT joy, NOT trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation</s></s>Dan bought every single package of cookies the girls had!</s>',\n",
       " '<s>The following sentences contain emotions: NOT joy, NOT trust, fear, NOT surprise, NOT sadness, disgust, anger, NOT anticipation</s></s>Dan bought every single package of cookies the girls had!</s>',\n",
       " \"<s>The following sentences contain emotions: NOT joy, NOT trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation</s></s>Mary decided to be more cautious so she wouldn't miss any stop signs.</s>\"]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(features[\"input_ids\"][a][i]) for a in range(5) for i in range(1) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a286ba6-cb84-4619-b842-780124d26a4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dd4ccecf0f14a9ebd4da71593c38379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3de75bf20c4416a0e43ca578d0a22d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7706d875-3a89-4e52-9f08-c77256b621ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at C:\\Users\\JAM_0/.cache\\huggingface\\transformers\\733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at C:\\Users\\JAM_0/.cache\\huggingface\\transformers\\51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForMultipleChoice: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "if model_checkpoint != 'distilbert-base-uncased-finetuned-sst-2-english':\n",
    "    from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "    model = AutoModelForMultipleChoice.from_pretrained(model_checkpoint)\n",
    "else:\n",
    "    from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "    from transformers import DistilBertTokenizer, DistilBertForMultipleChoice\n",
    "    import torch\n",
    "    model = DistilBertForMultipleChoice.from_pretrained(\"distilbert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2cd7be65-ebd8-43db-bcbf-a87d7e2342e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-emotionCommonsense\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=5e-6, # for bert-base\n",
    "    # learning_rate=1e-3,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2737e04e-19c2-407d-8ce1-06b675f208c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [[{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        # Un-flatten\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        # Add back labels\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "03a0ec05-de5e-434f-b07c-63212e7c7f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_keys = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "features = [{k: v for k, v in encoded_datasets[\"train\"][i].items() if k in accepted_keys} for i in range(10)]\n",
    "batch = DataCollatorForMultipleChoice(tokenizer)(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "45f7f26c-04bb-42ae-8627-897ced69888e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>The following sentences contain emotions: VERY joy, VERY trust, NOT fear, surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation</s></s>So he kept adding more and more ingredients.</s><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<s>The following sentences contain emotions: VERY joy, VERY trust, NOT fear, surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation</s></s>The two had been buddies for years.</s><pad><pad><pad><pad><pad><pad><pad><pad>']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(batch[\"input_ids\"][8][i].tolist()) for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c4b55256-30fa-4e30-a3a4-66fe1114b941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: {'joy': 3, 'trust': 3, 'fear': 0, 'surprise': 2, 'sadness': 0, 'disgust': 0, 'anger': 0, 'anticipation': 0}\n",
      "  A - So he kept adding more and more ingredients.\n",
      "  B - The two had been buddies for years.\n",
      "\n",
      "Ground truth: option B\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8305d3-8dc9-4d0f-8628-f51dc356c2d2",
   "metadata": {},
   "source": [
    "# Trainer Defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b707863a-bc16-43b0-b633-c7ffb4fa72e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "valStored = []\n",
    "def compute_metrics(eval_predictions):\n",
    "    predictions, label_ids = eval_predictions\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    valStored.append((preds != label_ids).astype(np.float32));\n",
    "    return {\"accuracy\": (preds == label_ids).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b115c1ba-323a-47d5-bb9d-55de985f13b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_datasets[\"train\"],\n",
    "    eval_dataset=encoded_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5e3430-bbd6-484d-8a8d-9cbcdba37d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `RobertaForMultipleChoice.forward` and have been ignored: emotion, selection0, plutchik, selection1, Unnamed: 0. If emotion, selection0, plutchik, selection1, Unnamed: 0 are not expected by `RobertaForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "C:\\Python\\miniconda3\\envs\\pytorchEnvWithDataSci\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 53234\n",
      "  Num Epochs = 16\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53248\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3621' max='53248' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3621/53248 08:59 < 2:03:11, 6.71 it/s, Epoch 1.09/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.581400</td>\n",
       "      <td>0.558830</td>\n",
       "      <td>0.696055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to roberta-base-finetuned-emotionCommonsense\\checkpoint-500\n",
      "Configuration saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-500\\config.json\n",
      "Model weights saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-500\\special_tokens_map.json\n",
      "Saving model checkpoint to roberta-base-finetuned-emotionCommonsense\\checkpoint-1000\n",
      "Configuration saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-1000\\config.json\n",
      "Model weights saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-1000\\special_tokens_map.json\n",
      "Saving model checkpoint to roberta-base-finetuned-emotionCommonsense\\checkpoint-1500\n",
      "Configuration saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-1500\\config.json\n",
      "Model weights saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-1500\\pytorch_model.bin\n",
      "tokenizer config file saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-1500\\special_tokens_map.json\n",
      "Saving model checkpoint to roberta-base-finetuned-emotionCommonsense\\checkpoint-2000\n",
      "Configuration saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-2000\\config.json\n",
      "Model weights saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-2000\\special_tokens_map.json\n",
      "Saving model checkpoint to roberta-base-finetuned-emotionCommonsense\\checkpoint-2500\n",
      "Configuration saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-2500\\config.json\n",
      "Model weights saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-2500\\pytorch_model.bin\n",
      "tokenizer config file saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-2500\\tokenizer_config.json\n",
      "Special tokens file saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-2500\\special_tokens_map.json\n",
      "Saving model checkpoint to roberta-base-finetuned-emotionCommonsense\\checkpoint-3000\n",
      "Configuration saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-3000\\config.json\n",
      "Model weights saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-3000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForMultipleChoice.forward` and have been ignored: emotion, selection0, plutchik, selection1, Unnamed: 0. If emotion, selection0, plutchik, selection1, Unnamed: 0 are not expected by `RobertaForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to roberta-base-finetuned-emotionCommonsense\\checkpoint-3500\n",
      "Configuration saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-3500\\config.json\n",
      "Model weights saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-3500\\pytorch_model.bin\n",
      "tokenizer config file saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-3500\\tokenizer_config.json\n",
      "Special tokens file saved in roberta-base-finetuned-emotionCommonsense\\checkpoint-3500\\special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a17948-a8f7-4450-b2b0-8a7016e91391",
   "metadata": {},
   "source": [
    "出现validation loss 上升情况大多是训练集验证集数据分布不一致，或者训练集过小，未包含验证集中所有情况，\n",
    "也就是过拟合导致的。而解决这种现象可以尝试以下几种策略：\n",
    "1. 增加训练样本增加正则项系数权重，\n",
    "2. 减小过拟合加入早停机制，ValLoss上升几个epoch直接停止\n",
    "3. 采用Focal Loss\n",
    "4. 加入Label Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d6ab3-33ac-4e8e-99ee-3c3f17d71642",
   "metadata": {},
   "source": [
    "# Store Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30271fe-7ce9-43e8-9e87-de8d6ae2c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "Z = np.transpose(valStored)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.pcolormesh(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e77d30e-e51a-45a6-9130-83a17c4d2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "if model_checkpoint == 'distilbert-base-uncased-finetuned-sst-2-english':\n",
    "    model_checkpoint = 'distilbert-base'\n",
    "dataLog = pd.DataFrame(trainer.state.log_history)\n",
    "dataLog.to_csv(f'./trainingMetric/[Plutchik] 2Select/TI-{model_checkpoint}-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c90cfec4-96ec-46c8-a99f-3c78b989b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluationIterationResult = pd.DataFrame(np.transpose(valStored))\n",
    "evaluationIterationResult.to_csv(f'./trainingMetric/[Plutchik] 2Select/ESI-{model_checkpoint}-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd7f330-1477-4119-a9dc-1ebb7acb7665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchEnvWithDataSci",
   "language": "python",
   "name": "pytorchenvwithdatasci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
