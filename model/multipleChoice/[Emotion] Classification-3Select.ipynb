{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1615a8a-9813-4956-b4ed-33ef2ea30723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'distilbert-base-uncased-finetuned-sst-2-english'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# global var set\n",
    "import transformers\n",
    "\n",
    "# model info, change as needed\n",
    "# model_checkpoint = \"roberta-base\"\n",
    "model_checkpoint = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "batch_size = 16\n",
    "num_epochs = 16\n",
    "\n",
    "# fileTag = \"clean-v1\"                      # clean + no phase + combine    (pure clean)\n",
    "# fileTag = \"clean-phase-v1\"                # clean +   phase  + combine\n",
    "# fileTag = 'clean-phase-noCombin-v1'       # clean +   phase  + no combine\n",
    "fileTag = 'original-noCheat-noCombin-v1'  # raw   +   no Cheat case\n",
    "# fileTag = 'original'                        # row   +   keep Cheat case     (pure raw) \n",
    "\n",
    "fileTag\n",
    "model_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b9d76f-5ed6-4ab9-8c62-f6d6a8b47be4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Convert dataset to suitable format\n",
    "IMPORTANT: please never run this section again if you have your dataset ready!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a93a9f46-6703-4535-af96-8be1b5b3407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "trainDatasetOriginal = pd.read_csv(f'../../data/csv_version/dev/emotion/allcharlinepairs-{fileTag}.csv')\n",
    "testDatasetOriginal = pd.read_csv(f'../../data/csv_version/test/emotion/allcharlinepairs-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7265a797-adc2-49ed-b237-19abf9e0569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatasetProcessed = DataFrame({'emotion' : trainDatasetOriginal['emotion'],\n",
    "                                   'plutchik' : trainDatasetOriginal['plutchik'],\n",
    "                                  'selection0': pd.concat([trainDatasetOriginal['sentence'][:trainDatasetOriginal.shape[0]//3], trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//3:]]), \n",
    "                                  'selection1': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//3], \n",
    "                                                pd.concat([trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//3 : trainDatasetOriginal.shape[0]//3*2], \n",
    "                                                           trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//3*2:]])]), \n",
    "                                  'selection2': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//3*2], \n",
    "                                                           trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//3*2:]]),\n",
    "                                  'label': pd.Series(0 if x < trainDatasetOriginal.shape[0]//3 else (1 if x < trainDatasetOriginal.shape[0]//3*2 else 2) for x in trainDatasetOriginal.index)}).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "testDatasetProcessed = DataFrame({'emotion' : testDatasetOriginal['emotion'],\n",
    "                                   'plutchik' : testDatasetOriginal['plutchik'],\n",
    "                                  'selection0': pd.concat([testDatasetOriginal['sentence'][:testDatasetOriginal.shape[0]//3], testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//3:]]), \n",
    "                                  'selection1': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//3], \n",
    "                                                pd.concat([testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//3 : testDatasetOriginal.shape[0]//3*2], \n",
    "                                                testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//3*2:]])]), \n",
    "                                  'selection2': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//3*2], \n",
    "                                                           testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//3*2:]]),\n",
    "                                  'label': pd.Series(0 if x < testDatasetOriginal.shape[0]//3 else (1 if x < testDatasetOriginal.shape[0]//3*2 else 2) for x in testDatasetOriginal.index)}).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "19e3c334-b371-44ad-b6e1-7161f405b741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>plutchik</th>\n",
       "      <th>selection0</th>\n",
       "      <th>selection1</th>\n",
       "      <th>selection2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['joy']</td>\n",
       "      <td>{'joy': 3, 'trust': 3, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>His friend Doug had taunted him for having a l...</td>\n",
       "      <td>After takeoff Jane started to calm down.</td>\n",
       "      <td>They gathered their clothes and shoes and went...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['frustrated']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>John grew complacent though, and he stopped pr...</td>\n",
       "      <td>Brian got lost between rides.</td>\n",
       "      <td>Brandon tried everything but he couldn't solve...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['glad']</td>\n",
       "      <td>{'joy': 2, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>After mulling it over the owner decided not to...</td>\n",
       "      <td>Joe and Jane were two candidates for a job.</td>\n",
       "      <td>He went home and his mom saw his knees, but he...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['excited']</td>\n",
       "      <td>{'joy': 3, 'trust': 2, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>The little girl pointed at Biscuit!</td>\n",
       "      <td>She ended up with five bluegill!</td>\n",
       "      <td>The girls screamed.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['relieved']</td>\n",
       "      <td>{'joy': 3, 'trust': 3, 'fear': 2, 'surprise': ...</td>\n",
       "      <td>At the store, they choose a king sized pillow ...</td>\n",
       "      <td>The woman braided her hair.</td>\n",
       "      <td>Eventually the power turned back on and she go...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53113</th>\n",
       "      <td>['positive']</td>\n",
       "      <td>{'joy': 3, 'trust': 2, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Jordan's mom is happy to see her little girl g...</td>\n",
       "      <td>The doll sold for $50.</td>\n",
       "      <td>The price was too high and he quit.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53114</th>\n",
       "      <td>['Startled']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 3, 'surprise': ...</td>\n",
       "      <td>She pulled her owner around the corner.</td>\n",
       "      <td>Andrew got his revenge in Halloween and scared...</td>\n",
       "      <td>He sang along to the song.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53115</th>\n",
       "      <td>['desperate']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>He felt something brush his leg.</td>\n",
       "      <td>He tacked it to every telephone pole around hi...</td>\n",
       "      <td>One day he finally took advice from his dad.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53116</th>\n",
       "      <td>['concerned', 'upset']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 3, 'surprise': ...</td>\n",
       "      <td>After a while, the kid caught every ball.</td>\n",
       "      <td>Cayla wanted her hair cut.</td>\n",
       "      <td>Mimi realized she had contracted the e coli ba...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53117</th>\n",
       "      <td>['satisfied']</td>\n",
       "      <td>{'joy': 2, 'trust': 2, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>A V P. of the company came out to stake out th...</td>\n",
       "      <td>Soon, her behavior made no one want to be frie...</td>\n",
       "      <td>We had good friends in our condo from 1993 to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53118 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      emotion  \\\n",
       "0                     ['joy']   \n",
       "1              ['frustrated']   \n",
       "2                    ['glad']   \n",
       "3                 ['excited']   \n",
       "4                ['relieved']   \n",
       "...                       ...   \n",
       "53113            ['positive']   \n",
       "53114            ['Startled']   \n",
       "53115           ['desperate']   \n",
       "53116  ['concerned', 'upset']   \n",
       "53117           ['satisfied']   \n",
       "\n",
       "                                                plutchik  \\\n",
       "0      {'joy': 3, 'trust': 3, 'fear': 0, 'surprise': ...   \n",
       "1      {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "2      {'joy': 2, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "3      {'joy': 3, 'trust': 2, 'fear': 0, 'surprise': ...   \n",
       "4      {'joy': 3, 'trust': 3, 'fear': 2, 'surprise': ...   \n",
       "...                                                  ...   \n",
       "53113  {'joy': 3, 'trust': 2, 'fear': 0, 'surprise': ...   \n",
       "53114  {'joy': 0, 'trust': 0, 'fear': 3, 'surprise': ...   \n",
       "53115  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "53116  {'joy': 0, 'trust': 0, 'fear': 3, 'surprise': ...   \n",
       "53117  {'joy': 2, 'trust': 2, 'fear': 0, 'surprise': ...   \n",
       "\n",
       "                                              selection0  \\\n",
       "0      His friend Doug had taunted him for having a l...   \n",
       "1      John grew complacent though, and he stopped pr...   \n",
       "2      After mulling it over the owner decided not to...   \n",
       "3                    The little girl pointed at Biscuit!   \n",
       "4      At the store, they choose a king sized pillow ...   \n",
       "...                                                  ...   \n",
       "53113  Jordan's mom is happy to see her little girl g...   \n",
       "53114            She pulled her owner around the corner.   \n",
       "53115                   He felt something brush his leg.   \n",
       "53116          After a while, the kid caught every ball.   \n",
       "53117  A V P. of the company came out to stake out th...   \n",
       "\n",
       "                                              selection1  \\\n",
       "0               After takeoff Jane started to calm down.   \n",
       "1                          Brian got lost between rides.   \n",
       "2            Joe and Jane were two candidates for a job.   \n",
       "3                       She ended up with five bluegill!   \n",
       "4                            The woman braided her hair.   \n",
       "...                                                  ...   \n",
       "53113                             The doll sold for $50.   \n",
       "53114  Andrew got his revenge in Halloween and scared...   \n",
       "53115  He tacked it to every telephone pole around hi...   \n",
       "53116                         Cayla wanted her hair cut.   \n",
       "53117  Soon, her behavior made no one want to be frie...   \n",
       "\n",
       "                                              selection2  label  \n",
       "0      They gathered their clothes and shoes and went...      2  \n",
       "1      Brandon tried everything but he couldn't solve...      2  \n",
       "2      He went home and his mom saw his knees, but he...      0  \n",
       "3                                    The girls screamed.      2  \n",
       "4      Eventually the power turned back on and she go...      2  \n",
       "...                                                  ...    ...  \n",
       "53113                The price was too high and he quit.      0  \n",
       "53114                         He sang along to the song.      1  \n",
       "53115       One day he finally took advice from his dad.      2  \n",
       "53116  Mimi realized she had contracted the e coli ba...      2  \n",
       "53117  We had good friends in our condo from 1993 to ...      0  \n",
       "\n",
       "[53118 rows x 6 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDatasetProcessed.to_csv(f'./dataset/3Select-{fileTag}-train.csv')\n",
    "trainDatasetProcessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b770299d-567d-46e2-b928-8ee31a341c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>plutchik</th>\n",
       "      <th>selection0</th>\n",
       "      <th>selection1</th>\n",
       "      <th>selection2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"frustrated\"]</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 3, 'surprise': ...</td>\n",
       "      <td>Lillian went to school that day with a headache.</td>\n",
       "      <td>His family has tried several therapies without...</td>\n",
       "      <td>Allie was babysitting a four year old.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"accomplished\"]</td>\n",
       "      <td>{'joy': 3, 'trust': 3, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Back as his table, a woman winked at him, thin...</td>\n",
       "      <td>He smothered it with whip cream and it tasted ...</td>\n",
       "      <td>And performed adequately in his class.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"happy\"]</td>\n",
       "      <td>{'joy': 2, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Afterward, Sandy's parents said she had been v...</td>\n",
       "      <td>Jim no longer has a driver's license.</td>\n",
       "      <td>Mia took a cab home, and was angry at her daug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"welcoming\"]</td>\n",
       "      <td>{'joy': 3, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>I went to fun parties.</td>\n",
       "      <td>Gage wanted to go camping very badly.</td>\n",
       "      <td>He was getting pushed into the lockers everyday.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"content\"]</td>\n",
       "      <td>{'joy': 2, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Heather gives her niece anything she asks for ...</td>\n",
       "      <td>At first she thought she wouldn't like it but ...</td>\n",
       "      <td>His parents talked it over and agreed to give ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51886</th>\n",
       "      <td>[\"none\"]</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>After starting it up, John began to mow his lawn.</td>\n",
       "      <td>He kept getting raises year after year.</td>\n",
       "      <td>However, this time, the teacher punished her h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51887</th>\n",
       "      <td>[\"proud\"]</td>\n",
       "      <td>{'joy': 3, 'trust': 3, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>I cheered wildly.</td>\n",
       "      <td>When he found out he got an A, he thanked Mike...</td>\n",
       "      <td>Karen wore a grizzly bear necklace.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51888</th>\n",
       "      <td>[\"interested\"]</td>\n",
       "      <td>{'joy': 2, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>When it opened she went with her best friend.</td>\n",
       "      <td>Jan regretted wearing the sweater since she ha...</td>\n",
       "      <td>Rex uses a few online resources and also gets ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51889</th>\n",
       "      <td>[\"accomplished\", \"worried about the future\"]</td>\n",
       "      <td>{'joy': 3, 'trust': 2, 'fear': 3, 'surprise': ...</td>\n",
       "      <td>Evan realized that he could see his classmate'...</td>\n",
       "      <td>John was now sober for a year.</td>\n",
       "      <td>I was front squatting in the gym.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51890</th>\n",
       "      <td>[\"none\"]</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Mira was a very old woman who lived by herself.</td>\n",
       "      <td>Alex loves horror movies.</td>\n",
       "      <td>He was eating gummy bears.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51891 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            emotion  \\\n",
       "0                                    [\"frustrated\"]   \n",
       "1                                  [\"accomplished\"]   \n",
       "2                                         [\"happy\"]   \n",
       "3                                     [\"welcoming\"]   \n",
       "4                                       [\"content\"]   \n",
       "...                                             ...   \n",
       "51886                                      [\"none\"]   \n",
       "51887                                     [\"proud\"]   \n",
       "51888                                [\"interested\"]   \n",
       "51889  [\"accomplished\", \"worried about the future\"]   \n",
       "51890                                      [\"none\"]   \n",
       "\n",
       "                                                plutchik  \\\n",
       "0      {'joy': 0, 'trust': 0, 'fear': 3, 'surprise': ...   \n",
       "1      {'joy': 3, 'trust': 3, 'fear': 0, 'surprise': ...   \n",
       "2      {'joy': 2, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "3      {'joy': 3, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "4      {'joy': 2, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "...                                                  ...   \n",
       "51886  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "51887  {'joy': 3, 'trust': 3, 'fear': 0, 'surprise': ...   \n",
       "51888  {'joy': 2, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "51889  {'joy': 3, 'trust': 2, 'fear': 3, 'surprise': ...   \n",
       "51890  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "\n",
       "                                              selection0  \\\n",
       "0       Lillian went to school that day with a headache.   \n",
       "1      Back as his table, a woman winked at him, thin...   \n",
       "2      Afterward, Sandy's parents said she had been v...   \n",
       "3                                 I went to fun parties.   \n",
       "4      Heather gives her niece anything she asks for ...   \n",
       "...                                                  ...   \n",
       "51886  After starting it up, John began to mow his lawn.   \n",
       "51887                                  I cheered wildly.   \n",
       "51888      When it opened she went with her best friend.   \n",
       "51889  Evan realized that he could see his classmate'...   \n",
       "51890    Mira was a very old woman who lived by herself.   \n",
       "\n",
       "                                              selection1  \\\n",
       "0      His family has tried several therapies without...   \n",
       "1      He smothered it with whip cream and it tasted ...   \n",
       "2                  Jim no longer has a driver's license.   \n",
       "3                  Gage wanted to go camping very badly.   \n",
       "4      At first she thought she wouldn't like it but ...   \n",
       "...                                                  ...   \n",
       "51886            He kept getting raises year after year.   \n",
       "51887  When he found out he got an A, he thanked Mike...   \n",
       "51888  Jan regretted wearing the sweater since she ha...   \n",
       "51889                     John was now sober for a year.   \n",
       "51890                          Alex loves horror movies.   \n",
       "\n",
       "                                              selection2  label  \n",
       "0                 Allie was babysitting a four year old.      1  \n",
       "1                 And performed adequately in his class.      2  \n",
       "2      Mia took a cab home, and was angry at her daug...      0  \n",
       "3       He was getting pushed into the lockers everyday.      0  \n",
       "4      His parents talked it over and agreed to give ...      1  \n",
       "...                                                  ...    ...  \n",
       "51886  However, this time, the teacher punished her h...      1  \n",
       "51887                Karen wore a grizzly bear necklace.      0  \n",
       "51888  Rex uses a few online resources and also gets ...      2  \n",
       "51889                  I was front squatting in the gym.      1  \n",
       "51890                         He was eating gummy bears.      2  \n",
       "\n",
       "[51891 rows x 6 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDatasetProcessed.to_csv(f'./dataset/3Select-{fileTag}-test.csv')\n",
    "testDatasetProcessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7283c1-d83e-4369-b5e4-6c2e09d654ac",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "828a5092-83e6-4580-99c9-bd9ec434708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05151e3b-0bec-44f4-bf0a-ac58cddbf838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b6fdc6ef4fc7466c\n",
      "Reusing dataset csv (C:\\Users\\JAM_0\\.cache\\huggingface\\datasets\\csv\\default-b6fdc6ef4fc7466c\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a04d312e1741729199950e577e8e83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('csv', data_files={'train': f'./dataset/3Select-{fileTag}-train.csv', \n",
    "                                           'test': f'./dataset/3Select-{fileTag}-test.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d776c270-7752-4445-ba6c-eb078f71eccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'emotion', 'plutchik', 'selection0', 'selection1', 'selection2', 'label'],\n",
       "        num_rows: 53118\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'emotion', 'plutchik', 'selection0', 'selection1', 'selection2', 'label'],\n",
       "        num_rows: 51891\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1c79159-f795-4d02-b052-94f04286d53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 0,\n",
       " 'emotion': '[\"frustrated\"]',\n",
       " 'plutchik': \"{'joy': 0, 'trust': 0, 'fear': 3, 'surprise': 3, 'sadness': 3, 'disgust': 3, 'anger': 3, 'anticipation': 0}\",\n",
       " 'selection0': 'Lillian went to school that day with a headache.',\n",
       " 'selection1': 'His family has tried several therapies without success.',\n",
       " 'selection2': 'Allie was babysitting a four year old.',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f6ad67d-b4cb-4f65-a9cb-d2d665deec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_one(example):\n",
    "    print(f\"Context: {example['emotion']}\")\n",
    "    print(f\"  A - {example['selection0']}\")\n",
    "    print(f\"  B - {example['selection1']}\")\n",
    "    print(f\"  C - {example['selection2']}\")\n",
    "    print(f\"\\nGround truth: option {['A', 'B', 'C'][example['label']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15cd7cfb-748a-4fe7-8152-7debf6a65ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: ['frustrated']\n",
      "  A - John grew complacent though, and he stopped practicing.\n",
      "  B - Brian got lost between rides.\n",
      "  C - Brandon tried everything but he couldn't solve the math problem.\n",
      "\n",
      "Ground truth: option C\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da93346-1037-41ed-b67d-91877fa8c0ec",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3da78c12-9aff-4beb-a006-e287bbf61023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "from transformers import DistilBertTokenizer, DistilBertForMultipleChoice\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caffe397-a65d-478f-b966-7b910fb2edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectionList = [\"selection0\", \"selection1\", \"selection2\"]\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Repeat each first sentence four times to go with the four possibilities of second sentences.\n",
    "    first_sentences = [[\"The following sentences contain emotions: {}\".format(context.strip(\"[\").strip(\"]\").replace('\\'', '')) ]*3 for context in examples[\"emotion\"]]\n",
    "    # Grab all second sentences possible for each context.\n",
    "    second_sentences = [[examples[selection][index] for selection in selectionList] for index in range(len(examples['selection0']))]\n",
    "\n",
    "    # Flatten everything\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "    \n",
    "    # Tokenize\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "    # Un-flatten\n",
    "    # print(tokenized_examples.items())\n",
    "    return {k: [v[i:i+3] for i in range(0, len(v), 3)] for k, v in tokenized_examples.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0afb4841-ab69-4b91-8859-fd249badb923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 3 [23, 18, 20]\n"
     ]
    }
   ],
   "source": [
    "examples = dataset[\"train\"][:5]\n",
    "features = preprocess_function(examples)\n",
    "print(len(features[\"input_ids\"]), len(features[\"input_ids\"][0]), [len(x) for x in features[\"input_ids\"][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "903e2891-0e3d-4e87-b98a-727eaf36417a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] The following sentences contain emotions : joy [SEP] His friend Doug had taunted him for having a large nose. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : joy [SEP] After takeoff Jane started to calm down. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : joy [SEP] They gathered their clothes and shoes and went home. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : frustrated [SEP] John grew complacent though, and he stopped practicing. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : frustrated [SEP] Brian got lost between rides. [SEP]',\n",
       " \"[CLS] The following sentences contain emotions : frustrated [SEP] Brandon tried everything but he couldn't solve the math problem. [SEP]\",\n",
       " '[CLS] The following sentences contain emotions : glad [SEP] After mulling it over the owner decided not to sell. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : glad [SEP] Joe and Jane were two candidates for a job. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : glad [SEP] He went home and his mom saw his knees, but helped him heal. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : excited [SEP] The little girl pointed at Biscuit! [SEP]',\n",
       " '[CLS] The following sentences contain emotions : excited [SEP] She ended up with five bluegill! [SEP]',\n",
       " '[CLS] The following sentences contain emotions : excited [SEP] The girls screamed. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : relieved [SEP] At the store, they choose a king sized pillow top bed. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : relieved [SEP] The woman braided her hair. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : relieved [SEP] Eventually the power turned back on and she got up. [SEP]']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(features[\"input_ids\"][a][i]) for a in range(5) for i in range(3) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a286ba6-cb84-4619-b842-780124d26a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\JAM_0\\.cache\\huggingface\\datasets\\csv\\default-b6fdc6ef4fc7466c\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-f585c12f4db92e91.arrow\n",
      "Loading cached processed dataset at C:\\Users\\JAM_0\\.cache\\huggingface\\datasets\\csv\\default-b6fdc6ef4fc7466c\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-2053fe78183013bb.arrow\n"
     ]
    }
   ],
   "source": [
    "encoded_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f496be7-4673-4520-b30e-656cd5640b34",
   "metadata": {},
   "source": [
    "# Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7706d875-3a89-4e52-9f08-c77256b621ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForMultipleChoice: ['vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForMultipleChoice were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "from transformers import DistilBertTokenizer, DistilBertForMultipleChoice\n",
    "import torch\n",
    "model = DistilBertForMultipleChoice.from_pretrained(\"distilbert-base-cased\")\n",
    "\n",
    "# model = AutoModelForMultipleChoice.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cd7be65-ebd8-43db-bcbf-a87d7e2342e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-emotionCommonsense\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    # learning_rate=5e-5, # for bert-base\n",
    "    learning_rate=5e-7, # for roberta-base\n",
    "    # learning_rate=1e-3,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2737e04e-19c2-407d-8ce1-06b675f208c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [[{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        # Un-flatten\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        # Add back labels\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03a0ec05-de5e-434f-b07c-63212e7c7f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_keys = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "features = [{k: v for k, v in encoded_datasets[\"train\"][i].items() if k in accepted_keys} for i in range(10)]\n",
    "batch = DataCollatorForMultipleChoice(tokenizer)(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45f7f26c-04bb-42ae-8627-897ced69888e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] The following sentences contain emotions : cold, scared, thankful [SEP] Fargo finds a cat while playing in the yard. [SEP] [PAD] [PAD]',\n",
       " '[CLS] The following sentences contain emotions : cold, scared, thankful [SEP] He gave her his coat to warm herself. [SEP] [PAD] [PAD] [PAD]',\n",
       " '[CLS] The following sentences contain emotions : cold, scared, thankful [SEP] He told me he had cellulitis of the foot. [SEP]']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(batch[\"input_ids\"][8][i].tolist()) for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4b55256-30fa-4e30-a3a4-66fe1114b941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: ['cold', 'scared', 'thankful']\n",
      "  A - Fargo finds a cat while playing in the yard.\n",
      "  B - He gave her his coat to warm herself.\n",
      "  C - He told me he had cellulitis of the foot.\n",
      "\n",
      "Ground truth: option B\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8305d3-8dc9-4d0f-8628-f51dc356c2d2",
   "metadata": {},
   "source": [
    "# Trainer Defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b707863a-bc16-43b0-b633-c7ffb4fa72e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "valStored = []\n",
    "def compute_metrics(eval_predictions):\n",
    "    predictions, label_ids = eval_predictions\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    valStored.append((preds != label_ids).astype(np.float32));\n",
    "    return {\"accuracy\": (preds == label_ids).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b115c1ba-323a-47d5-bb9d-55de985f13b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_datasets[\"train\"],\n",
    "    eval_dataset=encoded_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df5a83ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 22 20:55:15 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 511.65       Driver Version: 511.65       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   46C    P2   104W / 370W |   9086MiB / 10240MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1492    C+G                                   N/A      |\n",
      "|    0   N/A  N/A      8512    C+G   ...d\\runtime\\WeChatAppEx.exe    N/A      |\n",
      "|    0   N/A  N/A      8708      C   ...EnvWithDataSci\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     10292    C+G   ...er_engine\\wallpaper64.exe    N/A      |\n",
      "|    0   N/A  N/A     10796    C+G                                   N/A      |\n",
      "|    0   N/A  N/A     11932    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     13644    C+G   ...8bbwe\\Microsoft.Notes.exe    N/A      |\n",
      "|    0   N/A  N/A     14008    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     14016    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     14880    C+G   ...tracted\\WechatBrowser.exe    N/A      |\n",
      "|    0   N/A  N/A     16340    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     16604    C+G   ...urrent\\LogiOptionsMgr.exe    N/A      |\n",
      "|    0   N/A  N/A     16628    C+G   ...e\\Current\\LogiOverlay.exe    N/A      |\n",
      "|    0   N/A  N/A     19884    C+G   ...\\app-1.0.9005\\Discord.exe    N/A      |\n",
      "|    0   N/A  N/A     21732    C+G   ...245.44\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     22292    C+G   ...tracted\\WechatBrowser.exe    N/A      |\n",
      "|    0   N/A  N/A     22540    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     23456    C+G   ...ck\\app-4.27.154\\slack.exe    N/A      |\n",
      "|    0   N/A  N/A     23568    C+G   ...8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
      "|    0   N/A  N/A     23948    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     24108    C+G   ...ncher\\CiscoCollabHost.exe    N/A      |\n",
      "|    0   N/A  N/A     27420    C+G   ...oot\\Office16\\POWERPNT.EXE    N/A      |\n",
      "|    0   N/A  N/A     27812    C+G   ...245.44\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     27900    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A     29896    C+G   ...8wekyb3d8bbwe\\GameBar.exe    N/A      |\n",
      "|    0   N/A  N/A     31184    C+G   ...\\dependencies\\washost.exe    N/A      |\n",
      "|    0   N/A  N/A     31640    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     32104    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A     33500      C   ...EnvWithDataSci\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     34200    C+G   ...erver\\YourPhoneServer.exe    N/A      |\n",
      "|    0   N/A  N/A     34756    C+G   ...ncher\\CiscoCollabHost.exe    N/A      |\n",
      "|    0   N/A  N/A     35280    C+G   ...8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A     36392    C+G   ...2\\extracted\\WeChatApp.exe    N/A      |\n",
      "|    0   N/A  N/A     37416    C+G   ...ekyb3d8bbwe\\HxOutlook.exe    N/A      |\n",
      "|    0   N/A  N/A     37716      C   ...EnvWithDataSci\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fe74f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce RTX 3080\n",
      "Memory Usage:\n",
      "Allocated: 0.2 GB\n",
      "Cached:    0.3 GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a5e3430-bbd6-484d-8a8d-9cbcdba37d6e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection2, selection0, selection1, emotion, plutchik, Unnamed: 0. If selection2, selection0, selection1, emotion, plutchik, Unnamed: 0 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "C:\\Python\\miniconda3\\envs\\pytorchEnvWithDataSci\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 53118\n",
      "  Num Epochs = 16\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23241' max='53120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23240/53120 24:27 < 31:26, 15.84 it/s, Epoch 7.00/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.098800</td>\n",
       "      <td>1.095999</td>\n",
       "      <td>0.394230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.015000</td>\n",
       "      <td>1.007750</td>\n",
       "      <td>0.493303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.976700</td>\n",
       "      <td>0.968177</td>\n",
       "      <td>0.515889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.948600</td>\n",
       "      <td>0.944265</td>\n",
       "      <td>0.532732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.933700</td>\n",
       "      <td>0.927301</td>\n",
       "      <td>0.545123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.915200</td>\n",
       "      <td>0.914737</td>\n",
       "      <td>0.552254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1146' max='3244' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1146/3244 00:17 < 00:31, 66.21 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection2, selection0, selection1, emotion, plutchik, Unnamed: 0. If selection2, selection0, selection1, emotion, plutchik, Unnamed: 0 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection2, selection0, selection1, emotion, plutchik, Unnamed: 0. If selection2, selection0, selection1, emotion, plutchik, Unnamed: 0 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection2, selection0, selection1, emotion, plutchik, Unnamed: 0. If selection2, selection0, selection1, emotion, plutchik, Unnamed: 0 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-12000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-12000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-12000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-12000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-12000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-12500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-12500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-12500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-12500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-12500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-13000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-13000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-13000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-13000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-13000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection2, selection0, selection1, emotion, plutchik, Unnamed: 0. If selection2, selection0, selection1, emotion, plutchik, Unnamed: 0 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-13500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-13500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-13500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-13500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-13500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-14000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-14000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-14000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-14000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-14000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-14500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-14500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-14500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-14500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-14500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-15000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-15000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-15000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-15000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-15000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-15500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-15500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-15500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-15500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-15500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-16000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-16000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-16000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-16000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-16000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-16500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-16500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-16500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-16500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-16500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection2, selection0, selection1, emotion, plutchik, Unnamed: 0. If selection2, selection0, selection1, emotion, plutchik, Unnamed: 0 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-17000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-17000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-17000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-17000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-17000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-17500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-17500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-17500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-17500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-17500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-18000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-18000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-18000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-18000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-18000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-18500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-18500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-18500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-18500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-18500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-19000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-19000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-19000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-19000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-19000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-19500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-19500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-19500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-19500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-19500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection2, selection0, selection1, emotion, plutchik, Unnamed: 0. If selection2, selection0, selection1, emotion, plutchik, Unnamed: 0 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-20000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-20000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-20000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-20000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-20000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-20500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-20500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-20500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-20500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-20500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-21000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-21000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-21000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-21000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-21000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-21500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-21500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-21500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-21500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-21500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-22000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-22000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-22000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-22000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-22000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-22500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-22500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-22500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-22500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-22500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-23000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-23000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-23000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-23000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-23000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection2, selection0, selection1, emotion, plutchik, Unnamed: 0. If selection2, selection0, selection1, emotion, plutchik, Unnamed: 0 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python\\miniconda3\\envs\\pytorchEnvWithDataSci\\lib\\site-packages\\transformers\\trainer.py:1317\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m   1314\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1316\u001b[0m )\n\u001b[1;32m-> 1317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python\\miniconda3\\envs\\pytorchEnvWithDataSci\\lib\\site-packages\\transformers\\trainer.py:1644\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1641\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1643\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m-> 1644\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_tpu_available():\n\u001b[0;32m   1648\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python\\miniconda3\\envs\\pytorchEnvWithDataSci\\lib\\site-packages\\transformers\\trainer.py:1796\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1794\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[1;32m-> 1796\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1797\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, epoch, metrics)\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n",
      "File \u001b[1;32mC:\\Python\\miniconda3\\envs\\pytorchEnvWithDataSci\\lib\\site-packages\\transformers\\trainer.py:2458\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   2455\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   2457\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 2458\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2459\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2461\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[0;32m   2462\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[0;32m   2463\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2466\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2468\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[0;32m   2469\u001b[0m output\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m   2470\u001b[0m     speed_metrics(\n\u001b[0;32m   2471\u001b[0m         metric_key_prefix,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2475\u001b[0m     )\n\u001b[0;32m   2476\u001b[0m )\n",
      "File \u001b[1;32mC:\\Python\\miniconda3\\envs\\pytorchEnvWithDataSci\\lib\\site-packages\\transformers\\trainer.py:2643\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   2641\u001b[0m \u001b[38;5;66;03m# Update containers on host\u001b[39;00m\n\u001b[0;32m   2642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2643\u001b[0m     losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nested_gather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2644\u001b[0m     losses_host \u001b[38;5;241m=\u001b[39m losses \u001b[38;5;28;01mif\u001b[39;00m losses_host \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat((losses_host, losses), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   2645\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Python\\miniconda3\\envs\\pytorchEnvWithDataSci\\lib\\site-packages\\transformers\\trainer.py:2764\u001b[0m, in \u001b[0;36mTrainer._nested_gather\u001b[1;34m(self, tensors, name)\u001b[0m\n\u001b[0;32m   2762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2763\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m-> 2764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_torch_tpu_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   2765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2766\u001b[0m         name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnested_gather\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mC:\\Python\\miniconda3\\envs\\pytorchEnvWithDataSci\\lib\\site-packages\\transformers\\utils\\import_utils.py:372\u001b[0m, in \u001b[0;36mis_torch_tpu_available\u001b[1;34m()\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;66;03m# This test is probably enough, but just in case, we unpack a bit.\u001b[39;00m\n\u001b[1;32m--> 372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtorch_xla\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mfind_spec(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_xla.core\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Python\\miniconda3\\envs\\pytorchEnvWithDataSci\\lib\\importlib\\util.py:103\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    102\u001b[0m         parent_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_find_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    105\u001b[0m     module \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[fullname]\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:914\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1407\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1379\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1506\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:142\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a17948-a8f7-4450-b2b0-8a7016e91391",
   "metadata": {},
   "source": [
    "出现validation loss 上升情况大多是训练集验证集数据分布不一致，或者训练集过小，未包含验证集中所有情况，\n",
    "也就是过拟合导致的。而解决这种现象可以尝试以下几种策略：\n",
    "1. 增加训练样本增加正则项系数权重，\n",
    "2. 减小过拟合加入早停机制，ValLoss上升几个epoch直接停止\n",
    "3. 采用Focal Loss\n",
    "4. 加入Label Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d6ab3-33ac-4e8e-99ee-3c3f17d71642",
   "metadata": {},
   "source": [
    "# Store Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c30271fe-7ce9-43e8-9e87-de8d6ae2c2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x20bda843190>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD4CAYAAADy46FuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAWfklEQVR4nO3df6xfdX3H8edrLbQU7aRzYOmtaVmKsxCY0pVOMsOsxk4JZcnAmimNdmnGGFTjJq0m239L44wTs8nSALadBGgqG42hKz+cc38AVVDB0kkb6cqVSnGgdtPUtr73x/dT+Xp/nHu/v+45n/t5PZKb+72fe873vs/3nu95fz8/jyICMzOz8fxa3QGYmVmzOVGYmVklJwozM6vkRGFmZpWcKMzMrNLMugPo1pmaFbM5u+4wzMyycoxXfhgRv9nJPtkmitmczeVaWXcYZmZZeTh2/nen+7jpyczMKjlRmJlZpWybni685Kfs2fPtusMwM8vKjPmd75Ntonj2qTm8+/xL6w7DzCwzBzrew01PZmZWyYnCzMwqZdv0NAh7XnCfRz/l0jTY7//7II47l3Mzl/+5dSbbROHO7OYbxMXNF6JmyyWhlayozuyS+WLZXzm8njnEaLnovDM720SRy6inQXzCyuVTWy5NMDmcR4Pg19ImK9tEMQi5vHFyiXMQcokzB34tbbKcKNrk8sbJJU4zmx48PNbMzCo5UZiZWSUnCjMzq+Q+igyV3JltZlNPEVF3DF1Zduns2LvnjXWHMaFcLsBOPv2Ty/DlkuUyGnEQZsw/8ERELOtknwlrFJLuBK4CjkbExalsHnAvsAg4BFwXEa+k320C1gGngJsjYk8qvwzYCpwFPABsiIiQNAvYDlwG/A/wvog41MlBNFkuJ88glHrsuSTIUv8/UPaxd2PCGoWktwP/C2xvSxSfAl6OiM2SNgLnRMQtkpYCdwPLgfOBh4ELI+KUpL3ABuAxWonicxGxW9KfA5dExJ9JWgP8UUS8b6LA52pe+FaoZmadeTh2dlyjmLAzOyK+Brw8ong1sC093gZc01Z+T0Qcj4jngIPAcknzgbkR8Wi0MtP2Efucfq6dwEpJ6uQgzMxscLod9XReRBwBSN/PTeULgOfbthtOZQvS45Hlv7JPRJwEfgz8xlh/VNJ6Sd+Q9I0THO8ydDMz60S/h8eOVROIivKqfUYXRmyJiGURsewMZnUZopmZdaLbRPFiak4ifT+ayoeBhW3bDQEvpPKhMcp/ZR9JM4FfZ3RTl5mZ1aTbRLELWJserwXubytfI2mWpMXAEmBvap46JmlF6n+4fsQ+p5/rj4GvRK5jds3MpqHJDI+9G7gSeL2kYeBvgM3ADknrgMPAtQARsU/SDuAZ4CRwY0ScSk91A68Oj92dvgDuAP5Z0kFaNYk1fTkyMzPri2wn3Hl4bJk8MdCsN90Mj812CY9B3Ao1l9maJV/YSj52s7pkmygGIZeLumeVmlm3urlntpuezMwKMpCZ2WZmVjYnCjMzq+REYWZmldyZnSF3Zps1z3QekedEkaHpfEKaWfNkmygGMY/CrB88JNqazMNjzcysUlEzs61MuUyKNJtOnCgsK76om009D481M7NK2dYo3JldJncUm/XGndlmZlbJaz2ZmVnfOVGYmVklJwozM6vkzuwMuUO3v/r9epb8WlrzddOZnW2iePapOR5T33Cl/n9KPW7LxYGO98g2UVh/+eJmZuPJNlHk0vTkZiJrKn84sMnKNlGU3PRU6nGbWT2yTRSDkMuCc7nUKHI59hwSb6nHDfkcey7vS8/MNjOzSp6ZbWZmfedEYWZmlbLto8hl1JOZWZMUNeFuEHLp3DMz615BE+5KHh5rZjaVekoUkj4K/CkQwNPAh4A5wL3AIuAQcF1EvJK23wSsA04BN0fEnlR+GbAVOAt4ANgQuQ7HylQuQxDNbOp1nSgkLQBuBpZGxM8k7QDWAEuBRyJis6SNwEbgFklL0+8vAs4HHpZ0YUScAm4D1gOP0UoUq4DdPRyXdcgXdTMbT69NTzOBsySdoFWTeAHYBFyZfr8N+CpwC7AauCcijgPPSToILJd0CJgbEY8CSNoOXMMEiWIQndklT8IxszJMaWd2RHxf0qeBw8DPgAcj4kFJ50XEkbTNEUnnpl0W0KoxnDacyk6kxyPLR5G0nlbNg9nk0UeRQ4xmVpLOO7O7nkch6RxatYTFtJqSzpb0gapdxiiLivLRhRFbImJZRCw7g1mdhmxmZl3oZcLdO4HnIuKliDgB3Ae8DXhR0nyA9P1o2n4YWNi2/xCtpqrh9HhkuZmZNUAvieIwsELSHEkCVgL7gV3A2rTNWuD+9HgXsEbSLEmLgSXA3tRMdUzSivQ817ftY2ZmNeulj+JxSTuBJ4GTwDeBLcBrgB2S1tFKJtem7felkVHPpO1vTCOeAG7g1eGxu/GIJ7Ms5TLMuuQ4i1o9dtmls2PvnjfWHcaEcjl5BsEd+WbN083qsZ6ZnaFSj9vM6uHVY83MrFK2NQprvlzagc2smhOFDYwv6mbTg5uezMysUrY1Ct+4yMysc0XduKjkUU9mZt2bwrWezMysDNnWKAYhl1E6uUy4G4QcapG5nEeD4HOzvzwzu0dzNS8u18q6wzAzy0o3M7Pd9GRmZpWcKMzMrJL7KAas5DbbQcilHdisqYrqoxjE6rG5dBiamXXLq8eamVnfuY/CzMwqOVGYmVklJwozM6uUbR/FIBYFdJ+Hmdlo2SYKd2abmU0NNz2ZmVklJwozM6uUbdPTIHiGrllvPHO++Yq6cdEguM/DrHn8vuy3zm9c5ESRoZI/Yfmi0Wwl34tjOnOiyJDfONZUPjenp2wTxSDmUZiZTXdF9VF4HoWZWTcK6qNwjcLMrHNF1SgGwTUUM5v+prhGIel1wO3AxUAAHwa+C9wLLAIOAddFxCtp+03AOuAUcHNE7EnllwFbgbOAB4ANMcEdlQbR9JTLiI2SRz2ZWW+m/A53krYB/xkRt0s6E5gDfAJ4OSI2S9oInBMRt0haCtwNLAfOBx4GLoyIU5L2AhuAx2glis9FxO6qvz1X8+Jyrew6djOzEnVzh7uul/CQNBd4O3AHQET8PCJ+BKwGtqXNtgHXpMergXsi4nhEPAccBJZLmg/MjYhHUy1ie9s+ZmZWs16ani4AXgK+IOlS4AlatYLzIuIIQEQckXRu2n4BrRrDacOp7ER6PLJ8yuXS9JSLUl/PXJoG3SxapqnuzJ4JvBW4KSIel3QrsLFie41RFhXlo59AWg+sB5jNnM6inYQcLkI5KfX1LPW4oexjz0fnndm9rB47DAxHxOPp5520EseLqTmJ9P1o2/YL2/YfAl5I5UNjlI8SEVsiYllELDuDWT2EbmZmk9V1ooiIHwDPS3pTKloJPAPsAtamsrXA/enxLmCNpFmSFgNLgL2pmeqYpBWSBFzfto+ZmdWs13kUNwF3pRFP3wM+RCv57JC0DjgMXAsQEfsk7aCVTE4CN0bEqfQ8N/Dq8Njd6cvMMlNqv9R019Pw2DoNYnisT3Izm+66GR7rmdltfFE3Mxst20ThtZ7MzDpX1FpPXj3WzKwbXj22J7lMQMolTusf/8+tX4qqUeQil1pPLnHmIJcLsP/npSqoRuGmJ2sqn5c23WSbKHJpejIzy122iWIQcmkyMDPrVlF9FG56MjPrxtQuCmhmZgVwojAzs0pOFGZmVinbPgov4WFm1jl3ZpuZ2QTcmW1mZn2WbY3CE+7MzKZGtonCTU9mZlPDTU9mZlbJicLMzCo5UZiZWSUnCjMzq5RtZ7Yn3JmZda6oCXe5KHlkVi63gTUrS0F3uBuEXC5CuVyAfZ/n/vFraf3iGkWPfAHur1KPPYcYzTqhiKg7hq7M1by4XCvrDsPMLCsPx84nImJZJ/u4RtHGn9rK1O8agM8ja7Kimp486qm/Sm4uySVOs7q46cnMrCDdND15wp2ZmVXqOVFImiHpm5K+nH6eJ+khSQfS93Patt0k6aCk70p6d1v5ZZKeTr/7nCT1GpeZmfVHP2oUG4D9bT9vBB6JiCXAI+lnJC0F1gAXAauAz0uakfa5DVgPLElfq/oQl5mZ9UFPiULSEPBe4Pa24tXAtvR4G3BNW/k9EXE8Ip4DDgLLJc0H5kbEo9HqMNneto+ZmdWs11FPnwU+Dry2rey8iDgCEBFHJJ2byhcAj7VtN5zKTqTHI8unhVwmsuUSZw5yeS1zGe1V8rEPwpQOj5V0FXA0Ip6QdOVkdhmjLCrKx/qb62k1UTGbOZMLtGa5XCxziTMHubyWucQ5CCUf+1Sv9XQFcLWk9wCzgbmSvgi8KGl+qk3MB46m7YeBhW37DwEvpPKhMcpHiYgtwBZoDY/tIXYzM5ukrvsoImJTRAxFxCJandRfiYgPALuAtWmztcD96fEuYI2kWZIW0+q03puaqY5JWpFGO13fto+ZmdVsEDOzNwM7JK0DDgPXAkTEPkk7gGeAk8CNEXEq7XMDsBU4C9idvszMrAE8M9vMrCCemW1mZn3nRGFmZpWcKMzMrFK2y4wPQi4TpcysN36vd8aJok0uM0Cn8wlpNhX8HuqME8WA+YQ0s9y5j8LMzCplW6Mo+VaouTSRmVnzdLMooCfcmZkVpJsJd9nWKKz5Sq2luMbXfO477IwTRRuPUOqvko+93/xaWp2cKNr4zWhmNlq2iaLkzuxByKW5JJc4c5DLa5lLnLmY0jvc1e3Zp+YUWwPI5SQv9Q1e6nEPSsnH3hQe9WRmVhAvM25mZn2XbdNTLnJpszUzG0+2icKd2f3lhGZm43EfRYbcuWdm3Zox/4BnZpfAn9TNrHsHOt4j20Thpiczs84VNY8iFx5Tb2a5cx9Fm1wuwE4+/dXv17Pk19Kar5s+imwTxbJLZ8fePW+sOwybYqX2z5Q8Ks2Jt7+KShQlj3oyM+uW70fRo5I/tQ1CLp8ES/4fmU2GE0WbXNr+c7mw5RJnv/9HuRy32WRl2/TkPooy5ZLMzZrKfRRmZlapqD6KQUy4y+XTqps2zGwqZZsocrlxUQ4xmplV6TpRSFoIbAfeAPwC2BIRt0qaB9wLLAIOAddFxCtpn03AOuAUcHNE7EnllwFbgbOAB4ANMUGbWC41CjOz3PVy46KTwMci4s3ACuBGSUuBjcAjEbEEeCT9TPrdGuAiYBXweUkz0nPdBqwHlqSvVT3EZWZmfdR1jSIijgBH0uNjkvYDC4DVwJVps23AV4FbUvk9EXEceE7SQWC5pEPA3Ih4FEDSduAaYHfV3x9E01Muo19y6Usxs+apbVFASYuAtwCPA+elJEJEHJF0btpsAfBY227DqexEejyyfKy/s55WzYPZzOlH6AOXS3NWLnGaWa9qWGZc0muALwEfiYifSBp30zHKoqJ8dGHEFmALtIbHdh5tNV8szcxG66WPAkln0EoSd0XEfan4RUnz0+/nA0dT+TCwsG33IeCFVD40RrmZmTVA14lCrarDHcD+iPhM2692AWvT47XA/W3layTNkrSYVqf13tRMdUzSivSc17ftY2ZmNeul6ekK4IPA05K+lco+AWwGdkhaBxwGrgWIiH2SdgDP0BoxdWNEnEr73cCrw2N3M0FHduly6XjOpdPdgyLMqnkJDzOzgnSzhEdPfRRmZjb9ZbuEh/VXDk06kEezTqnHDfkcu5vdOpNt09Mglhn3SW5m011Rq8cOQi6f2nKJ08yap7aZ2XXIZfVYM7NmqWFmdl0GsXqs9VcuTXlmJSmqRlGykmtSORx7yf1SuSRyv56dybYzexDzKEp+g5tZGdyZ3SNf1M3MRnOiMMtAU5ogJlJyv9R0/qDpRGGWgel8EZpIycfeFF7Cw8zMKrlG0cZVXLPm8SCT+jlRDFguJ2TJb8ZcPiCUquR+j0HoZh6Fh8eamRXEy4ybmVnfuenJspJDk0EuTSW5NA3mIodzE9z0ZGZmE3DTk5mZ9Z0ThZmZVcq2jyKXZcbdXl2eXNqqByGX88jvoc64j8LMrCBFrR6bS40iF7l8Gir507pZP/jGRda1ki/A/U6SJTdr+DzKQee3QnXTk5lZQTw81szM+s6JwszMKmXbR+HObCtJLsOsrfm8hIeZmVVyH4WZmfVdY5qeJK0CbgVmALdHxOaq7QfR9JRL9T6XYXilNm3k8v/JRcnvoaZoRNOTpBnAs8C7gGHg68D7I+KZ8fZx05OZWedynpm9HDgYEd8DkHQPsBoYN1FYmfzp0mzqNSVRLACeb/t5GLh85EaS1gPr04/HH46d35mC2Hr1euCHdQcxCVnEOWP+IOLsfKbqBLJ4LXGc/ZZLnG/qdIemJAqNUTaqTSwitgBbACR9o9PqUx0cZ3/lEGcOMYLj7Lec4ux0n6aMehoGFrb9PAS8UFMsZmbWpimJ4uvAEkmLJZ0JrAF21RyTmZnRkKaniDgp6S+APbSGx94ZEfsm2G3L4CPrC8fZXznEmUOM4Dj7bdrG2YjhsWZm1lxNaXoyM7OGcqIwM7NKWSYKSaskfVfSQUkb645nJEkLJf27pP2S9knaUHdMVSTNkPRNSV+uO5bxSHqdpJ2S/iu9rr9Xd0xjkfTR9D//jqS7Jc2uOyYASXdKOirpO21l8yQ9JOlA+n5OnTGmmMaK8+/S//0pSf8i6XU1hng6plFxtv3uLyWFpNfXEduIWMaMU9JN6Rq6T9KnJnqe7BJFWu7jH4E/BJYC75e0tN6oRjkJfCwi3gysAG5sYIztNgD76w5iArcC/xYRvw1cSgPjlbQAuBlYFhEX0xqYsabeqH5pK7BqRNlG4JGIWAI8kn6u21ZGx/kQcHFEXEJrqZ9NUx3UGLYyOk4kLaS1FNHhqQ5oHFsZEaekP6C18sUlEXER8OmJniS7REHbch8R8XPg9HIfjRERRyLiyfT4GK2L2oJ6oxqbpCHgvcDtdccyHklzgbcDdwBExM8j4ke1BjW+mcBZkmYCc2jIfKCI+Brw8oji1cC29HgbcM1UxjSWseKMiAcj4mT68TFa86xqNc7rCfD3wMcZY8JwHcaJ8wZgc0QcT9scneh5ckwUYy330ciLMICkRcBbgMdrDmU8n6V1Yv+i5jiqXAC8BHwhNZHdLunsuoMaKSK+T+vT2WHgCPDjiHiw3qgqnRcRR6D14QY4t+Z4JuPDwO66gxiLpKuB70dE05dNvhD4fUmPS/oPSb870Q45JopJLffRBJJeA3wJ+EhE/KTueEaSdBVwNCKeqDuWCcwE3grcFhFvAf6PZjST/IrUxr8aWAycD5wt6QP1RjV9SPokrWbdu+qOZSRJc4BPAn9ddyyTMBM4h1az+F8BOySNdV39pRwTRRbLfUg6g1aSuCsi7qs7nnFcAVwt6RCtJrx3SPpivSGNaRgYjojTtbKdtBJH07wTeC4iXoqIE8B9wNtqjqnKi5LmA6TvEzZB1EXSWuAq4E+imZO/fovWB4Rvp/fTEPCkpDfUGtXYhoH7omUvrdaEyo73HBNF45f7SNn5DmB/RHym7njGExGbImIoIhbReh2/EhGN+wQcET8Anpd0etXLlTRzCfrDwApJc9I5sJIGdrq32QWsTY/XAvfXGMu40k3NbgGujoif1h3PWCLi6Yg4NyIWpffTMPDWdO42zb8C7wCQdCFwJhOseptdokidWqeX+9gP7JjEch9T7Qrgg7Q+oX8rfb2n7qAydxNwl6SngN8B/rbecEZLNZ6dwJPA07TeX41Y1kHS3cCjwJskDUtaB2wG3iXpAK2ROpV3lZwK48T5D8BrgYfSe+mfag2SceNsnHHivBO4IA2ZvQdYO1EtzUt4mJlZpexqFGZmNrWcKMzMrJIThZmZVXKiMDOzSk4UZmZWyYnCzMwqOVGYmVml/wfZbqZBLt3uHgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "Z = np.transpose(valStored)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.pcolormesh(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5e77d30e-e51a-45a6-9130-83a17c4d2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "if model_checkpoint == 'distilbert-base-uncased-finetuned-sst-2-english':\n",
    "    model_checkpoint = 'distilbert-base'\n",
    "dataLog = pd.DataFrame(trainer.state.log_history)\n",
    "dataLog.to_csv(f'./trainingMetric/[Emotion] 3Select/TI-{model_checkpoint}-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c90cfec4-96ec-46c8-a99f-3c78b989b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluationIterationResult = pd.DataFrame(np.transpose(valStored))\n",
    "evaluationIterationResult.to_csv(f'./trainingMetric/[Emotion] 3Select/ESI-{model_checkpoint}-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd7f330-1477-4119-a9dc-1ebb7acb7665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchEnvWithDataSci",
   "language": "python",
   "name": "pytorchenvwithdatasci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
