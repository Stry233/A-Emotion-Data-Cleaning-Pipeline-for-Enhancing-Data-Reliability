{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8533643b-5b68-4dec-8a8a-49852c237e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global var set\n",
    "import transformers\n",
    "\n",
    "# model info, change as needed\n",
    "model_checkpoint = \"roberta-base\"\n",
    "batch_size = 16\n",
    "num_epochs = 16\n",
    "\n",
    "fileTag = \"original-plutchik-noCombin-v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa38989-ff76-4de1-a82e-6853a1e61687",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Convert dataset to suitable format\n",
    "IMPORTANT: please never run this section again if you have your dataset ready!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a93a9f46-6703-4535-af96-8be1b5b3407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "trainDatasetOriginal = pd.read_csv(f'../../data/csv_version/dev/emotion/allcharlinepairs-{fileTag}.csv')\n",
    "testDatasetOriginal = pd.read_csv(f'../../data/csv_version/test/emotion/allcharlinepairs-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7265a797-adc2-49ed-b237-19abf9e0569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatasetProcessed = DataFrame({'emotion' : trainDatasetOriginal['emotion'],\n",
    "                                   'plutchik' : trainDatasetOriginal['emotion'],\n",
    "                                  'selection0': pd.concat([trainDatasetOriginal['sentence'][:trainDatasetOriginal.shape[0]//2], trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//2:]]), \n",
    "                                  'selection1': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//2], trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//2:]]), \n",
    "                                  'label': pd.Series(0 if x < trainDatasetOriginal.shape[0]//2 else 1 for x in trainDatasetOriginal.index)}).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "testDatasetProcessed = DataFrame({'emotion' : testDatasetOriginal['emotion'], \n",
    "                                  'plutchik' : testDatasetOriginal['emotion'],\n",
    "                                  'selection0': pd.concat([testDatasetOriginal['sentence'][:testDatasetOriginal.shape[0]//2], testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//2:]]), \n",
    "                                  'selection1': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//2], testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//2:]]), \n",
    "                                  'label': pd.Series(0 if x < testDatasetOriginal.shape[0]//2 else 1 for x in testDatasetOriginal.index)}).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19e3c334-b371-44ad-b6e1-7161f405b741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>selection0</th>\n",
       "      <th>selection1</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"anxious\"]</td>\n",
       "      <td>I had to hit a target.</td>\n",
       "      <td>Lisa really loved to play baseball with her br...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"happy\"]</td>\n",
       "      <td>A few hours into her painting, a man walked by.</td>\n",
       "      <td>My mom Davey is 92 and in good health.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"proud\", \"creative\", \"precise \"]</td>\n",
       "      <td>Jane thought she left it at the restaurant.</td>\n",
       "      <td>Tim wrote the code for the app.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"frustrated\"]</td>\n",
       "      <td>Chelsea immediately called the plumber to reso...</td>\n",
       "      <td>Soon, the entrepreneurs had enough money to fu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"none\"]</td>\n",
       "      <td>He stopped because the therapy was not working.</td>\n",
       "      <td>I have a dog named lollipop.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53229</th>\n",
       "      <td>[\"sad\"]</td>\n",
       "      <td>Rick's neighbors moved away.</td>\n",
       "      <td>The tough gal punched Sonya with all her might.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53230</th>\n",
       "      <td>[\"none\"]</td>\n",
       "      <td>He was great with the children, and their cats.</td>\n",
       "      <td>Our granddaughter Ella lives in NYC, while we ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53231</th>\n",
       "      <td>[\"afraid\"]</td>\n",
       "      <td>Suddenly, an alligator appeared near the boat.</td>\n",
       "      <td>He gave her $1000 so she can catch up on her b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53232</th>\n",
       "      <td>[\"confident\"]</td>\n",
       "      <td>Andrew and Tom loaded up their canoes.</td>\n",
       "      <td>Patrick just walked into English class.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53233</th>\n",
       "      <td>[\"restless\"]</td>\n",
       "      <td>They were great.</td>\n",
       "      <td>He tells her he has to stay late at work.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53234 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 emotion  \\\n",
       "0                            [\"anxious\"]   \n",
       "1                              [\"happy\"]   \n",
       "2      [\"proud\", \"creative\", \"precise \"]   \n",
       "3                         [\"frustrated\"]   \n",
       "4                               [\"none\"]   \n",
       "...                                  ...   \n",
       "53229                            [\"sad\"]   \n",
       "53230                           [\"none\"]   \n",
       "53231                         [\"afraid\"]   \n",
       "53232                      [\"confident\"]   \n",
       "53233                       [\"restless\"]   \n",
       "\n",
       "                                              selection0  \\\n",
       "0                                 I had to hit a target.   \n",
       "1        A few hours into her painting, a man walked by.   \n",
       "2            Jane thought she left it at the restaurant.   \n",
       "3      Chelsea immediately called the plumber to reso...   \n",
       "4        He stopped because the therapy was not working.   \n",
       "...                                                  ...   \n",
       "53229                       Rick's neighbors moved away.   \n",
       "53230    He was great with the children, and their cats.   \n",
       "53231     Suddenly, an alligator appeared near the boat.   \n",
       "53232             Andrew and Tom loaded up their canoes.   \n",
       "53233                                   They were great.   \n",
       "\n",
       "                                              selection1  label  \n",
       "0      Lisa really loved to play baseball with her br...      0  \n",
       "1                 My mom Davey is 92 and in good health.      1  \n",
       "2                        Tim wrote the code for the app.      1  \n",
       "3      Soon, the entrepreneurs had enough money to fu...      0  \n",
       "4                           I have a dog named lollipop.      1  \n",
       "...                                                  ...    ...  \n",
       "53229    The tough gal punched Sonya with all her might.      0  \n",
       "53230  Our granddaughter Ella lives in NYC, while we ...      1  \n",
       "53231  He gave her $1000 so she can catch up on her b...      0  \n",
       "53232            Patrick just walked into English class.      1  \n",
       "53233          He tells her he has to stay late at work.      1  \n",
       "\n",
       "[53234 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDatasetProcessed.to_csv(f'./multiSelect-{fileTag}-train.csv')\n",
    "trainDatasetProcessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b770299d-567d-46e2-b928-8ee31a341c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>selection0</th>\n",
       "      <th>selection1</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"guilty\"]</td>\n",
       "      <td>Jordan's mother saw this and brought his frien...</td>\n",
       "      <td>Jim and Janie Jones had a cat named Vixen.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"none\"]</td>\n",
       "      <td>It is her husband's sister's kid.</td>\n",
       "      <td>He wrote a book about it.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"none\"]</td>\n",
       "      <td>The movie had sold out before we got there.</td>\n",
       "      <td>He saw the most beautiful cat there.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"proud\", \"happy\"]</td>\n",
       "      <td>She told all her coworkers about it as she hea...</td>\n",
       "      <td>I was in shape and ready for my upcoming wedding.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"frustrated and angry\"]</td>\n",
       "      <td>Everyone had an amazing time thanks to Carla's...</td>\n",
       "      <td>Jay couldn't find a job.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51886</th>\n",
       "      <td>[\"distrustful of roommate\"]</td>\n",
       "      <td>The food was amazing there.</td>\n",
       "      <td>The roommate admitted to borrowing it.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51887</th>\n",
       "      <td>[\"none\"]</td>\n",
       "      <td>Megan brought her little children to the park.</td>\n",
       "      <td>After a nail biting game, the young child was ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51888</th>\n",
       "      <td>[\"scare\", \"surprise\"]</td>\n",
       "      <td>The next day, Kayla saw someone wearing her ne...</td>\n",
       "      <td>Felicia smiled too but her heart was still bea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51889</th>\n",
       "      <td>[\"hard working\"]</td>\n",
       "      <td>Gina's crush had smiled at her in the morning.</td>\n",
       "      <td>Jean went back home and continued tilling.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51890</th>\n",
       "      <td>[\"happy with excitement\"]</td>\n",
       "      <td>He counted them himself, twelve slimy slugs.</td>\n",
       "      <td>Tiffany loved shredded cheese and crackers in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51891 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           emotion  \\\n",
       "0                       [\"guilty\"]   \n",
       "1                         [\"none\"]   \n",
       "2                         [\"none\"]   \n",
       "3               [\"proud\", \"happy\"]   \n",
       "4         [\"frustrated and angry\"]   \n",
       "...                            ...   \n",
       "51886  [\"distrustful of roommate\"]   \n",
       "51887                     [\"none\"]   \n",
       "51888        [\"scare\", \"surprise\"]   \n",
       "51889             [\"hard working\"]   \n",
       "51890    [\"happy with excitement\"]   \n",
       "\n",
       "                                              selection0  \\\n",
       "0      Jordan's mother saw this and brought his frien...   \n",
       "1                      It is her husband's sister's kid.   \n",
       "2            The movie had sold out before we got there.   \n",
       "3      She told all her coworkers about it as she hea...   \n",
       "4      Everyone had an amazing time thanks to Carla's...   \n",
       "...                                                  ...   \n",
       "51886                        The food was amazing there.   \n",
       "51887     Megan brought her little children to the park.   \n",
       "51888  The next day, Kayla saw someone wearing her ne...   \n",
       "51889     Gina's crush had smiled at her in the morning.   \n",
       "51890       He counted them himself, twelve slimy slugs.   \n",
       "\n",
       "                                              selection1  label  \n",
       "0             Jim and Janie Jones had a cat named Vixen.      0  \n",
       "1                              He wrote a book about it.      1  \n",
       "2                   He saw the most beautiful cat there.      1  \n",
       "3      I was in shape and ready for my upcoming wedding.      1  \n",
       "4                               Jay couldn't find a job.      1  \n",
       "...                                                  ...    ...  \n",
       "51886             The roommate admitted to borrowing it.      1  \n",
       "51887  After a nail biting game, the young child was ...      0  \n",
       "51888  Felicia smiled too but her heart was still bea...      1  \n",
       "51889         Jean went back home and continued tilling.      1  \n",
       "51890  Tiffany loved shredded cheese and crackers in ...      1  \n",
       "\n",
       "[51891 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDatasetProcessed.to_csv(f'./multiSelect-{fileTag}-test.csv')\n",
    "testDatasetProcessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7283c1-d83e-4369-b5e4-6c2e09d654ac",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "828a5092-83e6-4580-99c9-bd9ec434708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05151e3b-0bec-44f4-bf0a-ac58cddbf838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-52ca1ef45d27d0a7\n",
      "Reusing dataset csv (C:\\Users\\JAM_0\\.cache\\huggingface\\datasets\\csv\\default-52ca1ef45d27d0a7\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25cd9cd36aa64a56b533421c8740a432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('csv', data_files={'train': f'./dataset/2Select-{fileTag}-train.csv', \n",
    "                                           'test': f'./dataset/2Select-{fileTag}-test.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d776c270-7752-4445-ba6c-eb078f71eccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'emotion', 'plutchik', 'selection0', 'selection1', 'label'],\n",
       "        num_rows: 53234\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'emotion', 'plutchik', 'selection0', 'selection1', 'label'],\n",
       "        num_rows: 51891\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1c79159-f795-4d02-b052-94f04286d53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 0,\n",
       " 'emotion': \"['upset']\",\n",
       " 'plutchik': \"{'joy': 0, 'trust': 0, 'fear': 3, 'surprise': 3, 'sadness': 3, 'disgust': 3, 'anger': 3, 'anticipation': 0}\",\n",
       " 'selection0': \"Yesterday, she found out she's going to have to work on Thanksgiving.\",\n",
       " 'selection1': 'Ben worked on a report late at night.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f6ad67d-b4cb-4f65-a9cb-d2d665deec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_one(example):\n",
    "    print(f\"Context: {example['plutchik']}\")\n",
    "    print(f\"  A - {example['selection0']}\")\n",
    "    print(f\"  B - {example['selection1']}\")\n",
    "    print(f\"\\nGround truth: option {['A', 'B'][example['label']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15cd7cfb-748a-4fe7-8152-7debf6a65ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: {'joy': 0, 'trust': 3, 'fear': 0, 'surprise': 0, 'sadness': 0, 'disgust': 0, 'anger': 0, 'anticipation': 3}\n",
      "  A - Rob was really hoping to work on a new important project.\n",
      "  B - They dog's rarely barked at or jumped at her grandma.\n",
      "\n",
      "Ground truth: option A\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da93346-1037-41ed-b67d-91877fa8c0ec",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3da78c12-9aff-4beb-a006-e287bbf61023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caffe397-a65d-478f-b966-7b910fb2edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "selectionList = [\"selection0\", \"selection1\"]\n",
    "weightRemap = [\"NOT \", \"LITTLE \", \"\", \"VERY \", \"ABSOLUTELY \"]\n",
    "def preprocess_function(examples):\n",
    "    # Repeat each first sentence four times to go with the four possibilities of second sentences.\n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(context.strip(\"[\").strip(\"]\").replace('\\'', '')) ]*2 for context in examples[\"emotion\"] ]\n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(context.strip(\"[\").strip(\"]\").replace('\\\"', '')) ]*2 for context in examples[\"plutchik\"] ]\n",
    "    first_sentences = [[\"The following sentences contain emotions: {}\".format(\", \".join([weightRemap[int(eachCaseWeight.replace(\"]\", \"\").replace(\"[\", \"\").replace(\"}\", \"\").replace(\"{\", \"\").replace(\"\\\"\", \"\").replace(\"\\'\", \"\"))] \n",
    "                                                        + eachCaseEmotionType.replace(\"]\", \"\").replace(\"[\", \"\").replace(\"}\", \"\").replace(\"{\", \"\").replace(\"\\\"\", \"\").replace(\"\\'\", \"\").strip()\n",
    "                        for eachCaseWeight, eachCaseEmotionType in \n",
    "                        zip([re.split(':|,',eachEmotionCombination)[1::2] for eachEmotionCombination in examples[\"plutchik\"]][eventIndex], \n",
    "                           [re.split(':|,',eachEmotionCombination)[::2] for eachEmotionCombination in examples[\"plutchik\"]][eventIndex])]))]*2 for eventIndex in \n",
    "                           range(len([re.split(':|,',eachEmotionCombination)[1::2] for eachEmotionCombination in examples[\"plutchik\"]]))]\n",
    "    \n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(', '.join([(weightRemap[eachEmotion[1]] + \" \" +eachEmotion[0]).strip() \n",
    "    #                    for eachEmotion in ast.literal_eval(context).items()]))]*2 \n",
    "    #                    for context in examples[\"plutchik\"]]\n",
    "    # Grab all second sentences possible for each context.\n",
    "    second_sentences = [[examples[selection][index] for selection in selectionList]for index in range(len(examples['selection0']))]\n",
    "\n",
    "    # Flatten everything\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "    \n",
    "    # Tokenize\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "    # Un-flatten\n",
    "    # print(tokenized_examples.items())\n",
    "    return {k: [v[i:i+2] for i in range(0, len(v), 2)] for k, v in tokenized_examples.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0afb4841-ab69-4b91-8859-fd249badb923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2 [45, 46]\n"
     ]
    }
   ],
   "source": [
    "examples = dataset[\"train\"][:5]\n",
    "features = preprocess_function(examples)\n",
    "print(len(features[\"input_ids\"]), len(features[\"input_ids\"][0]), [len(x) for x in features[\"input_ids\"][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "903e2891-0e3d-4e87-b98a-727eaf36417a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>The following sentences contain emotions: NOT joy, VERY trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, VERY anticipation</s></s>Rob was really hoping to work on a new important project.</s>',\n",
       " '<s>The following sentences contain emotions: NOT joy, NOT trust, NOT fear, surprise, VERY sadness, disgust, anger, NOT anticipation</s></s>Next morning i convinced my friend that i will copy her assignment.</s>',\n",
       " '<s>The following sentences contain emotions: NOT joy, NOT trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation</s></s>Dan bought every single package of cookies the girls had!</s>',\n",
       " '<s>The following sentences contain emotions: NOT joy, NOT trust, fear, NOT surprise, NOT sadness, disgust, anger, NOT anticipation</s></s>Dan bought every single package of cookies the girls had!</s>',\n",
       " \"<s>The following sentences contain emotions: NOT joy, NOT trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation</s></s>Mary decided to be more cautious so she wouldn't miss any stop signs.</s>\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(features[\"input_ids\"][a][i]) for a in range(5) for i in range(1) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a286ba6-cb84-4619-b842-780124d26a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da34589539324187a8314dd2c45cc506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=54.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128e0481a33a486e8f4e4356cd361a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=52.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7706d875-3a89-4e52-9f08-c77256b621ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForMultipleChoice: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForMultipleChoice.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2cd7be65-ebd8-43db-bcbf-a87d7e2342e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-emotionCommonsense\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=5e-6, # for bert-base\n",
    "    # learning_rate=1e-3,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    save_steps = 10000,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2737e04e-19c2-407d-8ce1-06b675f208c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [[{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        # Un-flatten\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        # Add back labels\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "03a0ec05-de5e-434f-b07c-63212e7c7f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_keys = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "features = [{k: v for k, v in encoded_datasets[\"train\"][i].items() if k in accepted_keys} for i in range(10)]\n",
    "batch = DataCollatorForMultipleChoice(tokenizer)(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "45f7f26c-04bb-42ae-8627-897ced69888e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>The following sentences contain emotions: VERY joy, VERY trust, NOT fear, surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation</s></s>So he kept adding more and more ingredients.</s><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<s>The following sentences contain emotions: VERY joy, VERY trust, NOT fear, surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation</s></s>The two had been buddies for years.</s><pad><pad><pad><pad><pad><pad><pad><pad>']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(batch[\"input_ids\"][8][i].tolist()) for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c4b55256-30fa-4e30-a3a4-66fe1114b941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: {'joy': 3, 'trust': 3, 'fear': 0, 'surprise': 2, 'sadness': 0, 'disgust': 0, 'anger': 0, 'anticipation': 0}\n",
      "  A - So he kept adding more and more ingredients.\n",
      "  B - The two had been buddies for years.\n",
      "\n",
      "Ground truth: option B\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8305d3-8dc9-4d0f-8628-f51dc356c2d2",
   "metadata": {},
   "source": [
    "# Trainer Defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b707863a-bc16-43b0-b633-c7ffb4fa72e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "valStored = []\n",
    "def compute_metrics(eval_predictions):\n",
    "    predictions, label_ids = eval_predictions\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    valStored.append((preds != label_ids).astype(np.float32));\n",
    "    return {\"accuracy\": (preds == label_ids).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b115c1ba-323a-47d5-bb9d-55de985f13b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_datasets[\"train\"],\n",
    "    eval_dataset=encoded_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5e3430-bbd6-484d-8a8d-9cbcdba37d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7843' max='53248' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 7843/53248 24:47 < 2:23:34, 5.27 it/s, Epoch 2.36/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.563400</td>\n",
       "      <td>0.562486</td>\n",
       "      <td>0.696286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.520900</td>\n",
       "      <td>0.553651</td>\n",
       "      <td>0.709584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a17948-a8f7-4450-b2b0-8a7016e91391",
   "metadata": {},
   "source": [
    "出现validation loss 上升情况大多是训练集验证集数据分布不一致，或者训练集过小，未包含验证集中所有情况，\n",
    "也就是过拟合导致的。而解决这种现象可以尝试以下几种策略：\n",
    "1. 增加训练样本增加正则项系数权重，\n",
    "2. 减小过拟合加入早停机制，ValLoss上升几个epoch直接停止\n",
    "3. 采用Focal Loss\n",
    "4. 加入Label Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d6ab3-33ac-4e8e-99ee-3c3f17d71642",
   "metadata": {},
   "source": [
    "# Store Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c30271fe-7ce9-43e8-9e87-de8d6ae2c2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x1b2cdcb6940>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "Z = np.transpose(valStored)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.pcolormesh(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e77d30e-e51a-45a6-9130-83a17c4d2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "if model_checkpoint == 'distilbert-base-uncased-finetuned-sst-2-english':\n",
    "    model_checkpoint = 'distilbert-base'\n",
    "dataLog = pd.DataFrame(trainer.state.log_history)\n",
    "dataLog.to_csv(f'./trainingMetric/[Plutchik] 2Select/TI-{model_checkpoint}-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c90cfec4-96ec-46c8-a99f-3c78b989b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluationIterationResult = pd.DataFrame(np.transpose(valStored))\n",
    "evaluationIterationResult.to_csv(f'./trainingMetric/[Plutchik] 2Select/ESI-{model_checkpoint}-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd7f330-1477-4119-a9dc-1ebb7acb7665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchEnvWithDataSci",
   "language": "python",
   "name": "pytorchenvwithdatasci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
