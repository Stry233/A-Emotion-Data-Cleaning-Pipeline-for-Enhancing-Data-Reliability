{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c50bd14d-a967-4843-9cd5-4985a676dc1f",
   "metadata": {},
   "source": [
    "# ATTENTION!!!!\n",
    "NO 4 SELECTION IN THIS PROJECT!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ad2474-58c5-4417-a6e5-8b5f26d79e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global var set\n",
    "import transformers\n",
    "\n",
    "# model info, change as needed\n",
    "model_checkpoint = \"roberta-base\"\n",
    "batch_size = 16\n",
    "num_epochs = 16\n",
    "\n",
    "fileTag = \"clean-v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa38989-ff76-4de1-a82e-6853a1e61687",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Convert dataset to suitable format\n",
    "IMPORTANT: please never run this section again if you have your dataset ready!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a93a9f46-6703-4535-af96-8be1b5b3407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "trainDatasetOriginal = pd.read_csv(f'../../data/csv_version/dev/emotion/allcharlinepairs-{fileTag}.csv')\n",
    "testDatasetOriginal = pd.read_csv(f'../../data/csv_version/test/emotion/allcharlinepairs-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7265a797-adc2-49ed-b237-19abf9e0569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatasetProcessed = DataFrame({'emotion' : trainDatasetOriginal['emotion'],\n",
    "                                   'plutchik' : trainDatasetOriginal['plutchik'],\n",
    "                                  'selection0': pd.concat([trainDatasetOriginal['sentence'][:trainDatasetOriginal.shape[0]//4], trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//4:]]), \n",
    "                                  'selection1': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//4], \n",
    "                                                pd.concat([trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//4:trainDatasetOriginal.shape[0]//2], \n",
    "                                                trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//2:]])]), \n",
    "                                  'selection2': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//2], \n",
    "                                                pd.concat([trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//2:trainDatasetOriginal.shape[0]//4*3], \n",
    "                                                trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//4*3:]])]), \n",
    "                                  'selection3': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//4*3], \n",
    "                                                           trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//4*3:]]),\n",
    "                                  'label': pd.Series(0 if x < trainDatasetOriginal.shape[0]//4 else (1 if x < trainDatasetOriginal.shape[0]//2 \n",
    "                                                                                               else (2 if x < trainDatasetOriginal.shape[0]//4*3 \n",
    "                                                                                               else 3)) for x in trainDatasetOriginal.index)}).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "testDatasetProcessed = DataFrame({'emotion' : testDatasetOriginal['emotion'],\n",
    "                                   'plutchik' : testDatasetOriginal['plutchik'],\n",
    "                                  'selection0': pd.concat([testDatasetOriginal['sentence'][:testDatasetOriginal.shape[0]//4], testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//4:]]), \n",
    "                                  'selection1': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//4], \n",
    "                                                pd.concat([testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//4:testDatasetOriginal.shape[0]//2], \n",
    "                                                testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//2:]])]), \n",
    "                                  'selection2': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//2], \n",
    "                                                pd.concat([testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//2:testDatasetOriginal.shape[0]//4*3], \n",
    "                                                testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//4*3:]])]), \n",
    "                                  'selection3': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//4*3], \n",
    "                                                           testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//4*3:]]),\n",
    "                                  'label': pd.Series(0 if x < testDatasetOriginal.shape[0]//4 else (1 if x < testDatasetOriginal.shape[0]//2 \n",
    "                                                                                               else (2 if x < testDatasetOriginal.shape[0]//4*3 \n",
    "                                                                                               else 3)) for x in testDatasetOriginal.index)}).sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19e3c334-b371-44ad-b6e1-7161f405b741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>plutchik</th>\n",
       "      <th>selection0</th>\n",
       "      <th>selection1</th>\n",
       "      <th>selection2</th>\n",
       "      <th>selection3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['scared', 'helpless', 'uncomfortable', 'nervo...</td>\n",
       "      <td>{'joy': 0, 'trust': 2, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>Finally, the day came when she could get in th...</td>\n",
       "      <td>They're planning to learn to weave together!</td>\n",
       "      <td>Tim was playing in the house.</td>\n",
       "      <td>He asked his friend for advice about the probl...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['nervous', 'loving', 'enthralled']</td>\n",
       "      <td>{'joy': 1, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>He showed up the next day with white skin and ...</td>\n",
       "      <td>I opened the large door with my shoulder.</td>\n",
       "      <td>Lonnie had the biggest crush on Lorrie.</td>\n",
       "      <td>Shana used to live in a run-down trailer in th...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['tired', 'exhausted', 'bored']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>Terrin moved back, but changed a lot.</td>\n",
       "      <td>He was tired of walking.</td>\n",
       "      <td>Larry received a toy for his birthday.</td>\n",
       "      <td>One day, he could not find his bag.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['self-conscious', 'inadequate', 'anticipation...</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>He couldn't keep fixing it.</td>\n",
       "      <td>In the moving process, Tubby was misplaced in ...</td>\n",
       "      <td>Right now i can only leg lift about one hundre...</td>\n",
       "      <td>Carly crashed into the wall because she didn't...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['excitement', 'excited']</td>\n",
       "      <td>{'joy': 2, 'trust': 2, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>While leaving the office, William closed his f...</td>\n",
       "      <td>Liam moved to a new house.</td>\n",
       "      <td>It's tempting to keep holding the rope.</td>\n",
       "      <td>He eats a handful of peanuts.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11605</th>\n",
       "      <td>['exhausted', 'tired', 'relieved']</td>\n",
       "      <td>{'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>He really wanted to relax.</td>\n",
       "      <td>Tanya decided to sneak into Kim's room and tak...</td>\n",
       "      <td>Sam stayed at a friend's house during his visit.</td>\n",
       "      <td>Freda was a cocky woman.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11606</th>\n",
       "      <td>['proud', 'happy', 'nervous', 'anxious']</td>\n",
       "      <td>{'joy': 1, 'trust': 0, 'fear': 2, 'surprise': ...</td>\n",
       "      <td>They were psyched for the big game!</td>\n",
       "      <td>Ryan bought a large, impressive engagement ring.</td>\n",
       "      <td>She secretly switched him to decaffeinated cof...</td>\n",
       "      <td>One day his phone rang and it was his ex wife.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11607</th>\n",
       "      <td>['hopeful', 'determined']</td>\n",
       "      <td>{'joy': 0, 'trust': 1, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>They headed to an old abandoned barn to light ...</td>\n",
       "      <td>They decided to run around in a hotel.</td>\n",
       "      <td>She mostly walked around watching people have ...</td>\n",
       "      <td>She went home, researched how to fix it and go...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11608</th>\n",
       "      <td>['excited', 'delighted', 'accomplished']</td>\n",
       "      <td>{'joy': 3, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>I finally got my PHD.</td>\n",
       "      <td>Sheila loves her Australian home.</td>\n",
       "      <td>She was so sick from the heat when she got there.</td>\n",
       "      <td>She dug through her freezer but had no ideas.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11609</th>\n",
       "      <td>['worried', 'anxious', 'deceptive', 'dishonest...</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...</td>\n",
       "      <td>It was dark by the time I headed home.</td>\n",
       "      <td>The steak had been cooked to perfection.</td>\n",
       "      <td>Gina felt slightly better about the whole situ...</td>\n",
       "      <td>It didn't take long for Martin's bad decision ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11610 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 emotion  \\\n",
       "0      ['scared', 'helpless', 'uncomfortable', 'nervo...   \n",
       "1                    ['nervous', 'loving', 'enthralled']   \n",
       "2                        ['tired', 'exhausted', 'bored']   \n",
       "3      ['self-conscious', 'inadequate', 'anticipation...   \n",
       "4                              ['excitement', 'excited']   \n",
       "...                                                  ...   \n",
       "11605                 ['exhausted', 'tired', 'relieved']   \n",
       "11606           ['proud', 'happy', 'nervous', 'anxious']   \n",
       "11607                          ['hopeful', 'determined']   \n",
       "11608           ['excited', 'delighted', 'accomplished']   \n",
       "11609  ['worried', 'anxious', 'deceptive', 'dishonest...   \n",
       "\n",
       "                                                plutchik  \\\n",
       "0      {'joy': 0, 'trust': 2, 'fear': 1, 'surprise': ...   \n",
       "1      {'joy': 1, 'trust': 1, 'fear': 0, 'surprise': ...   \n",
       "2      {'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...   \n",
       "3      {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "4      {'joy': 2, 'trust': 2, 'fear': 0, 'surprise': ...   \n",
       "...                                                  ...   \n",
       "11605  {'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "11606  {'joy': 1, 'trust': 0, 'fear': 2, 'surprise': ...   \n",
       "11607  {'joy': 0, 'trust': 1, 'fear': 1, 'surprise': ...   \n",
       "11608  {'joy': 3, 'trust': 1, 'fear': 0, 'surprise': ...   \n",
       "11609  {'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...   \n",
       "\n",
       "                                              selection0  \\\n",
       "0      Finally, the day came when she could get in th...   \n",
       "1      He showed up the next day with white skin and ...   \n",
       "2                  Terrin moved back, but changed a lot.   \n",
       "3                            He couldn't keep fixing it.   \n",
       "4      While leaving the office, William closed his f...   \n",
       "...                                                  ...   \n",
       "11605                         He really wanted to relax.   \n",
       "11606                They were psyched for the big game!   \n",
       "11607  They headed to an old abandoned barn to light ...   \n",
       "11608                              I finally got my PHD.   \n",
       "11609             It was dark by the time I headed home.   \n",
       "\n",
       "                                              selection1  \\\n",
       "0           They're planning to learn to weave together!   \n",
       "1              I opened the large door with my shoulder.   \n",
       "2                               He was tired of walking.   \n",
       "3      In the moving process, Tubby was misplaced in ...   \n",
       "4                             Liam moved to a new house.   \n",
       "...                                                  ...   \n",
       "11605  Tanya decided to sneak into Kim's room and tak...   \n",
       "11606   Ryan bought a large, impressive engagement ring.   \n",
       "11607             They decided to run around in a hotel.   \n",
       "11608                  Sheila loves her Australian home.   \n",
       "11609           The steak had been cooked to perfection.   \n",
       "\n",
       "                                              selection2  \\\n",
       "0                          Tim was playing in the house.   \n",
       "1                Lonnie had the biggest crush on Lorrie.   \n",
       "2                 Larry received a toy for his birthday.   \n",
       "3      Right now i can only leg lift about one hundre...   \n",
       "4                It's tempting to keep holding the rope.   \n",
       "...                                                  ...   \n",
       "11605   Sam stayed at a friend's house during his visit.   \n",
       "11606  She secretly switched him to decaffeinated cof...   \n",
       "11607  She mostly walked around watching people have ...   \n",
       "11608  She was so sick from the heat when she got there.   \n",
       "11609  Gina felt slightly better about the whole situ...   \n",
       "\n",
       "                                              selection3  label  \n",
       "0      He asked his friend for advice about the probl...      3  \n",
       "1      Shana used to live in a run-down trailer in th...      2  \n",
       "2                    One day, he could not find his bag.      1  \n",
       "3      Carly crashed into the wall because she didn't...      2  \n",
       "4                          He eats a handful of peanuts.      1  \n",
       "...                                                  ...    ...  \n",
       "11605                           Freda was a cocky woman.      0  \n",
       "11606     One day his phone rang and it was his ex wife.      1  \n",
       "11607  She went home, researched how to fix it and go...      3  \n",
       "11608      She dug through her freezer but had no ideas.      0  \n",
       "11609  It didn't take long for Martin's bad decision ...      3  \n",
       "\n",
       "[11610 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDatasetProcessed.to_csv(f'./dataset/4Select-{fileTag}-train.csv')\n",
    "trainDatasetProcessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b770299d-567d-46e2-b928-8ee31a341c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>plutchik</th>\n",
       "      <th>selection0</th>\n",
       "      <th>selection1</th>\n",
       "      <th>selection2</th>\n",
       "      <th>selection3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['achievable', 'determined', 'proud']</td>\n",
       "      <td>{'joy': 2, 'trust': 2, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>He wound up making millions playing video games.</td>\n",
       "      <td>She worked hard all year to get nominated.</td>\n",
       "      <td>She also had a pool and I was excited to swim ...</td>\n",
       "      <td>His plane lands and he gets out of the airport.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['unhappy', 'violated', 'content']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>She wanted to host a bonfire party for her fri...</td>\n",
       "      <td>Diane convinced management to give the workers...</td>\n",
       "      <td>And his friend talked him into getting the sam...</td>\n",
       "      <td>Her ordeal provided a conversation that lasted...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['playful', 'fun', 'accompanied', 'furnished',...</td>\n",
       "      <td>{'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>He asked a friend to help him study.</td>\n",
       "      <td>Jane wanted to have a water gun fight.</td>\n",
       "      <td>John talked to his counselor.</td>\n",
       "      <td>Finn loved to go hiking.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['foolish']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>But she chose to wait for her friend so she wo...</td>\n",
       "      <td>Gina was carrying gallons of water in plastic ...</td>\n",
       "      <td>She found out she had forgotten her wallet.</td>\n",
       "      <td>Alison lined up at the start line.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['worried', 'surprised', 'happy', 'scared', 't...</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>Their realtor called while they were out and t...</td>\n",
       "      <td>Suddenly, Julia stopped short and the color dr...</td>\n",
       "      <td>In 6 months I lost 100 pounds!</td>\n",
       "      <td>I looked around the school for one as well.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11124</th>\n",
       "      <td>['relaxed', 'happy']</td>\n",
       "      <td>{'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>He got into his car and relaxed in the seat be...</td>\n",
       "      <td>Melinda fell asleep in the car going home beca...</td>\n",
       "      <td>Gustav had won the contest of strengths by ben...</td>\n",
       "      <td>Everything was going well when one of the ball...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11125</th>\n",
       "      <td>['nervous', 'scared']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...</td>\n",
       "      <td>My stepmother was physically abusive, while st...</td>\n",
       "      <td>When everyone ate the soup, they complained ab...</td>\n",
       "      <td>His father told him no.</td>\n",
       "      <td>As soon as she sat down, she flinched.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11126</th>\n",
       "      <td>['disappointed', 'unhappy', 'fear', 'upset']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>Some bubbles popped in her hair.</td>\n",
       "      <td>She stumbled over her first few words.</td>\n",
       "      <td>During the hike, Jim fell and twisted his ankle.</td>\n",
       "      <td>My brother and his family went to buy food for...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11127</th>\n",
       "      <td>['proud', 'accomplished']</td>\n",
       "      <td>{'joy': 3, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>They decided to go on jungle trekking adventure.</td>\n",
       "      <td>He calls it the iPhone.</td>\n",
       "      <td>Ben was training to become a police officer.</td>\n",
       "      <td>At the beginning of the year we moved the shop.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>['excited', 'curious']</td>\n",
       "      <td>{'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>John bought a new racquet and enjoyed his time...</td>\n",
       "      <td>They were surprised to see dark clouds rolling...</td>\n",
       "      <td>She decided to try it out.</td>\n",
       "      <td>He spent hours perfecting his technique.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11129 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 emotion  \\\n",
       "0                  ['achievable', 'determined', 'proud']   \n",
       "1                     ['unhappy', 'violated', 'content']   \n",
       "2      ['playful', 'fun', 'accompanied', 'furnished',...   \n",
       "3                                            ['foolish']   \n",
       "4      ['worried', 'surprised', 'happy', 'scared', 't...   \n",
       "...                                                  ...   \n",
       "11124                               ['relaxed', 'happy']   \n",
       "11125                              ['nervous', 'scared']   \n",
       "11126       ['disappointed', 'unhappy', 'fear', 'upset']   \n",
       "11127                          ['proud', 'accomplished']   \n",
       "11128                             ['excited', 'curious']   \n",
       "\n",
       "                                                plutchik  \\\n",
       "0      {'joy': 2, 'trust': 2, 'fear': 0, 'surprise': ...   \n",
       "1      {'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...   \n",
       "2      {'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "3      {'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...   \n",
       "4      {'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...   \n",
       "...                                                  ...   \n",
       "11124  {'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...   \n",
       "11125  {'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...   \n",
       "11126  {'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...   \n",
       "11127  {'joy': 3, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "11128  {'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "\n",
       "                                              selection0  \\\n",
       "0       He wound up making millions playing video games.   \n",
       "1      She wanted to host a bonfire party for her fri...   \n",
       "2                   He asked a friend to help him study.   \n",
       "3      But she chose to wait for her friend so she wo...   \n",
       "4      Their realtor called while they were out and t...   \n",
       "...                                                  ...   \n",
       "11124  He got into his car and relaxed in the seat be...   \n",
       "11125  My stepmother was physically abusive, while st...   \n",
       "11126                   Some bubbles popped in her hair.   \n",
       "11127   They decided to go on jungle trekking adventure.   \n",
       "11128  John bought a new racquet and enjoyed his time...   \n",
       "\n",
       "                                              selection1  \\\n",
       "0             She worked hard all year to get nominated.   \n",
       "1      Diane convinced management to give the workers...   \n",
       "2                 Jane wanted to have a water gun fight.   \n",
       "3      Gina was carrying gallons of water in plastic ...   \n",
       "4      Suddenly, Julia stopped short and the color dr...   \n",
       "...                                                  ...   \n",
       "11124  Melinda fell asleep in the car going home beca...   \n",
       "11125  When everyone ate the soup, they complained ab...   \n",
       "11126             She stumbled over her first few words.   \n",
       "11127                            He calls it the iPhone.   \n",
       "11128  They were surprised to see dark clouds rolling...   \n",
       "\n",
       "                                              selection2  \\\n",
       "0      She also had a pool and I was excited to swim ...   \n",
       "1      And his friend talked him into getting the sam...   \n",
       "2                          John talked to his counselor.   \n",
       "3            She found out she had forgotten her wallet.   \n",
       "4                         In 6 months I lost 100 pounds!   \n",
       "...                                                  ...   \n",
       "11124  Gustav had won the contest of strengths by ben...   \n",
       "11125                            His father told him no.   \n",
       "11126   During the hike, Jim fell and twisted his ankle.   \n",
       "11127       Ben was training to become a police officer.   \n",
       "11128                         She decided to try it out.   \n",
       "\n",
       "                                              selection3  label  \n",
       "0        His plane lands and he gets out of the airport.      1  \n",
       "1      Her ordeal provided a conversation that lasted...      3  \n",
       "2                               Finn loved to go hiking.      1  \n",
       "3                     Alison lined up at the start line.      2  \n",
       "4            I looked around the school for one as well.      1  \n",
       "...                                                  ...    ...  \n",
       "11124  Everything was going well when one of the ball...      0  \n",
       "11125             As soon as she sat down, she flinched.      3  \n",
       "11126  My brother and his family went to buy food for...      2  \n",
       "11127    At the beginning of the year we moved the shop.      1  \n",
       "11128           He spent hours perfecting his technique.      2  \n",
       "\n",
       "[11129 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDatasetProcessed.to_csv(f'./dataset/4Select-{fileTag}-test.csv')\n",
    "testDatasetProcessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7283c1-d83e-4369-b5e4-6c2e09d654ac",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "828a5092-83e6-4580-99c9-bd9ec434708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05151e3b-0bec-44f4-bf0a-ac58cddbf838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-c2d0ae98ecdd3708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:\\Users\\JAM_0\\.cache\\huggingface\\datasets\\csv\\default-c2d0ae98ecdd3708\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5927fec55de645108d0d35fc3e388441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83170ba4cc7c40c8a6efe7e30f1f9f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:\\Users\\JAM_0\\.cache\\huggingface\\datasets\\csv\\default-c2d0ae98ecdd3708\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e750db9dd44b14af6b915632a7c014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('csv', data_files={'train': f'./dataset/4Select-{fileTag}-train.csv', \n",
    "                                           'test': f'./dataset/4Select-{fileTag}-test.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d776c270-7752-4445-ba6c-eb078f71eccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'emotion', 'plutchik', 'selection0', 'selection1', 'selection2', 'selection3', 'label'],\n",
       "        num_rows: 11610\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'emotion', 'plutchik', 'selection0', 'selection1', 'selection2', 'selection3', 'label'],\n",
       "        num_rows: 11129\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1c79159-f795-4d02-b052-94f04286d53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 0,\n",
       " 'emotion': \"['achievable', 'determined', 'proud']\",\n",
       " 'plutchik': \"{'joy': 2, 'trust': 2, 'fear': 0, 'surprise': 0, 'sadness': 0, 'disgust': 0, 'anger': 0, 'anticipation': 2}\",\n",
       " 'selection0': 'He wound up making millions playing video games.',\n",
       " 'selection1': 'She worked hard all year to get nominated.',\n",
       " 'selection2': 'She also had a pool and I was excited to swim in it.',\n",
       " 'selection3': 'His plane lands and he gets out of the airport.',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f6ad67d-b4cb-4f65-a9cb-d2d665deec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_one(example):\n",
    "    print(f\"Context: {example['plutchik']}\")\n",
    "    print(f\"  A - {example['selection0']}\")\n",
    "    print(f\"  B - {example['selection1']}\")\n",
    "    print(f\"  C - {example['selection2']}\")\n",
    "    print(f\"  D - {example['selection3']}\")\n",
    "    print(f\"\\nGround truth: option {['A', 'B', 'C', 'D'][example['label']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15cd7cfb-748a-4fe7-8152-7debf6a65ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: {'joy': 0, 'trust': 2, 'fear': 1, 'surprise': 0, 'sadness': 0, 'disgust': 0, 'anger': 0, 'anticipation': 2}\n",
      "  A - Finally, the day came when she could get in the ring.\n",
      "  B - They're planning to learn to weave together!\n",
      "  C - Tim was playing in the house.\n",
      "  C - He asked his friend for advice about the problem he had.\n",
      "\n",
      "Ground truth: option D\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da93346-1037-41ed-b67d-91877fa8c0ec",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3da78c12-9aff-4beb-a006-e287bbf61023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "caffe397-a65d-478f-b966-7b910fb2edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "selectionList = [\"selection0\", \"selection1\", \"selection2\", \"selection3\"]\n",
    "weightRemap = [\"NOT \", \"LITTLE \", \"\", \"VERY \", \"ABSOLUTELY \"]\n",
    "def preprocess_function(examples):\n",
    "    # Repeat each first sentence four times to go with the four possibilities of second sentences.\n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(context.strip(\"[\").strip(\"]\").replace('\\'', '')) ]*2 for context in examples[\"emotion\"] ]\n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(context.strip(\"[\").strip(\"]\").replace('\\\"', '')) ]*2 for context in examples[\"plutchik\"] ]\n",
    "    first_sentences = [[\"The following sentences contain emotions: {}\".format(\", \".join([weightRemap[int(eachCaseWeight.replace(\"]\", \"\").replace(\"[\", \"\").replace(\"}\", \"\").replace(\"{\", \"\").replace(\"\\\"\", \"\").replace(\"\\'\", \"\"))] \n",
    "                                                        + eachCaseEmotionType.replace(\"]\", \"\").replace(\"[\", \"\").replace(\"}\", \"\").replace(\"{\", \"\").replace(\"\\\"\", \"\").replace(\"\\'\", \"\").strip()\n",
    "                        for eachCaseWeight, eachCaseEmotionType in \n",
    "                        zip([re.split(':|,',eachEmotionCombination)[1::2] for eachEmotionCombination in examples[\"plutchik\"]][eventIndex], \n",
    "                           [re.split(':|,',eachEmotionCombination)[::2] for eachEmotionCombination in examples[\"plutchik\"]][eventIndex])]))]*4 for eventIndex in \n",
    "                           range(len([re.split(':|,',eachEmotionCombination)[1::2] for eachEmotionCombination in examples[\"plutchik\"]]))]\n",
    "    \n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(', '.join([(weightRemap[eachEmotion[1]] + \" \" +eachEmotion[0]).strip() \n",
    "    #                    for eachEmotion in ast.literal_eval(context).items()]))]*2 \n",
    "    #                    for context in examples[\"plutchik\"]]\n",
    "    # Grab all second sentences possible for each context.\n",
    "    second_sentences = [[examples[selection][index] for selection in selectionList]for index in range(len(examples['selection0']))]\n",
    "\n",
    "    # Flatten everything\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "    \n",
    "    # Tokenize\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "    # Un-flatten\n",
    "    # print(tokenized_examples.items())\n",
    "    return {k: [v[i:i+4] for i in range(0, len(v), 4)] for k, v in tokenized_examples.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0afb4841-ab69-4b91-8859-fd249badb923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 4 [46, 42, 40, 45]\n"
     ]
    }
   ],
   "source": [
    "examples = dataset[\"train\"][:5]\n",
    "features = preprocess_function(examples)\n",
    "print(len(features[\"input_ids\"]), len(features[\"input_ids\"][0]), [len(x) for x in features[\"input_ids\"][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "903e2891-0e3d-4e87-b98a-727eaf36417a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>The following sentences contain emotions: NOT joy, trust, LITTLE fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, anticipation</s></s>Finally, the day came when she could get in the ring.</s>',\n",
       " \"<s>The following sentences contain emotions: NOT joy, trust, LITTLE fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, anticipation</s></s>They're planning to learn to weave together!</s>\",\n",
       " '<s>The following sentences contain emotions: NOT joy, trust, LITTLE fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, anticipation</s></s>Tim was playing in the house.</s>',\n",
       " '<s>The following sentences contain emotions: LITTLE joy, LITTLE trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, anticipation</s></s>He showed up the next day with white skin and no muscles.</s>',\n",
       " '<s>The following sentences contain emotions: LITTLE joy, LITTLE trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, anticipation</s></s>I opened the large door with my shoulder.</s>',\n",
       " '<s>The following sentences contain emotions: LITTLE joy, LITTLE trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, anticipation</s></s>Lonnie had the biggest crush on Lorrie.</s>',\n",
       " '<s>The following sentences contain emotions: NOT joy, NOT trust, LITTLE fear, NOT surprise, sadness, NOT disgust, NOT anger, NOT anticipation</s></s>Terrin moved back, but changed a lot.</s>',\n",
       " '<s>The following sentences contain emotions: NOT joy, NOT trust, LITTLE fear, NOT surprise, sadness, NOT disgust, NOT anger, NOT anticipation</s></s>He was tired of walking.</s>',\n",
       " '<s>The following sentences contain emotions: NOT joy, NOT trust, LITTLE fear, NOT surprise, sadness, NOT disgust, NOT anger, NOT anticipation</s></s>Larry received a toy for his birthday.</s>',\n",
       " \"<s>The following sentences contain emotions: NOT joy, NOT trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, LITTLE anticipation</s></s>He couldn't keep fixing it.</s>\",\n",
       " '<s>The following sentences contain emotions: NOT joy, NOT trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, LITTLE anticipation</s></s>In the moving process, Tubby was misplaced in one of the boxes.</s>',\n",
       " '<s>The following sentences contain emotions: NOT joy, NOT trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, LITTLE anticipation</s></s>Right now i can only leg lift about one hundred pounds.</s>',\n",
       " '<s>The following sentences contain emotions: joy, trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, VERY anticipation</s></s>While leaving the office, William closed his finger between the doors.</s>',\n",
       " '<s>The following sentences contain emotions: joy, trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, VERY anticipation</s></s>Liam moved to a new house.</s>',\n",
       " \"<s>The following sentences contain emotions: joy, trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, VERY anticipation</s></s>It's tempting to keep holding the rope.</s>\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(features[\"input_ids\"][a][i]) for a in range(5) for i in range(4) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a286ba6-cb84-4619-b842-780124d26a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c98af9ec994d5f92ef657d08a6d564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0241766f7663465492350d7a80a1e531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7706d875-3a89-4e52-9f08-c77256b621ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForMultipleChoice: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForMultipleChoice.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cd7be65-ebd8-43db-bcbf-a87d7e2342e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-emotionCommonsense\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=5e-6, # for bert-base\n",
    "    # learning_rate=1e-3,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2737e04e-19c2-407d-8ce1-06b675f208c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [[{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        # Un-flatten\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        # Add back labels\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03a0ec05-de5e-434f-b07c-63212e7c7f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_keys = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "features = [{k: v for k, v in encoded_datasets[\"train\"][i].items() if k in accepted_keys} for i in range(10)]\n",
    "batch = DataCollatorForMultipleChoice(tokenizer)(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45f7f26c-04bb-42ae-8627-897ced69888e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>The following sentences contain emotions: VERY joy, trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, anticipation</s></s>This time the train was late.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " \"<s>The following sentences contain emotions: VERY joy, trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, anticipation</s></s>The night ended up a success even though I didn't spend a dime.</s><pad><pad><pad><pad><pad><pad><pad>\",\n",
       " '<s>The following sentences contain emotions: VERY joy, trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, anticipation</s></s>They started eating their hot dog lunches.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<s>The following sentences contain emotions: VERY joy, trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, anticipation</s></s>A week later the shoes arrived in Cambridge.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(batch[\"input_ids\"][8][i].tolist()) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4b55256-30fa-4e30-a3a4-66fe1114b941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: {'joy': 3, 'trust': 2, 'fear': 0, 'surprise': 1, 'sadness': 0, 'disgust': 0, 'anger': 0, 'anticipation': 2}\n",
      "  A - This time the train was late.\n",
      "  B - The night ended up a success even though I didn't spend a dime.\n",
      "  C - They started eating their hot dog lunches.\n",
      "  C - A week later the shoes arrived in Cambridge.\n",
      "\n",
      "Ground truth: option B\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8305d3-8dc9-4d0f-8628-f51dc356c2d2",
   "metadata": {},
   "source": [
    "# Trainer Defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b707863a-bc16-43b0-b633-c7ffb4fa72e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "valStored = []\n",
    "def compute_metrics(eval_predictions):\n",
    "    predictions, label_ids = eval_predictions\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    valStored.append((preds != label_ids).astype(np.float32));\n",
    "    return {\"accuracy\": (preds == label_ids).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b115c1ba-323a-47d5-bb9d-55de985f13b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_datasets[\"train\"],\n",
    "    eval_dataset=encoded_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a5e3430-bbd6-484d-8a8d-9cbcdba37d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "C:\\Python\\miniconda3\\envs\\pytorchEnvWithDataSci\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 53234\n",
      "  Num Epochs = 16\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53248\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53248' max='53248' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53248/53248 2:26:59, Epoch 16/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.693800</td>\n",
       "      <td>0.693128</td>\n",
       "      <td>0.504018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.614600</td>\n",
       "      <td>0.594435</td>\n",
       "      <td>0.656838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.564700</td>\n",
       "      <td>0.571774</td>\n",
       "      <td>0.684685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.526300</td>\n",
       "      <td>0.572104</td>\n",
       "      <td>0.695053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.499500</td>\n",
       "      <td>0.586160</td>\n",
       "      <td>0.701162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.472300</td>\n",
       "      <td>0.586649</td>\n",
       "      <td>0.705170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.620333</td>\n",
       "      <td>0.704207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.444200</td>\n",
       "      <td>0.623844</td>\n",
       "      <td>0.704265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.415700</td>\n",
       "      <td>0.655308</td>\n",
       "      <td>0.705055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.394100</td>\n",
       "      <td>0.685141</td>\n",
       "      <td>0.703860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.375700</td>\n",
       "      <td>0.723962</td>\n",
       "      <td>0.702183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.371000</td>\n",
       "      <td>0.727208</td>\n",
       "      <td>0.702646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.339400</td>\n",
       "      <td>0.768802</td>\n",
       "      <td>0.702723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.327800</td>\n",
       "      <td>0.798015</td>\n",
       "      <td>0.701258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.320600</td>\n",
       "      <td>0.806652</td>\n",
       "      <td>0.700892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.310600</td>\n",
       "      <td>0.814122</td>\n",
       "      <td>0.700565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-1500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-2500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-3500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-4500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-5500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-6500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-7500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-8500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-9500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-10500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-11500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-12500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-13500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-14500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-15500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-16500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-17500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-18500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-19500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-20500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-21500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-22500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-23500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-24500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-25500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-26500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-27500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-28500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-29500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-30500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-31500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-32500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-33500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-34500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-35500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-36500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-37500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-38500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-39500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-40500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-41500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-42500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-43500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-44500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-45500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-46500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-47500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-48500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-49500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-50500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-51500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52000\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52500\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52500\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-52500\\special_tokens_map.json\n",
      "Saving model checkpoint to bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-53000\n",
      "Configuration saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-53000\\config.json\n",
      "Model weights saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-53000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-53000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-finetuned-emotionCommonsense\\checkpoint-53000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: plutchik, Unnamed: 0, selection1, emotion, selection0. If plutchik, Unnamed: 0, selection1, emotion, selection0 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=53248, training_loss=0.4483006133769567, metrics={'train_runtime': 8821.4262, 'train_samples_per_second': 96.554, 'train_steps_per_second': 6.036, 'total_flos': 5.267817952412011e+16, 'train_loss': 0.4483006133769567, 'epoch': 16.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a17948-a8f7-4450-b2b0-8a7016e91391",
   "metadata": {},
   "source": [
    "出现validation loss 上升情况大多是训练集验证集数据分布不一致，或者训练集过小，未包含验证集中所有情况，\n",
    "也就是过拟合导致的。而解决这种现象可以尝试以下几种策略：\n",
    "1. 增加训练样本增加正则项系数权重，\n",
    "2. 减小过拟合加入早停机制，ValLoss上升几个epoch直接停止\n",
    "3. 采用Focal Loss\n",
    "4. 加入Label Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d6ab3-33ac-4e8e-99ee-3c3f17d71642",
   "metadata": {},
   "source": [
    "# Store Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c30271fe-7ce9-43e8-9e87-de8d6ae2c2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x23113595460>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "Z = np.transpose(valStored)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.pcolormesh(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e77d30e-e51a-45a6-9130-83a17c4d2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataLog = pd.DataFrame(trainer.state.log_history)\n",
    "dataLog.to_csv(f'./trainingMetric/[plutchik]trainingInfo-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c90cfec4-96ec-46c8-a99f-3c78b989b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluationIterationResult = pd.DataFrame(np.transpose(valStored))\n",
    "evaluationIterationResult.to_csv(f'./trainingMetric/[plutchik]evaluationSpecificInfo-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd7f330-1477-4119-a9dc-1ebb7acb7665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchEnvWithDataSci",
   "language": "python",
   "name": "pytorchenvwithdatasci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
