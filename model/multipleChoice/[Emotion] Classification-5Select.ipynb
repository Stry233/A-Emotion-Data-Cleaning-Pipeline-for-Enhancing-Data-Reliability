{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1615a8a-9813-4956-b4ed-33ef2ea30723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'roberta-large'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# global var set\n",
    "import transformers\n",
    "\n",
    "# model info, change as needed\n",
    "model_checkpoint = \"roberta-large\"\n",
    "batch_size = 4\n",
    "num_epochs = 10\n",
    "\n",
    "# fileTag = \"clean-v1\"                      # clean + no phase + combine    (pure clean)\n",
    "fileTag = \"clean-phase-v1\"                # clean +   phase  + combine\n",
    "#fileTag = 'clean-phase-noCombin-v1'       # clean +   phase  + no combine\n",
    "#fileTag = 'original-noCheat-noCombin-v1'  # raw   +   no Cheat case\n",
    "#fileTag = 'original'                        # row   +   keep Cheat case     (pure raw) \n",
    "\n",
    "model_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b9d76f-5ed6-4ab9-8c62-f6d6a8b47be4",
   "metadata": {},
   "source": [
    "# Convert dataset to suitable format\n",
    "IMPORTANT: please never run this section again if you have your dataset ready!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a93a9f46-6703-4535-af96-8be1b5b3407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "trainDatasetOriginal = pd.read_csv(f'../../data/csv_version/dev/emotion/allcharlinepairs-{fileTag}.csv')\n",
    "testDatasetOriginal = pd.read_csv(f'../../data/csv_version/test/emotion/allcharlinepairs-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7265a797-adc2-49ed-b237-19abf9e0569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatasetProcessed = DataFrame({'emotion' : trainDatasetOriginal['emotion'],\n",
    "                                   'plutchik' : trainDatasetOriginal['plutchik'],\n",
    "                                  'selection0': pd.concat([trainDatasetOriginal['sentence'][:trainDatasetOriginal.shape[0]//5], trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//5:]]), \n",
    "                                  'selection1': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//5], \n",
    "                                                pd.concat([trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//5:trainDatasetOriginal.shape[0]//5*2], \n",
    "                                                trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//5*2:]])]), \n",
    "                                  'selection2': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//5*2], \n",
    "                                                pd.concat([trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//5*2:trainDatasetOriginal.shape[0]//5*3], \n",
    "                                                trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//5*3:]])]), \n",
    "                                  'selection3': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//5*3], \n",
    "                                                pd.concat([trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//5*3:trainDatasetOriginal.shape[0]//5*4], \n",
    "                                                trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//5*4:]])]),\n",
    "                                  'selection4': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//5*4], \n",
    "                                                           trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//5*4:]]),\n",
    "                                  'label': pd.Series(0 if x < trainDatasetOriginal.shape[0]//5 else (1 if x < trainDatasetOriginal.shape[0]//5*2 \n",
    "                                                                                               else (2 if x < trainDatasetOriginal.shape[0]//5*3 \n",
    "                                                                                               else (3 if x < trainDatasetOriginal.shape[0]//5*4\n",
    "                                                                                               else  4))) for x in trainDatasetOriginal.index)}).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "testDatasetProcessed = DataFrame({'emotion' : testDatasetOriginal['emotion'],\n",
    "                                   'plutchik' : testDatasetOriginal['plutchik'],\n",
    "                                  'selection0': pd.concat([testDatasetOriginal['sentence'][:testDatasetOriginal.shape[0]//5], testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//5:]]), \n",
    "                                  'selection1': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//5], \n",
    "                                                pd.concat([testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//5:testDatasetOriginal.shape[0]//5*2], \n",
    "                                                testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//5*2:]])]), \n",
    "                                  'selection2': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//5*2], \n",
    "                                                pd.concat([testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//5*2:testDatasetOriginal.shape[0]//5*3], \n",
    "                                                testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//5*3:]])]), \n",
    "                                  'selection3': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//5*3], \n",
    "                                                pd.concat([testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//5*3:testDatasetOriginal.shape[0]//5*4], \n",
    "                                                testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//5*4:]])]),\n",
    "                                  'selection4': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//5*4], \n",
    "                                                           testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//5*4:]]),\n",
    "                                  'label': pd.Series(0 if x < testDatasetOriginal.shape[0]//5 else (1 if x < testDatasetOriginal.shape[0]//5*2 \n",
    "                                                                                               else (2 if x < testDatasetOriginal.shape[0]//5*3 \n",
    "                                                                                               else (3 if x < testDatasetOriginal.shape[0]//5*4\n",
    "                                                                                               else  4))) for x in testDatasetOriginal.index)}).sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19e3c334-b371-44ad-b6e1-7161f405b741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>plutchik</th>\n",
       "      <th>selection0</th>\n",
       "      <th>selection1</th>\n",
       "      <th>selection2</th>\n",
       "      <th>selection3</th>\n",
       "      <th>selection4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"funny\"]</td>\n",
       "      <td>[\"joy:2\", \"trust:2\", \"surprise:2\", \"anticipati...</td>\n",
       "      <td>Sally liked toys alot for xmas.</td>\n",
       "      <td>But then she woke up.</td>\n",
       "      <td>Professor Smith asked for forgiveness, he'd re...</td>\n",
       "      <td>I was in so much pain.</td>\n",
       "      <td>Six of his friends had the same idea.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"upset\"]</td>\n",
       "      <td>[\"disgust:2\", \"anger:2\", \"anticipation:2\"]</td>\n",
       "      <td>Mary was walking in the park when she heard a ...</td>\n",
       "      <td>To her surprise, she found it delicious!</td>\n",
       "      <td>I really thought it turned out terrible.</td>\n",
       "      <td>My daughter jumped up and grabbed the blue one...</td>\n",
       "      <td>He had a passion to change his country for bet...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"proud\"]</td>\n",
       "      <td>[\"joy:3\", \"trust:3\"]</td>\n",
       "      <td>They were very sweet when we went to meet them.</td>\n",
       "      <td>They ended up putting on a wonderful show for ...</td>\n",
       "      <td>A red sock had been hidden in the load and dye...</td>\n",
       "      <td>Her mother loved the picture and Jennifer deci...</td>\n",
       "      <td>Kylie invited her to get coffee and the two re...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"happy\"]</td>\n",
       "      <td>[\"joy:3\", \"trust:2\"]</td>\n",
       "      <td>However, her voice cracked when she was trying...</td>\n",
       "      <td>She told me it was everyone and everything.</td>\n",
       "      <td>Gina wanted to sit in her dad's car to be alone.</td>\n",
       "      <td>When the other kids wouldn't move over I'd sta...</td>\n",
       "      <td>Eventually he starts to have favorite televisi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"anxious\", \"ready\", \"encouraged\"]</td>\n",
       "      <td>[\"anticipation:2\"]</td>\n",
       "      <td>The chef worked his helpers very hard.</td>\n",
       "      <td>She demonstrated the Mac computer and it worke...</td>\n",
       "      <td>Davis decided that he needed to become more ac...</td>\n",
       "      <td>He thought it was a shark.</td>\n",
       "      <td>I got a little lost when it was my turn to hide.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53229</th>\n",
       "      <td>[\"none\"]</td>\n",
       "      <td>[\"none\"]</td>\n",
       "      <td>He had to have professionals go in and find it.</td>\n",
       "      <td>They had to stay at a dingy motel nearby.</td>\n",
       "      <td>They had a chance to help hold a hose spraying...</td>\n",
       "      <td>Ted was excited about opening up his new elect...</td>\n",
       "      <td>She saw a small duck swimming around.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53230</th>\n",
       "      <td>[\"happy\", \"excited\", \"accepted\"]</td>\n",
       "      <td>[\"joy:3\", \"trust:3\", \"surprise:3\", \"anticipati...</td>\n",
       "      <td>Amy called her friends to come to a surprise b...</td>\n",
       "      <td>I had no idea I was sitting on the lap of a le...</td>\n",
       "      <td>Lexi finally got the courage to try to sing.</td>\n",
       "      <td>She did not cry but she was very skeptical abo...</td>\n",
       "      <td>Luckily, his friend lived nearby.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53231</th>\n",
       "      <td>[\"nervous\"]</td>\n",
       "      <td>[\"fear:2\", \"surprise:2\", \"anticipation:2\"]</td>\n",
       "      <td>She accidentally hit the emergency brake.</td>\n",
       "      <td>When Rick woke up he couldn't see anyone.</td>\n",
       "      <td>All his roommates loved the smell.</td>\n",
       "      <td>We ended up getting married unnecessarily.</td>\n",
       "      <td>When he got to school he tried to study.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53232</th>\n",
       "      <td>[\"confused\"]</td>\n",
       "      <td>[\"fear:2\"]</td>\n",
       "      <td>When Agnes and Allen married they planned to r...</td>\n",
       "      <td>Her teacher promoted her to the next class up.</td>\n",
       "      <td>He didn't know if they were going to take his ...</td>\n",
       "      <td>The neighbor wanted privacy and had erected th...</td>\n",
       "      <td>Ryan was so happy when the neighbor called to ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53233</th>\n",
       "      <td>[\"amused\"]</td>\n",
       "      <td>[\"joy:2\", \"surprise:2\"]</td>\n",
       "      <td>Everyone saw this and laughed.</td>\n",
       "      <td>Tom bought a large quantity of the healthy gum.</td>\n",
       "      <td>She did her best to keep up with them in pract...</td>\n",
       "      <td>I was at home one day when I heard what sounde...</td>\n",
       "      <td>He drove from Virginia to California to visit ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53234 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  emotion  \\\n",
       "0                               [\"funny\"]   \n",
       "1                               [\"upset\"]   \n",
       "2                               [\"proud\"]   \n",
       "3                               [\"happy\"]   \n",
       "4      [\"anxious\", \"ready\", \"encouraged\"]   \n",
       "...                                   ...   \n",
       "53229                            [\"none\"]   \n",
       "53230    [\"happy\", \"excited\", \"accepted\"]   \n",
       "53231                         [\"nervous\"]   \n",
       "53232                        [\"confused\"]   \n",
       "53233                          [\"amused\"]   \n",
       "\n",
       "                                                plutchik  \\\n",
       "0      [\"joy:2\", \"trust:2\", \"surprise:2\", \"anticipati...   \n",
       "1             [\"disgust:2\", \"anger:2\", \"anticipation:2\"]   \n",
       "2                                   [\"joy:3\", \"trust:3\"]   \n",
       "3                                   [\"joy:3\", \"trust:2\"]   \n",
       "4                                     [\"anticipation:2\"]   \n",
       "...                                                  ...   \n",
       "53229                                           [\"none\"]   \n",
       "53230  [\"joy:3\", \"trust:3\", \"surprise:3\", \"anticipati...   \n",
       "53231         [\"fear:2\", \"surprise:2\", \"anticipation:2\"]   \n",
       "53232                                         [\"fear:2\"]   \n",
       "53233                            [\"joy:2\", \"surprise:2\"]   \n",
       "\n",
       "                                              selection0  \\\n",
       "0                        Sally liked toys alot for xmas.   \n",
       "1      Mary was walking in the park when she heard a ...   \n",
       "2        They were very sweet when we went to meet them.   \n",
       "3      However, her voice cracked when she was trying...   \n",
       "4                 The chef worked his helpers very hard.   \n",
       "...                                                  ...   \n",
       "53229    He had to have professionals go in and find it.   \n",
       "53230  Amy called her friends to come to a surprise b...   \n",
       "53231          She accidentally hit the emergency brake.   \n",
       "53232  When Agnes and Allen married they planned to r...   \n",
       "53233                     Everyone saw this and laughed.   \n",
       "\n",
       "                                              selection1  \\\n",
       "0                                  But then she woke up.   \n",
       "1               To her surprise, she found it delicious!   \n",
       "2      They ended up putting on a wonderful show for ...   \n",
       "3            She told me it was everyone and everything.   \n",
       "4      She demonstrated the Mac computer and it worke...   \n",
       "...                                                  ...   \n",
       "53229          They had to stay at a dingy motel nearby.   \n",
       "53230  I had no idea I was sitting on the lap of a le...   \n",
       "53231          When Rick woke up he couldn't see anyone.   \n",
       "53232     Her teacher promoted her to the next class up.   \n",
       "53233    Tom bought a large quantity of the healthy gum.   \n",
       "\n",
       "                                              selection2  \\\n",
       "0      Professor Smith asked for forgiveness, he'd re...   \n",
       "1               I really thought it turned out terrible.   \n",
       "2      A red sock had been hidden in the load and dye...   \n",
       "3       Gina wanted to sit in her dad's car to be alone.   \n",
       "4      Davis decided that he needed to become more ac...   \n",
       "...                                                  ...   \n",
       "53229  They had a chance to help hold a hose spraying...   \n",
       "53230       Lexi finally got the courage to try to sing.   \n",
       "53231                 All his roommates loved the smell.   \n",
       "53232  He didn't know if they were going to take his ...   \n",
       "53233  She did her best to keep up with them in pract...   \n",
       "\n",
       "                                              selection3  \\\n",
       "0                                 I was in so much pain.   \n",
       "1      My daughter jumped up and grabbed the blue one...   \n",
       "2      Her mother loved the picture and Jennifer deci...   \n",
       "3      When the other kids wouldn't move over I'd sta...   \n",
       "4                             He thought it was a shark.   \n",
       "...                                                  ...   \n",
       "53229  Ted was excited about opening up his new elect...   \n",
       "53230  She did not cry but she was very skeptical abo...   \n",
       "53231         We ended up getting married unnecessarily.   \n",
       "53232  The neighbor wanted privacy and had erected th...   \n",
       "53233  I was at home one day when I heard what sounde...   \n",
       "\n",
       "                                              selection4  label  \n",
       "0                  Six of his friends had the same idea.      4  \n",
       "1      He had a passion to change his country for bet...      2  \n",
       "2      Kylie invited her to get coffee and the two re...      3  \n",
       "3      Eventually he starts to have favorite televisi...      1  \n",
       "4       I got a little lost when it was my turn to hide.      2  \n",
       "...                                                  ...    ...  \n",
       "53229              She saw a small duck swimming around.      4  \n",
       "53230                  Luckily, his friend lived nearby.      0  \n",
       "53231           When he got to school he tried to study.      1  \n",
       "53232  Ryan was so happy when the neighbor called to ...      2  \n",
       "53233  He drove from Virginia to California to visit ...      0  \n",
       "\n",
       "[53234 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDatasetProcessed.to_csv(f'./dataset/5Select-{fileTag}-train.csv')\n",
    "trainDatasetProcessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b770299d-567d-46e2-b928-8ee31a341c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>plutchik</th>\n",
       "      <th>selection0</th>\n",
       "      <th>selection1</th>\n",
       "      <th>selection2</th>\n",
       "      <th>selection3</th>\n",
       "      <th>selection4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"strange\"]</td>\n",
       "      <td>[\"surprise:3\"]</td>\n",
       "      <td>Lauren decided to go to the museum.</td>\n",
       "      <td>He is learning French.</td>\n",
       "      <td>Steven brought the couch home and set it up.</td>\n",
       "      <td>His wife was terribly embarrassed.</td>\n",
       "      <td>She really wanted to speak!</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"lively\"]</td>\n",
       "      <td>[\"joy:3\", \"trust:2\", \"surprise:2\"]</td>\n",
       "      <td>Daniel is driving home from work.</td>\n",
       "      <td>Every since I could remember, I didn't feel li...</td>\n",
       "      <td>A substitute teacher came to teach her class f...</td>\n",
       "      <td>After that the horse let him ride for a long t...</td>\n",
       "      <td>It was dark and they were scary.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"relieved\", \"thankful\"]</td>\n",
       "      <td>[\"joy:3\"]</td>\n",
       "      <td>He called his mom to bring some spare keys.</td>\n",
       "      <td>The girl he liked read the letter and was quit...</td>\n",
       "      <td>His mom came and unlocked the car.</td>\n",
       "      <td>Mr Cooper found out about the affair after com...</td>\n",
       "      <td>Ben worked on a report late at night.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"satisfied\"]</td>\n",
       "      <td>[\"joy:2\", \"trust:2\", \"surprise:2\", \"anticipati...</td>\n",
       "      <td>Which made more milk come out.</td>\n",
       "      <td>The next day Sam happily took his stolen blue ...</td>\n",
       "      <td>He had never played before and spent many hour...</td>\n",
       "      <td>While their guard was down the opposition reta...</td>\n",
       "      <td>So he put frozen pizza in his oven.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"helpful\"]</td>\n",
       "      <td>[\"joy:3\", \"trust:2\", \"anticipation:2\"]</td>\n",
       "      <td>She ate it for lunch everyday for a week.</td>\n",
       "      <td>He took his job very seriously.</td>\n",
       "      <td>He lives so far out into the country that he s...</td>\n",
       "      <td>When he got to the restaurant, he stood where ...</td>\n",
       "      <td>After that day, every time I got in the pool I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51886</th>\n",
       "      <td>[\"nervous\"]</td>\n",
       "      <td>[\"fear:2\", \"surprise:2\", \"anticipation:3\"]</td>\n",
       "      <td>Joe and Jim were avid hikers.</td>\n",
       "      <td>And drinking the coffee made her feel warm.</td>\n",
       "      <td>He went shopping for the food he would cook.</td>\n",
       "      <td>He was worried about one thing, though.</td>\n",
       "      <td>He dressed and he took the bus to work</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51887</th>\n",
       "      <td>[\"clever\"]</td>\n",
       "      <td>[]</td>\n",
       "      <td>The vet gave it some medicine.</td>\n",
       "      <td>It was far too sour and Suzy never wanted coff...</td>\n",
       "      <td>She assumed it was because of the coal power p...</td>\n",
       "      <td>After much thought he laid his coat on the gro...</td>\n",
       "      <td>They switched places to see if he would notice.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51888</th>\n",
       "      <td>[\"none\"]</td>\n",
       "      <td>[\"none\"]</td>\n",
       "      <td>He sent it in the mail to the buyer.</td>\n",
       "      <td>We finished much quicker as a team than if I d...</td>\n",
       "      <td>But when she bit into it, her face twisted.</td>\n",
       "      <td>Jack was glad he could buy his own shoes.</td>\n",
       "      <td>He shuddered with anticipation at the confirma...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51889</th>\n",
       "      <td>[\"Relieved\"]</td>\n",
       "      <td>[\"joy:3\", \"trust:2\", \"fear:2\", \"surprise:3\", \"...</td>\n",
       "      <td>Jennie recently started feeling distant from T...</td>\n",
       "      <td>Then as it got dark, a sculpture carved like a...</td>\n",
       "      <td>I quickly left the dog park.</td>\n",
       "      <td>He felt lucky to have a seat next to someone h...</td>\n",
       "      <td>Mary was cooking dinner.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51890</th>\n",
       "      <td>[\"helpful\"]</td>\n",
       "      <td>[\"joy:2\", \"trust:2\"]</td>\n",
       "      <td>He was so nervous, but knew he had to ask her ...</td>\n",
       "      <td>One day, she saw a lonely kitty walking alone.</td>\n",
       "      <td>She tried several times but all of her tries l...</td>\n",
       "      <td>Kate used a lot of software to remove them.</td>\n",
       "      <td>He fell to his knees with shortness of breath ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        emotion  \\\n",
       "0                   [\"strange\"]   \n",
       "1                    [\"lively\"]   \n",
       "2      [\"relieved\", \"thankful\"]   \n",
       "3                 [\"satisfied\"]   \n",
       "4                   [\"helpful\"]   \n",
       "...                         ...   \n",
       "51886               [\"nervous\"]   \n",
       "51887                [\"clever\"]   \n",
       "51888                  [\"none\"]   \n",
       "51889              [\"Relieved\"]   \n",
       "51890               [\"helpful\"]   \n",
       "\n",
       "                                                plutchik  \\\n",
       "0                                         [\"surprise:3\"]   \n",
       "1                     [\"joy:3\", \"trust:2\", \"surprise:2\"]   \n",
       "2                                              [\"joy:3\"]   \n",
       "3      [\"joy:2\", \"trust:2\", \"surprise:2\", \"anticipati...   \n",
       "4                 [\"joy:3\", \"trust:2\", \"anticipation:2\"]   \n",
       "...                                                  ...   \n",
       "51886         [\"fear:2\", \"surprise:2\", \"anticipation:3\"]   \n",
       "51887                                                 []   \n",
       "51888                                           [\"none\"]   \n",
       "51889  [\"joy:3\", \"trust:2\", \"fear:2\", \"surprise:3\", \"...   \n",
       "51890                               [\"joy:2\", \"trust:2\"]   \n",
       "\n",
       "                                              selection0  \\\n",
       "0                    Lauren decided to go to the museum.   \n",
       "1                      Daniel is driving home from work.   \n",
       "2            He called his mom to bring some spare keys.   \n",
       "3                         Which made more milk come out.   \n",
       "4              She ate it for lunch everyday for a week.   \n",
       "...                                                  ...   \n",
       "51886                      Joe and Jim were avid hikers.   \n",
       "51887                     The vet gave it some medicine.   \n",
       "51888               He sent it in the mail to the buyer.   \n",
       "51889  Jennie recently started feeling distant from T...   \n",
       "51890  He was so nervous, but knew he had to ask her ...   \n",
       "\n",
       "                                              selection1  \\\n",
       "0                                 He is learning French.   \n",
       "1      Every since I could remember, I didn't feel li...   \n",
       "2      The girl he liked read the letter and was quit...   \n",
       "3      The next day Sam happily took his stolen blue ...   \n",
       "4                        He took his job very seriously.   \n",
       "...                                                  ...   \n",
       "51886        And drinking the coffee made her feel warm.   \n",
       "51887  It was far too sour and Suzy never wanted coff...   \n",
       "51888  We finished much quicker as a team than if I d...   \n",
       "51889  Then as it got dark, a sculpture carved like a...   \n",
       "51890     One day, she saw a lonely kitty walking alone.   \n",
       "\n",
       "                                              selection2  \\\n",
       "0           Steven brought the couch home and set it up.   \n",
       "1      A substitute teacher came to teach her class f...   \n",
       "2                     His mom came and unlocked the car.   \n",
       "3      He had never played before and spent many hour...   \n",
       "4      He lives so far out into the country that he s...   \n",
       "...                                                  ...   \n",
       "51886       He went shopping for the food he would cook.   \n",
       "51887  She assumed it was because of the coal power p...   \n",
       "51888        But when she bit into it, her face twisted.   \n",
       "51889                       I quickly left the dog park.   \n",
       "51890  She tried several times but all of her tries l...   \n",
       "\n",
       "                                              selection3  \\\n",
       "0                     His wife was terribly embarrassed.   \n",
       "1      After that the horse let him ride for a long t...   \n",
       "2      Mr Cooper found out about the affair after com...   \n",
       "3      While their guard was down the opposition reta...   \n",
       "4      When he got to the restaurant, he stood where ...   \n",
       "...                                                  ...   \n",
       "51886            He was worried about one thing, though.   \n",
       "51887  After much thought he laid his coat on the gro...   \n",
       "51888          Jack was glad he could buy his own shoes.   \n",
       "51889  He felt lucky to have a seat next to someone h...   \n",
       "51890        Kate used a lot of software to remove them.   \n",
       "\n",
       "                                              selection4  label  \n",
       "0                            She really wanted to speak!      4  \n",
       "1                       It was dark and they were scary.      3  \n",
       "2                  Ben worked on a report late at night.      2  \n",
       "3                    So he put frozen pizza in his oven.      2  \n",
       "4      After that day, every time I got in the pool I...      1  \n",
       "...                                                  ...    ...  \n",
       "51886             He dressed and he took the bus to work      3  \n",
       "51887    They switched places to see if he would notice.      3  \n",
       "51888  He shuddered with anticipation at the confirma...      4  \n",
       "51889                           Mary was cooking dinner.      3  \n",
       "51890  He fell to his knees with shortness of breath ...      3  \n",
       "\n",
       "[51891 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDatasetProcessed.to_csv(f'./dataset/5Select-{fileTag}-test.csv')\n",
    "testDatasetProcessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7283c1-d83e-4369-b5e4-6c2e09d654ac",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "828a5092-83e6-4580-99c9-bd9ec434708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05151e3b-0bec-44f4-bf0a-ac58cddbf838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-4f7a012c76cd326e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to C:\\Users\\evans\\.cache\\huggingface\\datasets\\csv\\default-4f7a012c76cd326e\\0.0.0\\2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:\\Users\\evans\\.cache\\huggingface\\datasets\\csv\\default-4f7a012c76cd326e\\0.0.0\\2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv', data_files={'train': f'./dataset/5Select-{fileTag}-train.csv', \n",
    "                                           'test': f'./dataset/5Select-{fileTag}-test.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d776c270-7752-4445-ba6c-eb078f71eccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'emotion', 'plutchik', 'selection0', 'selection1', 'selection2', 'selection3', 'selection4', 'label'],\n",
       "        num_rows: 11610\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'emotion', 'plutchik', 'selection0', 'selection1', 'selection2', 'selection3', 'selection4', 'label'],\n",
       "        num_rows: 11129\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1c79159-f795-4d02-b052-94f04286d53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 0,\n",
       " 'emotion': \"['upset', 'frustrated', 'unsatisfied']\",\n",
       " 'label': 3,\n",
       " 'plutchik': \"{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': 1, 'sadness': 1, 'disgust': 0, 'anger': 0, 'anticipation': 2}\",\n",
       " 'selection0': 'The captain gasped and they hit the underside of the boat.',\n",
       " 'selection1': 'Reading and the motion of the bus soon lulled him to sleep.',\n",
       " 'selection2': 'I fell and hurt my back.',\n",
       " 'selection3': 'Then she realized she was out of butter.',\n",
       " 'selection4': 'They put new staples in the stapler.'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f6ad67d-b4cb-4f65-a9cb-d2d665deec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_one(example):\n",
    "    print(f\"Context: {example['emotion']}\")\n",
    "    print(f\"  A - {example['selection0']}\")\n",
    "    print(f\"  B - {example['selection1']}\")\n",
    "    print(f\"  C - {example['selection2']}\")\n",
    "    print(f\"  D - {example['selection3']}\")\n",
    "    print(f\"  E - {example['selection4']}\")\n",
    "    print(f\"\\nGround truth: option {['A', 'B', 'C', 'D', 'E'][example['label']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15cd7cfb-748a-4fe7-8152-7debf6a65ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: ['awful', 'upset', 'disappointed', 'embarrassed', 'irritated']\n",
      "  A - She felt like she was an adult so she made cup of coffee.\n",
      "  B - His mom made an appointment with the barber for next week.\n",
      "  C - The toughest gal around wanted to fight.\n",
      "  D - She was so uncomfortable, she had to go home.\n",
      "  E - This place had the best doughnuts in town.\n",
      "\n",
      "Ground truth: option D\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da93346-1037-41ed-b67d-91877fa8c0ec",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3da78c12-9aff-4beb-a006-e287bbf61023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "caffe397-a65d-478f-b966-7b910fb2edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectionList = [\"selection0\", \"selection1\", \"selection2\", \"selection3\", \"selection4\"]\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Repeat each first sentence four times to go with the four possibilities of second sentences.\n",
    "    first_sentences = [[\"The following sentences contain emotions: {}\".format(context.strip(\"[\").strip(\"]\").replace('\\'', '')) ]*5 for context in examples[\"emotion\"]]\n",
    "    # Grab all second sentences possible for each context.\n",
    "    second_sentences = [[examples[selection][index] for selection in selectionList] for index in range(len(examples['selection0']))]\n",
    "\n",
    "    # Flatten everything\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "    \n",
    "    # Tokenize\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "    # Un-flatten\n",
    "    # print(tokenized_examples.items())\n",
    "    return {k: [v[i:i+5] for i in range(0, len(v), 5)] for k, v in tokenized_examples.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0afb4841-ab69-4b91-8859-fd249badb923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5 [23, 26, 21, 23, 33]\n"
     ]
    }
   ],
   "source": [
    "examples = dataset[\"train\"][:5]\n",
    "features = preprocess_function(examples)\n",
    "print(len(features[\"input_ids\"]), len(features[\"input_ids\"][0]), [len(x) for x in features[\"input_ids\"][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "903e2891-0e3d-4e87-b98a-727eaf36417a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>The following sentences contain emotions: okay, part, included</s></s>Ricky called his dad for help.</s>',\n",
       " '<s>The following sentences contain emotions: okay, part, included</s></s>Neil was impressed by the amount of work done there.</s>',\n",
       " '<s>The following sentences contain emotions: okay, part, included</s></s>She ran to the bathroom.</s>',\n",
       " '<s>The following sentences contain emotions: okay, part, included</s></s>He bought the ticket through a proxy.</s>',\n",
       " \"<s>The following sentences contain emotions: okay, part, included</s></s>Andrea didn't want to be an outcast, so she ate the ice cream.</s>\",\n",
       " '<s>The following sentences contain emotions: pro, anxious, rushed</s></s>I stopped at a blockbuster video store.</s>',\n",
       " '<s>The following sentences contain emotions: pro, anxious, rushed</s></s>She read that the inside of a banana peel helps stop the itch.</s>',\n",
       " \"<s>The following sentences contain emotions: pro, anxious, rushed</s></s>Ben's wristwatch had stopped working.</s>\",\n",
       " '<s>The following sentences contain emotions: pro, anxious, rushed</s></s>Cameron looked outside the open door of the plane.</s>',\n",
       " '<s>The following sentences contain emotions: pro, anxious, rushed</s></s>So I sped it up.</s>',\n",
       " '<s>The following sentences contain emotions: awful, upset, disappointed, embarrassed, irritated</s></s>She felt like she was an adult so she made cup of coffee.</s>',\n",
       " '<s>The following sentences contain emotions: awful, upset, disappointed, embarrassed, irritated</s></s>His mom made an appointment with the barber for next week.</s>',\n",
       " '<s>The following sentences contain emotions: awful, upset, disappointed, embarrassed, irritated</s></s>The toughest gal around wanted to fight.</s>',\n",
       " '<s>The following sentences contain emotions: awful, upset, disappointed, embarrassed, irritated</s></s>She was so uncomfortable, she had to go home.</s>',\n",
       " '<s>The following sentences contain emotions: awful, upset, disappointed, embarrassed, irritated</s></s>This place had the best doughnuts in town.</s>',\n",
       " '<s>The following sentences contain emotions: bored, impatient, annoyed</s></s>They objected to their union.</s>',\n",
       " \"<s>The following sentences contain emotions: bored, impatient, annoyed</s></s>One of my daughter's friends got married a few days ago.</s>\",\n",
       " \"<s>The following sentences contain emotions: bored, impatient, annoyed</s></s>The baby settled in Chad's lap at the bottom of the stairs.</s>\",\n",
       " '<s>The following sentences contain emotions: bored, impatient, annoyed</s></s>I began to get tired of using the same crayons.</s>',\n",
       " '<s>The following sentences contain emotions: bored, impatient, annoyed</s></s>Ellen had a huge crush on her classmate Evan.</s>',\n",
       " '<s>The following sentences contain emotions: dirty, upset</s></s>Amy went camping.</s>',\n",
       " '<s>The following sentences contain emotions: dirty, upset</s></s>So on her next test, she failed a question, got a B and was happy.</s>',\n",
       " '<s>The following sentences contain emotions: dirty, upset</s></s>Her hair was so greasy!</s>',\n",
       " '<s>The following sentences contain emotions: dirty, upset</s></s>Bill was on boating while on holiday.</s>',\n",
       " '<s>The following sentences contain emotions: dirty, upset</s></s>She was expecting to eat a nice dinner that night.</s>']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(features[\"input_ids\"][a][i]) for a in range(5) for i in range(5) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a286ba6-cb84-4619-b842-780124d26a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c20ab810d664729bbf3d60fafd9205f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1ca74e7b3943dbaceca5bc459fb2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f496be7-4673-4520-b30e-656cd5640b34",
   "metadata": {},
   "source": [
    "# Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7706d875-3a89-4e52-9f08-c77256b621ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForMultipleChoice: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForMultipleChoice.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2cd7be65-ebd8-43db-bcbf-a87d7e2342e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-emotionCommonsense\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    #learning_rate=5e-5, # for bert-base\n",
    "    learning_rate=5e-7, # for roberta-base\n",
    "    # learning_rate=1e-3,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    save_total_limit=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2737e04e-19c2-407d-8ce1-06b675f208c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [[{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        # Un-flatten\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        # Add back labels\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "03a0ec05-de5e-434f-b07c-63212e7c7f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_keys = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "features = [{k: v for k, v in encoded_datasets[\"train\"][i].items() if k in accepted_keys} for i in range(10)]\n",
    "batch = DataCollatorForMultipleChoice(tokenizer)(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45f7f26c-04bb-42ae-8627-897ced69888e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>The following sentences contain emotions: enjoyed, happy</s></s>Six months later, the skinny guy could bench press 200 lbs!</s><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<s>The following sentences contain emotions: enjoyed, happy</s></s>A few months later I was running well over five miles at once!</s><pad><pad><pad><pad><pad><pad>',\n",
       " '<s>The following sentences contain emotions: enjoyed, happy</s></s>She said to hurry up since the breakfast was getting cold.</s><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<s>The following sentences contain emotions: enjoyed, happy</s></s>I went to a party.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<s>The following sentences contain emotions: enjoyed, happy</s></s>I decided to leave and purchase a phone online.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(batch[\"input_ids\"][8][i].tolist()) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4b55256-30fa-4e30-a3a4-66fe1114b941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: ['enjoyed', 'happy']\n",
      "  A - Six months later, the skinny guy could bench press 200 lbs!\n",
      "  B - A few months later I was running well over five miles at once!\n",
      "  C - She said to hurry up since the breakfast was getting cold.\n",
      "  D - I went to a party.\n",
      "  E - I decided to leave and purchase a phone online.\n",
      "\n",
      "Ground truth: option D\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8305d3-8dc9-4d0f-8628-f51dc356c2d2",
   "metadata": {},
   "source": [
    "# Trainer Defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b707863a-bc16-43b0-b633-c7ffb4fa72e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "valStored = []\n",
    "def compute_metrics(eval_predictions):\n",
    "    predictions, label_ids = eval_predictions\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    valStored.append((preds != label_ids).astype(np.float32));\n",
    "    return {\"accuracy\": (preds == label_ids).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b115c1ba-323a-47d5-bb9d-55de985f13b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_datasets[\"train\"],\n",
    "    eval_dataset=encoded_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2fe74f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce RTX 3090\n",
      "Memory Usage:\n",
      "Allocated: 1.3 GB\n",
      "Cached:    6.9 GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a5e3430-bbd6-484d-8a8d-9cbcdba37d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29030' max='29030' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29030/29030 1:22:45, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.622300</td>\n",
       "      <td>1.605104</td>\n",
       "      <td>0.240453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.638700</td>\n",
       "      <td>1.613267</td>\n",
       "      <td>0.256447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.578500</td>\n",
       "      <td>1.350340</td>\n",
       "      <td>0.519364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.203700</td>\n",
       "      <td>1.040996</td>\n",
       "      <td>0.671309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.934300</td>\n",
       "      <td>0.842262</td>\n",
       "      <td>0.712014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.908500</td>\n",
       "      <td>0.798140</td>\n",
       "      <td>0.731512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.876100</td>\n",
       "      <td>0.720762</td>\n",
       "      <td>0.740947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.814300</td>\n",
       "      <td>0.724944</td>\n",
       "      <td>0.747417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.714073</td>\n",
       "      <td>0.751550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.746800</td>\n",
       "      <td>0.712315</td>\n",
       "      <td>0.752538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=29030, training_loss=1.1420526136581626, metrics={'train_runtime': 4965.498, 'train_samples_per_second': 5.846, 'total_flos': 44135807509800.0, 'epoch': 10.0})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a17948-a8f7-4450-b2b0-8a7016e91391",
   "metadata": {},
   "source": [
    "出现validation loss 上升情况大多是训练集验证集数据分布不一致，或者训练集过小，未包含验证集中所有情况，\n",
    "也就是过拟合导致的。而解决这种现象可以尝试以下几种策略：\n",
    "1. 增加训练样本增加正则项系数权重，\n",
    "2. 减小过拟合加入早停机制，ValLoss上升几个epoch直接停止\n",
    "3. 采用Focal Loss\n",
    "4. 加入Label Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d6ab3-33ac-4e8e-99ee-3c3f17d71642",
   "metadata": {},
   "source": [
    "# Store Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c30271fe-7ce9-43e8-9e87-de8d6ae2c2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x203d06ca2b0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "Z = np.transpose(valStored)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.pcolormesh(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5e77d30e-e51a-45a6-9130-83a17c4d2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataLog = pd.DataFrame(trainer.state.log_history)\n",
    "dataLog.to_csv(f'./trainingMetric/[Emotion] 5Select/TI-{model_checkpoint}-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c90cfec4-96ec-46c8-a99f-3c78b989b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluationIterationResult = pd.DataFrame(np.transpose(valStored))\n",
    "evaluationIterationResult.to_csv(f'./trainingMetric/[Emotion] 5Select/ESI-{model_checkpoint}-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd7f330-1477-4119-a9dc-1ebb7acb7665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:story_cloze]",
   "language": "python",
   "name": "conda-env-story_cloze-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
