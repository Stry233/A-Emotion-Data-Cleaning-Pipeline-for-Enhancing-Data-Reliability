{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1615a8a-9813-4956-b4ed-33ef2ea30723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'distilbert-base-uncased-finetuned-sst-2-english'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# global var set\n",
    "import transformers\n",
    "\n",
    "# model info, change as needed\n",
    "model_checkpoint = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "batch_size = 16\n",
    "num_epochs = 16\n",
    "\n",
    "# fileTag = \"clean-v1\"                      # clean + no phase + combine    (pure clean)\n",
    "# fileTag = \"clean-phase-v1\"                # clean +   phase  + combine\n",
    "# fileTag = 'clean-phase-noCombin-v1'       # clean +   phase  + no combine\n",
    "# fileTag = 'original-noCheat-noCombin-v1'  # raw   +   no Cheat case\n",
    "fileTag = 'original'                        # row   +   keep Cheat case     (pure raw) \n",
    "\n",
    "model_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b9d76f-5ed6-4ab9-8c62-f6d6a8b47be4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Convert dataset to suitable format\n",
    "IMPORTANT: please never run this section again if you have your dataset ready!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a93a9f46-6703-4535-af96-8be1b5b3407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "trainDatasetOriginal = pd.read_csv(f'../../data/csv_version/dev/emotion/allcharlinepairs-{fileTag}.csv')\n",
    "testDatasetOriginal = pd.read_csv(f'../../data/csv_version/test/emotion/allcharlinepairs-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7265a797-adc2-49ed-b237-19abf9e0569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatasetProcessed = DataFrame({'emotion' : trainDatasetOriginal['emotion'],\n",
    "                                   'plutchik' : trainDatasetOriginal['plutchik'],\n",
    "                                  'selection0': pd.concat([trainDatasetOriginal['sentence'][:trainDatasetOriginal.shape[0]//5], trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//5:]]), \n",
    "                                  'selection1': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//5], \n",
    "                                                pd.concat([trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//5:trainDatasetOriginal.shape[0]//5*2], \n",
    "                                                trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//5*2:]])]), \n",
    "                                  'selection2': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//5*2], \n",
    "                                                pd.concat([trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//5*2:trainDatasetOriginal.shape[0]//5*3], \n",
    "                                                trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//5*3:]])]), \n",
    "                                  'selection3': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//5*3], \n",
    "                                                pd.concat([trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//5*3:trainDatasetOriginal.shape[0]//5*4], \n",
    "                                                trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//5*4:]])]),\n",
    "                                  'selection4': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//5*4], \n",
    "                                                           trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//5*4:]]),\n",
    "                                  'label': pd.Series(0 if x < trainDatasetOriginal.shape[0]//5 else (1 if x < trainDatasetOriginal.shape[0]//5*2 \n",
    "                                                                                               else (2 if x < trainDatasetOriginal.shape[0]//5*3 \n",
    "                                                                                               else (3 if x < trainDatasetOriginal.shape[0]//5*4\n",
    "                                                                                               else  4))) for x in trainDatasetOriginal.index)}).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "testDatasetProcessed = DataFrame({'emotion' : testDatasetOriginal['emotion'],\n",
    "                                   'plutchik' : testDatasetOriginal['plutchik'],\n",
    "                                  'selection0': pd.concat([testDatasetOriginal['sentence'][:testDatasetOriginal.shape[0]//5], testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//5:]]), \n",
    "                                  'selection1': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//5], \n",
    "                                                pd.concat([testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//5:testDatasetOriginal.shape[0]//5*2], \n",
    "                                                testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//5*2:]])]), \n",
    "                                  'selection2': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//5*2], \n",
    "                                                pd.concat([testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//5*2:testDatasetOriginal.shape[0]//5*3], \n",
    "                                                testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//5*3:]])]), \n",
    "                                  'selection3': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//5*3], \n",
    "                                                pd.concat([testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//5*3:testDatasetOriginal.shape[0]//5*4], \n",
    "                                                testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//5*4:]])]),\n",
    "                                  'selection4': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//5*4], \n",
    "                                                           testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//5*4:]]),\n",
    "                                  'label': pd.Series(0 if x < testDatasetOriginal.shape[0]//5 else (1 if x < testDatasetOriginal.shape[0]//5*2 \n",
    "                                                                                               else (2 if x < testDatasetOriginal.shape[0]//5*3 \n",
    "                                                                                               else (3 if x < testDatasetOriginal.shape[0]//5*4\n",
    "                                                                                               else  4))) for x in testDatasetOriginal.index)}).sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19e3c334-b371-44ad-b6e1-7161f405b741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>plutchik</th>\n",
       "      <th>selection0</th>\n",
       "      <th>selection1</th>\n",
       "      <th>selection2</th>\n",
       "      <th>selection3</th>\n",
       "      <th>selection4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['okay', 'part', 'included']</td>\n",
       "      <td>{'joy': 1, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Ricky called his dad for help.</td>\n",
       "      <td>Neil was impressed by the amount of work done ...</td>\n",
       "      <td>She ran to the bathroom.</td>\n",
       "      <td>He bought the ticket through a proxy.</td>\n",
       "      <td>Andrea didn't want to be an outcast, so she at...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['pro', 'anxious', 'rushed']</td>\n",
       "      <td>{'joy': 1, 'trust': 1, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>I stopped at a blockbuster video store.</td>\n",
       "      <td>She read that the inside of a banana peel help...</td>\n",
       "      <td>Ben's wristwatch had stopped working.</td>\n",
       "      <td>Cameron looked outside the open door of the pl...</td>\n",
       "      <td>So I sped it up.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['awful', 'upset', 'disappointed', 'embarrasse...</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>She felt like she was an adult so she made cup...</td>\n",
       "      <td>His mom made an appointment with the barber fo...</td>\n",
       "      <td>The toughest gal around wanted to fight.</td>\n",
       "      <td>She was so uncomfortable, she had to go home.</td>\n",
       "      <td>This place had the best doughnuts in town.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['bored', 'impatient', 'annoyed']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>They objected to their union.</td>\n",
       "      <td>One of my daughter's friends got married a few...</td>\n",
       "      <td>The baby settled in Chad's lap at the bottom o...</td>\n",
       "      <td>I began to get tired of using the same crayons.</td>\n",
       "      <td>Ellen had a huge crush on her classmate Evan.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['dirty', 'upset']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Amy went camping.</td>\n",
       "      <td>So on her next test, she failed a question, go...</td>\n",
       "      <td>Her hair was so greasy!</td>\n",
       "      <td>Bill was on boating while on holiday.</td>\n",
       "      <td>She was expecting to eat a nice dinner that ni...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11605</th>\n",
       "      <td>['satisfied', 'satisfaction', 'pride', 'achiev...</td>\n",
       "      <td>{'joy': 2, 'trust': 2, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Phil put a tape recorder in his shirt pocket a...</td>\n",
       "      <td>Boris didn't really understand the meaning beh...</td>\n",
       "      <td>After installation, Dan realized his house was...</td>\n",
       "      <td>He would buy ten tacos and eat them all under ...</td>\n",
       "      <td>She went to four different shops.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11606</th>\n",
       "      <td>['understanding', 'uncomfortable', 'empty', 'n...</td>\n",
       "      <td>{'joy': 0, 'trust': 1, 'fear': 2, 'surprise': ...</td>\n",
       "      <td>Oscar drove home in his new car.</td>\n",
       "      <td>She said she felt naked without the cross.</td>\n",
       "      <td>His mind was flooded with old memories from hi...</td>\n",
       "      <td>Much of it was unsavory and hurt his business.</td>\n",
       "      <td>When I got into the water I realized that it w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11607</th>\n",
       "      <td>['annoyed', 'sad', 'betrayed', 'angry']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Kay was upset since the coupons would have sav...</td>\n",
       "      <td>Her child started to cry.</td>\n",
       "      <td>When she was moving towards one, another car c...</td>\n",
       "      <td>Michelle didn't make the cheerleading squad.</td>\n",
       "      <td>Their babysitter informed them that their kid ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11608</th>\n",
       "      <td>['hunger', 'defeat', 'hungry', 'innovative', '...</td>\n",
       "      <td>{'joy': 1, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>They put them between graham crackers.</td>\n",
       "      <td>I'm sure glad our apartment complex has a pool...</td>\n",
       "      <td>Peter eventually recovered from his illness.</td>\n",
       "      <td>Their parents blamed Jane and she was very ash...</td>\n",
       "      <td>The teacher handed the class their exams to take.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11609</th>\n",
       "      <td>['intrigued', 'happy', 'contemplative']</td>\n",
       "      <td>{'joy': 3, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>At practice, the other members told him he was...</td>\n",
       "      <td>Roger was okay though he only got a few bruises.</td>\n",
       "      <td>The cop gave the person a ticket.</td>\n",
       "      <td>Shawn falls in love with the dog at the store.</td>\n",
       "      <td>Marcus was collecting shells on the beach.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11610 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 emotion  \\\n",
       "0                           ['okay', 'part', 'included']   \n",
       "1                           ['pro', 'anxious', 'rushed']   \n",
       "2      ['awful', 'upset', 'disappointed', 'embarrasse...   \n",
       "3                      ['bored', 'impatient', 'annoyed']   \n",
       "4                                     ['dirty', 'upset']   \n",
       "...                                                  ...   \n",
       "11605  ['satisfied', 'satisfaction', 'pride', 'achiev...   \n",
       "11606  ['understanding', 'uncomfortable', 'empty', 'n...   \n",
       "11607            ['annoyed', 'sad', 'betrayed', 'angry']   \n",
       "11608  ['hunger', 'defeat', 'hungry', 'innovative', '...   \n",
       "11609            ['intrigued', 'happy', 'contemplative']   \n",
       "\n",
       "                                                plutchik  \\\n",
       "0      {'joy': 1, 'trust': 1, 'fear': 0, 'surprise': ...   \n",
       "1      {'joy': 1, 'trust': 1, 'fear': 1, 'surprise': ...   \n",
       "2      {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "3      {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "4      {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "...                                                  ...   \n",
       "11605  {'joy': 2, 'trust': 2, 'fear': 0, 'surprise': ...   \n",
       "11606  {'joy': 0, 'trust': 1, 'fear': 2, 'surprise': ...   \n",
       "11607  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "11608  {'joy': 1, 'trust': 1, 'fear': 0, 'surprise': ...   \n",
       "11609  {'joy': 3, 'trust': 1, 'fear': 0, 'surprise': ...   \n",
       "\n",
       "                                              selection0  \\\n",
       "0                         Ricky called his dad for help.   \n",
       "1                I stopped at a blockbuster video store.   \n",
       "2      She felt like she was an adult so she made cup...   \n",
       "3                          They objected to their union.   \n",
       "4                                      Amy went camping.   \n",
       "...                                                  ...   \n",
       "11605  Phil put a tape recorder in his shirt pocket a...   \n",
       "11606                   Oscar drove home in his new car.   \n",
       "11607  Kay was upset since the coupons would have sav...   \n",
       "11608             They put them between graham crackers.   \n",
       "11609  At practice, the other members told him he was...   \n",
       "\n",
       "                                              selection1  \\\n",
       "0      Neil was impressed by the amount of work done ...   \n",
       "1      She read that the inside of a banana peel help...   \n",
       "2      His mom made an appointment with the barber fo...   \n",
       "3      One of my daughter's friends got married a few...   \n",
       "4      So on her next test, she failed a question, go...   \n",
       "...                                                  ...   \n",
       "11605  Boris didn't really understand the meaning beh...   \n",
       "11606         She said she felt naked without the cross.   \n",
       "11607                          Her child started to cry.   \n",
       "11608  I'm sure glad our apartment complex has a pool...   \n",
       "11609   Roger was okay though he only got a few bruises.   \n",
       "\n",
       "                                              selection2  \\\n",
       "0                               She ran to the bathroom.   \n",
       "1                  Ben's wristwatch had stopped working.   \n",
       "2               The toughest gal around wanted to fight.   \n",
       "3      The baby settled in Chad's lap at the bottom o...   \n",
       "4                                Her hair was so greasy!   \n",
       "...                                                  ...   \n",
       "11605  After installation, Dan realized his house was...   \n",
       "11606  His mind was flooded with old memories from hi...   \n",
       "11607  When she was moving towards one, another car c...   \n",
       "11608       Peter eventually recovered from his illness.   \n",
       "11609                  The cop gave the person a ticket.   \n",
       "\n",
       "                                              selection3  \\\n",
       "0                  He bought the ticket through a proxy.   \n",
       "1      Cameron looked outside the open door of the pl...   \n",
       "2          She was so uncomfortable, she had to go home.   \n",
       "3        I began to get tired of using the same crayons.   \n",
       "4                  Bill was on boating while on holiday.   \n",
       "...                                                  ...   \n",
       "11605  He would buy ten tacos and eat them all under ...   \n",
       "11606     Much of it was unsavory and hurt his business.   \n",
       "11607       Michelle didn't make the cheerleading squad.   \n",
       "11608  Their parents blamed Jane and she was very ash...   \n",
       "11609     Shawn falls in love with the dog at the store.   \n",
       "\n",
       "                                              selection4  label  \n",
       "0      Andrea didn't want to be an outcast, so she at...      4  \n",
       "1                                       So I sped it up.      4  \n",
       "2             This place had the best doughnuts in town.      3  \n",
       "3          Ellen had a huge crush on her classmate Evan.      3  \n",
       "4      She was expecting to eat a nice dinner that ni...      2  \n",
       "...                                                  ...    ...  \n",
       "11605                  She went to four different shops.      2  \n",
       "11606  When I got into the water I realized that it w...      1  \n",
       "11607  Their babysitter informed them that their kid ...      1  \n",
       "11608  The teacher handed the class their exams to take.      0  \n",
       "11609         Marcus was collecting shells on the beach.      4  \n",
       "\n",
       "[11610 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDatasetProcessed.to_csv(f'./dataset/5Select-{fileTag}-train.csv')\n",
    "trainDatasetProcessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b770299d-567d-46e2-b928-8ee31a341c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>plutchik</th>\n",
       "      <th>selection0</th>\n",
       "      <th>selection1</th>\n",
       "      <th>selection2</th>\n",
       "      <th>selection3</th>\n",
       "      <th>selection4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['upset', 'frustrated', 'unsatisfied']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>The captain gasped and they hit the underside ...</td>\n",
       "      <td>Reading and the motion of the bus soon lulled ...</td>\n",
       "      <td>I fell and hurt my back.</td>\n",
       "      <td>Then she realized she was out of butter.</td>\n",
       "      <td>They put new staples in the stapler.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['happy', 'excited']</td>\n",
       "      <td>{'joy': 3, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>He decided on spectacular New Zealand.</td>\n",
       "      <td>Fiona was driving her car one wintry day.</td>\n",
       "      <td>James won the tickets.</td>\n",
       "      <td>Suddenly he was awakened when his tent caught ...</td>\n",
       "      <td>Then she visited the Garden of the Gods.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['foolish', 'annoyed', 'frustrated']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>Anthony was Charles' little cousin.</td>\n",
       "      <td>Tim wound up drinking too much.</td>\n",
       "      <td>I had cracked a head gasket.</td>\n",
       "      <td>Omar's dad six years ago just before Father's ...</td>\n",
       "      <td>After several weeks, he realized he hated grow...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['happy', 'hungry']</td>\n",
       "      <td>{'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>I had a golden retriever when I was younger.</td>\n",
       "      <td>She placed the meat first, in order to cook it...</td>\n",
       "      <td>The principal told his bully to stop.</td>\n",
       "      <td>He promised her the world.</td>\n",
       "      <td>A bigger goat knocked the food right out of he...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['proud', 'pride', 'competent']</td>\n",
       "      <td>{'joy': 3, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>At one time most major cities ran PCC trolleys.</td>\n",
       "      <td>She was very grateful and thanked me.</td>\n",
       "      <td>Her mother loved the gift and thanked Sally.</td>\n",
       "      <td>The music store was a big success.</td>\n",
       "      <td>I tried to hold my stance.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11124</th>\n",
       "      <td>['disappointed', 'annoyed', 'angry', 'aggravat...</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>When he walked over to his pool, he noticed th...</td>\n",
       "      <td>I used to go to church all the time.</td>\n",
       "      <td>They got into a fight and went to sleep angry.</td>\n",
       "      <td>As a result, Dennis had to learn not to be so ...</td>\n",
       "      <td>Ben finished hanging the picture and then trea...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11125</th>\n",
       "      <td>['happy', 'glad', 'thankful', 'motherly']</td>\n",
       "      <td>{'joy': 2, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>This spring they took a cruise from Boston to ...</td>\n",
       "      <td>She went through catalogs and made note of the...</td>\n",
       "      <td>She pulled out the kitchen stool and took a step.</td>\n",
       "      <td>I have a son that I go to the park to play bas...</td>\n",
       "      <td>He paid very little money for them.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11126</th>\n",
       "      <td>['sad', 'angry', 'disappointed', 'distraught']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>I had a huge crush on Robbie.</td>\n",
       "      <td>She was very pleased with the delicious pie.</td>\n",
       "      <td>John's wife told him the air freshener did not...</td>\n",
       "      <td>Night began to fall so he looked for shelter t...</td>\n",
       "      <td>The marriage didn't last and they divorced.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11127</th>\n",
       "      <td>['aggravated', 'incapable', 'annoyed']</td>\n",
       "      <td>{'joy': 0, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Now I love using text messages as a quick emai...</td>\n",
       "      <td>Coming to a large fenced in area, John let Cha...</td>\n",
       "      <td>The players rushed onto the field.</td>\n",
       "      <td>She called her best friend to see if she had r...</td>\n",
       "      <td>The plow did not move the snow to the side.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>['touched', 'happy', 'grateful', 'thankful', '...</td>\n",
       "      <td>{'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Ivy was so touched and pleased by human kindness!</td>\n",
       "      <td>John frowned, and forked over the money to his...</td>\n",
       "      <td>Jake called home to say he was working some ex...</td>\n",
       "      <td>Bob had a stuffed bear when he was young.</td>\n",
       "      <td>I picked up a handful of corn and threw it at ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11129 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 emotion  \\\n",
       "0                 ['upset', 'frustrated', 'unsatisfied']   \n",
       "1                                   ['happy', 'excited']   \n",
       "2                   ['foolish', 'annoyed', 'frustrated']   \n",
       "3                                    ['happy', 'hungry']   \n",
       "4                        ['proud', 'pride', 'competent']   \n",
       "...                                                  ...   \n",
       "11124  ['disappointed', 'annoyed', 'angry', 'aggravat...   \n",
       "11125          ['happy', 'glad', 'thankful', 'motherly']   \n",
       "11126     ['sad', 'angry', 'disappointed', 'distraught']   \n",
       "11127             ['aggravated', 'incapable', 'annoyed']   \n",
       "11128  ['touched', 'happy', 'grateful', 'thankful', '...   \n",
       "\n",
       "                                                plutchik  \\\n",
       "0      {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "1      {'joy': 3, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "2      {'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...   \n",
       "3      {'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "4      {'joy': 3, 'trust': 1, 'fear': 0, 'surprise': ...   \n",
       "...                                                  ...   \n",
       "11124  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "11125  {'joy': 2, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "11126  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "11127  {'joy': 0, 'trust': 1, 'fear': 0, 'surprise': ...   \n",
       "11128  {'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...   \n",
       "\n",
       "                                              selection0  \\\n",
       "0      The captain gasped and they hit the underside ...   \n",
       "1                 He decided on spectacular New Zealand.   \n",
       "2                    Anthony was Charles' little cousin.   \n",
       "3           I had a golden retriever when I was younger.   \n",
       "4        At one time most major cities ran PCC trolleys.   \n",
       "...                                                  ...   \n",
       "11124  When he walked over to his pool, he noticed th...   \n",
       "11125  This spring they took a cruise from Boston to ...   \n",
       "11126                      I had a huge crush on Robbie.   \n",
       "11127  Now I love using text messages as a quick emai...   \n",
       "11128  Ivy was so touched and pleased by human kindness!   \n",
       "\n",
       "                                              selection1  \\\n",
       "0      Reading and the motion of the bus soon lulled ...   \n",
       "1              Fiona was driving her car one wintry day.   \n",
       "2                        Tim wound up drinking too much.   \n",
       "3      She placed the meat first, in order to cook it...   \n",
       "4                  She was very grateful and thanked me.   \n",
       "...                                                  ...   \n",
       "11124               I used to go to church all the time.   \n",
       "11125  She went through catalogs and made note of the...   \n",
       "11126       She was very pleased with the delicious pie.   \n",
       "11127  Coming to a large fenced in area, John let Cha...   \n",
       "11128  John frowned, and forked over the money to his...   \n",
       "\n",
       "                                              selection2  \\\n",
       "0                               I fell and hurt my back.   \n",
       "1                                 James won the tickets.   \n",
       "2                           I had cracked a head gasket.   \n",
       "3                  The principal told his bully to stop.   \n",
       "4           Her mother loved the gift and thanked Sally.   \n",
       "...                                                  ...   \n",
       "11124     They got into a fight and went to sleep angry.   \n",
       "11125  She pulled out the kitchen stool and took a step.   \n",
       "11126  John's wife told him the air freshener did not...   \n",
       "11127                 The players rushed onto the field.   \n",
       "11128  Jake called home to say he was working some ex...   \n",
       "\n",
       "                                              selection3  \\\n",
       "0               Then she realized she was out of butter.   \n",
       "1      Suddenly he was awakened when his tent caught ...   \n",
       "2      Omar's dad six years ago just before Father's ...   \n",
       "3                             He promised her the world.   \n",
       "4                     The music store was a big success.   \n",
       "...                                                  ...   \n",
       "11124  As a result, Dennis had to learn not to be so ...   \n",
       "11125  I have a son that I go to the park to play bas...   \n",
       "11126  Night began to fall so he looked for shelter t...   \n",
       "11127  She called her best friend to see if she had r...   \n",
       "11128          Bob had a stuffed bear when he was young.   \n",
       "\n",
       "                                              selection4  label  \n",
       "0                   They put new staples in the stapler.      3  \n",
       "1               Then she visited the Garden of the Gods.      2  \n",
       "2      After several weeks, he realized he hated grow...      2  \n",
       "3      A bigger goat knocked the food right out of he...      1  \n",
       "4                             I tried to hold my stance.      3  \n",
       "...                                                  ...    ...  \n",
       "11124  Ben finished hanging the picture and then trea...      2  \n",
       "11125                He paid very little money for them.      3  \n",
       "11126        The marriage didn't last and they divorced.      4  \n",
       "11127        The plow did not move the snow to the side.      4  \n",
       "11128  I picked up a handful of corn and threw it at ...      0  \n",
       "\n",
       "[11129 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDatasetProcessed.to_csv(f'./dataset/5Select-{fileTag}-test.csv')\n",
    "testDatasetProcessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7283c1-d83e-4369-b5e4-6c2e09d654ac",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "828a5092-83e6-4580-99c9-bd9ec434708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05151e3b-0bec-44f4-bf0a-ac58cddbf838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-a101b5fe4aa69cb2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:\\Users\\JAM_0\\.cache\\huggingface\\datasets\\csv\\default-a101b5fe4aa69cb2\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eede580aaffc422487f5debcee544970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac1df53dc4941219a30e206b94919bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:\\Users\\JAM_0\\.cache\\huggingface\\datasets\\csv\\default-a101b5fe4aa69cb2\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e84608fa28794a7ead92371a8684d540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('csv', data_files={'train': f'./dataset/5Select-{fileTag}-train.csv', \n",
    "                                           'test': f'./dataset/5Select-{fileTag}-test.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d776c270-7752-4445-ba6c-eb078f71eccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'emotion', 'plutchik', 'selection0', 'selection1', 'selection2', 'selection3', 'selection4', 'label'],\n",
       "        num_rows: 53234\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'emotion', 'plutchik', 'selection0', 'selection1', 'selection2', 'selection3', 'selection4', 'label'],\n",
       "        num_rows: 51891\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1c79159-f795-4d02-b052-94f04286d53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 0,\n",
       " 'emotion': '[\"strange\"]',\n",
       " 'plutchik': '[\"surprise:3\"]',\n",
       " 'selection0': 'Lauren decided to go to the museum.',\n",
       " 'selection1': 'He is learning French.',\n",
       " 'selection2': 'Steven brought the couch home and set it up.',\n",
       " 'selection3': 'His wife was terribly embarrassed.',\n",
       " 'selection4': 'She really wanted to speak!',\n",
       " 'label': 4}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f6ad67d-b4cb-4f65-a9cb-d2d665deec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_one(example):\n",
    "    print(f\"Context: {example['emotion']}\")\n",
    "    print(f\"  A - {example['selection0']}\")\n",
    "    print(f\"  B - {example['selection1']}\")\n",
    "    print(f\"  C - {example['selection2']}\")\n",
    "    print(f\"  D - {example['selection3']}\")\n",
    "    print(f\"  E - {example['selection4']}\")\n",
    "    print(f\"\\nGround truth: option {['A', 'B', 'C', 'D', 'E'][example['label']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15cd7cfb-748a-4fe7-8152-7debf6a65ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [\"proud\"]\n",
      "  A - They were very sweet when we went to meet them.\n",
      "  B - They ended up putting on a wonderful show for their friends.\n",
      "  C - A red sock had been hidden in the load and dyed the clothes.\n",
      "  D - Her mother loved the picture and Jennifer decided it was the best gift.\n",
      "  E - Kylie invited her to get coffee and the two reconnected.\n",
      "\n",
      "Ground truth: option D\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da93346-1037-41ed-b67d-91877fa8c0ec",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3da78c12-9aff-4beb-a006-e287bbf61023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "from transformers import DistilBertTokenizer, DistilBertForMultipleChoice\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caffe397-a65d-478f-b966-7b910fb2edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectionList = [\"selection0\", \"selection1\", \"selection2\", \"selection3\", \"selection4\"]\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Repeat each first sentence four times to go with the four possibilities of second sentences.\n",
    "    first_sentences = [[\"The following sentences contain emotions: {}\".format(context.strip(\"[\").strip(\"]\").replace('\\'', '')) ]*5 for context in examples[\"emotion\"]]\n",
    "    # Grab all second sentences possible for each context.\n",
    "    second_sentences = [[examples[selection][index] for selection in selectionList] for index in range(len(examples['selection0']))]\n",
    "\n",
    "    # Flatten everything\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "    \n",
    "    # Tokenize\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "    # Un-flatten\n",
    "    # print(tokenized_examples.items())\n",
    "    return {k: [v[i:i+5] for i in range(0, len(v), 5)] for k, v in tokenized_examples.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0afb4841-ab69-4b91-8859-fd249badb923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5 [21, 18, 26, 19, 21]\n"
     ]
    }
   ],
   "source": [
    "examples = dataset[\"train\"][:5]\n",
    "features = preprocess_function(examples)\n",
    "print(len(features[\"input_ids\"]), len(features[\"input_ids\"][0]), [len(x) for x in features[\"input_ids\"][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "903e2891-0e3d-4e87-b98a-727eaf36417a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] The following sentences contain emotions : \" funny \" [SEP] Sally liked toys alot for xmas. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : \" funny \" [SEP] But then she woke up. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : \" funny \" [SEP] Professor Smith asked for forgiveness, he\\'d recently had a stroke. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : \" funny \" [SEP] I was in so much pain. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : \" funny \" [SEP] Six of his friends had the same idea. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : \" upset \" [SEP] Mary was walking in the park when she heard a noise. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : \" upset \" [SEP] To her surprise, she found it delicious! [SEP]',\n",
       " '[CLS] The following sentences contain emotions : \" upset \" [SEP] I really thought it turned out terrible. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : \" upset \" [SEP] My daughter jumped up and grabbed the blue one out of her hand. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : \" upset \" [SEP] He had a passion to change his country for better. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : \" proud \" [SEP] They were very sweet when we went to meet them. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : \" proud \" [SEP] They ended up putting on a wonderful show for their friends. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : \" proud \" [SEP] A red sock had been hidden in the load and dyed the clothes. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : \" proud \" [SEP] Her mother loved the picture and Jennifer decided it was the best gift. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : \" proud \" [SEP] Kylie invited her to get coffee and the two reconnected. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : \" happy \" [SEP] However, her voice cracked when she was trying to sing at a high tone [SEP]',\n",
       " '[CLS] The following sentences contain emotions : \" happy \" [SEP] She told me it was everyone and everything. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : \" happy \" [SEP] Gina wanted to sit in her dad\\'s car to be alone. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : \" happy \" [SEP] When the other kids wouldn\\'t move over I\\'d start to sit anyway. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : \" happy \" [SEP] Eventually he starts to have favorite television shows. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : \" anxious \", \" ready \", \" encouraged \" [SEP] The chef worked his helpers very hard. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : \" anxious \", \" ready \", \" encouraged \" [SEP] She demonstrated the Mac computer and it worked fine. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : \" anxious \", \" ready \", \" encouraged \" [SEP] Davis decided that he needed to become more active. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : \" anxious \", \" ready \", \" encouraged \" [SEP] He thought it was a shark. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : \" anxious \", \" ready \", \" encouraged \" [SEP] I got a little lost when it was my turn to hide. [SEP]']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(features[\"input_ids\"][a][i]) for a in range(5) for i in range(5) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a286ba6-cb84-4619-b842-780124d26a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c608e3ed8a4bc3a95228856653f221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1769b7aa4bdf40e486fee128b44e9163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f496be7-4673-4520-b30e-656cd5640b34",
   "metadata": {},
   "source": [
    "# Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7706d875-3a89-4e52-9f08-c77256b621ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForMultipleChoice: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForMultipleChoice were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "from transformers import DistilBertTokenizer, DistilBertForMultipleChoice\n",
    "import torch\n",
    "model = DistilBertForMultipleChoice.from_pretrained(\"distilbert-base-cased\")\n",
    "\n",
    "# model = AutoModelForMultipleChoice.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cd7be65-ebd8-43db-bcbf-a87d7e2342e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-emotionCommonsense\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    #learning_rate=5e-5, # for bert-base\n",
    "    learning_rate=5e-7, # for roberta-base\n",
    "    # learning_rate=1e-3,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2737e04e-19c2-407d-8ce1-06b675f208c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [[{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        # Un-flatten\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        # Add back labels\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03a0ec05-de5e-434f-b07c-63212e7c7f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_keys = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "features = [{k: v for k, v in encoded_datasets[\"train\"][i].items() if k in accepted_keys} for i in range(10)]\n",
    "batch = DataCollatorForMultipleChoice(tokenizer)(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45f7f26c-04bb-42ae-8627-897ced69888e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] The following sentences contain emotions : \" competent \" [SEP] He took the cash and let us go. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] The following sentences contain emotions : \" competent \" [SEP] He saw a masked man come in and brandish a gun. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] The following sentences contain emotions : \" competent \" [SEP] They\\'d been kicked out of everywhere else. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] The following sentences contain emotions : \" competent \" [SEP] It was 10 PM on a summer night. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] The following sentences contain emotions : \" competent \" [SEP] Eric was a very hard working man. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(batch[\"input_ids\"][8][i].tolist()) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4b55256-30fa-4e30-a3a4-66fe1114b941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [\"competent\"]\n",
      "  A - He took the cash and let us go.\n",
      "  B - He saw a masked man come in and brandish a gun.\n",
      "  C - They'd been kicked out of everywhere else.\n",
      "  D - It was 10 PM on a summer night.\n",
      "  E - Eric was a very hard working man.\n",
      "\n",
      "Ground truth: option E\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8305d3-8dc9-4d0f-8628-f51dc356c2d2",
   "metadata": {},
   "source": [
    "# Trainer Defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b707863a-bc16-43b0-b633-c7ffb4fa72e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "valStored = []\n",
    "def compute_metrics(eval_predictions):\n",
    "    predictions, label_ids = eval_predictions\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    valStored.append((preds != label_ids).astype(np.float32));\n",
    "    return {\"accuracy\": (preds == label_ids).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b115c1ba-323a-47d5-bb9d-55de985f13b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_datasets[\"train\"],\n",
    "    eval_dataset=encoded_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df5a83ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 22 01:39:40 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 511.65       Driver Version: 511.65       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   46C    P2    76W / 370W |   4555MiB / 10240MiB |      2%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1536    C+G                                   N/A      |\n",
      "|    0   N/A  N/A      1956    C+G   ...d\\runtime\\WeChatAppEx.exe    N/A      |\n",
      "|    0   N/A  N/A      4068    C+G   ...8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A      5452    C+G   ...er_engine\\wallpaper64.exe    N/A      |\n",
      "|    0   N/A  N/A      7324    C+G   ...d\\runtime\\WeChatAppEx.exe    N/A      |\n",
      "|    0   N/A  N/A      7580    C+G                                   N/A      |\n",
      "|    0   N/A  N/A      9956    C+G   ...dk-17.0.3.1\\bin\\javaw.exe    N/A      |\n",
      "|    0   N/A  N/A     10776    C+G                                   N/A      |\n",
      "|    0   N/A  N/A     12552    C+G   ...8bbwe\\Microsoft.Notes.exe    N/A      |\n",
      "|    0   N/A  N/A     13344    C+G   ...\\dependencies\\washost.exe    N/A      |\n",
      "|    0   N/A  N/A     13524    C+G   ...tation\\x64\\mksSandbox.exe    N/A      |\n",
      "|    0   N/A  N/A     13716    C+G   ...e\\root\\Office16\\EXCEL.EXE    N/A      |\n",
      "|    0   N/A  N/A     14228    C+G   ...8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A     14688    C+G   ...dk-17.0.3.1\\bin\\javaw.exe    N/A      |\n",
      "|    0   N/A  N/A     15608    C+G   ...urrent\\LogiOptionsMgr.exe    N/A      |\n",
      "|    0   N/A  N/A     15632    C+G   ...e\\Current\\LogiOverlay.exe    N/A      |\n",
      "|    0   N/A  N/A     16460    C+G   ...ncher\\CiscoCollabHost.exe    N/A      |\n",
      "|    0   N/A  N/A     18892      C   ...EnvWithDataSci\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     18996    C+G   ...tracted\\WechatBrowser.exe    N/A      |\n",
      "|    0   N/A  N/A     19028    C+G   ...\\app-1.0.9005\\Discord.exe    N/A      |\n",
      "|    0   N/A  N/A     19576    C+G   ...lack\\app-4.26.2\\slack.exe    N/A      |\n",
      "|    0   N/A  N/A     21024    C+G   ...8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A     21044    C+G   ...8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A     22920    C+G   ...210.53\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     29120    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     29292    C+G   ...erver\\YourPhoneServer.exe    N/A      |\n",
      "|    0   N/A  N/A     31720    C+G   ...dk-17.0.3.1\\bin\\javaw.exe    N/A      |\n",
      "|    0   N/A  N/A     32096    C+G   ...tracted\\WechatBrowser.exe    N/A      |\n",
      "|    0   N/A  N/A     40036    C+G   ...ekyb3d8bbwe\\onenoteim.exe    N/A      |\n",
      "|    0   N/A  N/A     40344    C+G   ...8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A     42516    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     43416    C+G   ...root\\Office16\\WINWORD.EXE    N/A      |\n",
      "|    0   N/A  N/A     45152      C   ...EnvWithDataSci\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     46828    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     47624    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     50040      C   ...EnvWithDataSci\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     50636    C+G   ...8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A     51104    C+G   ...245.44\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     54668    C+G   ...8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A     55284    C+G   ...oot\\Office16\\POWERPNT.EXE    N/A      |\n",
      "|    0   N/A  N/A     56096    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     56920      C   ...EnvWithDataSci\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     60320    C+G                                   N/A      |\n",
      "|    0   N/A  N/A     66468    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     69548    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fe74f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce RTX 3080\n",
      "Memory Usage:\n",
      "Allocated: 0.2 GB\n",
      "Cached:    0.3 GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5e3430-bbd6-484d-8a8d-9cbcdba37d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection3, selection2, plutchik, selection0, selection1, emotion, Unnamed: 0, selection4. If selection3, selection2, plutchik, selection0, selection1, emotion, Unnamed: 0, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "C:\\Python\\miniconda3\\envs\\pytorchEnvWithDataSci\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 53234\n",
      "  Num Epochs = 16\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53248\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37501' max='53248' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37501/53248 1:13:20 < 30:47, 8.52 it/s, Epoch 11.27/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.608900</td>\n",
       "      <td>1.603167</td>\n",
       "      <td>0.286466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.505400</td>\n",
       "      <td>1.470213</td>\n",
       "      <td>0.344222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.462700</td>\n",
       "      <td>1.412309</td>\n",
       "      <td>0.386907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.419800</td>\n",
       "      <td>1.374631</td>\n",
       "      <td>0.413154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.391900</td>\n",
       "      <td>1.354231</td>\n",
       "      <td>0.423792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.375500</td>\n",
       "      <td>1.338527</td>\n",
       "      <td>0.431693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.354500</td>\n",
       "      <td>1.327360</td>\n",
       "      <td>0.436723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.351500</td>\n",
       "      <td>1.318660</td>\n",
       "      <td>0.441676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.327600</td>\n",
       "      <td>1.312824</td>\n",
       "      <td>0.444509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.314400</td>\n",
       "      <td>1.308387</td>\n",
       "      <td>0.447669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.329700</td>\n",
       "      <td>1.304217</td>\n",
       "      <td>0.450097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection3, selection2, plutchik, selection0, selection1, emotion, Unnamed: 0, selection4. If selection3, selection2, plutchik, selection0, selection1, emotion, Unnamed: 0, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection3, selection2, plutchik, selection0, selection1, emotion, Unnamed: 0, selection4. If selection3, selection2, plutchik, selection0, selection1, emotion, Unnamed: 0, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection3, selection2, plutchik, selection0, selection1, emotion, Unnamed: 0, selection4. If selection3, selection2, plutchik, selection0, selection1, emotion, Unnamed: 0, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-12000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-12000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-12000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-12000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-12000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-12500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-12500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-12500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-12500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-12500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-13000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-13000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-13000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-13000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-13000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection3, selection2, plutchik, selection0, selection1, emotion, Unnamed: 0, selection4. If selection3, selection2, plutchik, selection0, selection1, emotion, Unnamed: 0, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-13500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-13500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-13500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-13500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-13500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-14000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-14000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-14000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-14000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-14000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-14500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-14500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-14500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-14500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-14500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-15000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-15000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-15000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-15000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-15000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-15500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-15500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-15500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-15500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-15500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-16000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-16000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-16000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-16000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-16000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-16500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-16500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-16500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-16500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-16500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection3, selection2, plutchik, selection0, selection1, emotion, Unnamed: 0, selection4. If selection3, selection2, plutchik, selection0, selection1, emotion, Unnamed: 0, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-17000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-17000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-17000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-17000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-17000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-17500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-17500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-17500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-17500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-17500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-18000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-18000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-18000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-18000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-18000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-18500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-18500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-18500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-18500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-18500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-19000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-19000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-19000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-19000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-19000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-19500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-19500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-19500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-19500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-19500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection3, selection2, plutchik, selection0, selection1, emotion, Unnamed: 0, selection4. If selection3, selection2, plutchik, selection0, selection1, emotion, Unnamed: 0, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-20000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-20000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-20000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-20000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-20000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-20500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-20500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-20500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-20500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-20500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-21000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-21000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-21000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-21000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-21000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-21500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-21500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-21500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-21500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-21500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-22000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-22000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-22000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-22000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-22000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-22500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-22500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-22500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-22500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-22500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-23000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-23000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-23000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-23000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-23000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection3, selection2, plutchik, selection0, selection1, emotion, Unnamed: 0, selection4. If selection3, selection2, plutchik, selection0, selection1, emotion, Unnamed: 0, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-23500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-23500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-23500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-23500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-23500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-24000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-24000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-24000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-24000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-24000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-24500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-24500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-24500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-24500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-24500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-25000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-25000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-25000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-25000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-25000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-25500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-25500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-25500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-25500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-25500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-26000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-26000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-26000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-26000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-26000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-26500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-26500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-26500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-26500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-26500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection3, selection2, plutchik, selection0, selection1, emotion, Unnamed: 0, selection4. If selection3, selection2, plutchik, selection0, selection1, emotion, Unnamed: 0, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-27000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-27000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-27000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-27000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-27000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-27500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-27500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-27500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-27500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-27500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-28000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-28000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-28000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-28000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-28000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-28500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-28500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-28500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-28500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-28500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-29000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-29000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-29000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-29000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-29000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-29500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-29500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-29500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-29500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-29500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection3, selection2, plutchik, selection0, selection1, emotion, Unnamed: 0, selection4. If selection3, selection2, plutchik, selection0, selection1, emotion, Unnamed: 0, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-30000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-30000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-30000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-30000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-30000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-30500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-30500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-30500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-30500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-30500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-31000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-31000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-31000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-31000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-31000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-31500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-31500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-31500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-31500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-31500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-32000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-32000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-32000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-32000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-32000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-32500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-32500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-32500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-32500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-32500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-33000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-33000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-33000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-33000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-33000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection3, selection2, plutchik, selection0, selection1, emotion, Unnamed: 0, selection4. If selection3, selection2, plutchik, selection0, selection1, emotion, Unnamed: 0, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-33500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-33500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-33500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-33500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-33500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-34000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-34000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-34000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-34000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-34000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-34500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-34500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-34500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-34500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-34500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-35000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-35000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-35000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-35000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-35000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-35500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-35500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-35500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-35500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-35500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-36000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-36000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-36000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-36000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-36000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-36500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-36500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-36500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-36500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-36500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection3, selection2, plutchik, selection0, selection1, emotion, Unnamed: 0, selection4. If selection3, selection2, plutchik, selection0, selection1, emotion, Unnamed: 0, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 51891\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-37000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-37000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-37000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-37000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-37000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-37500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-37500\\config.json\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a17948-a8f7-4450-b2b0-8a7016e91391",
   "metadata": {},
   "source": [
    "出现validation loss 上升情况大多是训练集验证集数据分布不一致，或者训练集过小，未包含验证集中所有情况，\n",
    "也就是过拟合导致的。而解决这种现象可以尝试以下几种策略：\n",
    "1. 增加训练样本增加正则项系数权重，\n",
    "2. 减小过拟合加入早停机制，ValLoss上升几个epoch直接停止\n",
    "3. 采用Focal Loss\n",
    "4. 加入Label Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d6ab3-33ac-4e8e-99ee-3c3f17d71642",
   "metadata": {},
   "source": [
    "# Store Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c30271fe-7ce9-43e8-9e87-de8d6ae2c2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x146c6775f40>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "Z = np.transpose(valStored)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.pcolormesh(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e77d30e-e51a-45a6-9130-83a17c4d2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "if model_checkpoint == 'distilbert-base-uncased-finetuned-sst-2-english':\n",
    "    model_checkpoint = 'distilbert-base'\n",
    "dataLog = pd.DataFrame(trainer.state.log_history)\n",
    "dataLog.to_csv(f'./trainingMetric/[Emotion] 5Select/TI-{model_checkpoint}-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c90cfec4-96ec-46c8-a99f-3c78b989b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluationIterationResult = pd.DataFrame(np.transpose(valStored))\n",
    "evaluationIterationResult.to_csv(f'./trainingMetric/[Emotion] 5Select/ESI-{model_checkpoint}-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd7f330-1477-4119-a9dc-1ebb7acb7665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchEnvWithDataSci",
   "language": "python",
   "name": "pytorchenvwithdatasci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
