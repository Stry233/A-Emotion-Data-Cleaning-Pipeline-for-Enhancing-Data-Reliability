{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8533643b-5b68-4dec-8a8a-49852c237e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global var set\n",
    "import transformers\n",
    "\n",
    "# model info, change as needed\n",
    "batch_size = 16\n",
    "num_epochs = 16\n",
    "\n",
    "model_checkpoint = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "# model_checkpoint = 'bert-base-uncased'\n",
    "# fileTag = \"original-plutchik-noCombin-v1\"   # original - no Combine    - pure raw\n",
    "# fileTag = \"original-plutchik-v1\"             # original - w/ Combine\n",
    "# fileTag = \"clean-noCombin-v1\"                # clean    - no Combine\n",
    "fileTag = \"clean-v1\"                         # clean    - w/ Combine    - pure clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa38989-ff76-4de1-a82e-6853a1e61687",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Convert dataset to suitable format\n",
    "IMPORTANT: please never run this section again if you have your dataset ready!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a93a9f46-6703-4535-af96-8be1b5b3407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "trainDatasetOriginal = pd.read_csv(f'../../data/csv_version/dev/emotion/allcharlinepairs-{fileTag}.csv')\n",
    "testDatasetOriginal = pd.read_csv(f'../../data/csv_version/test/emotion/allcharlinepairs-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7265a797-adc2-49ed-b237-19abf9e0569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatasetProcessed = DataFrame({'emotion' : trainDatasetOriginal['emotion'],\n",
    "                                   'plutchik' : trainDatasetOriginal['plutchik'],\n",
    "                                  'selection0': pd.concat([trainDatasetOriginal['sentence'][:trainDatasetOriginal.shape[0]//5], trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//5:]]), \n",
    "                                  'selection1': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//5], \n",
    "                                                pd.concat([trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//5:trainDatasetOriginal.shape[0]//5*2], \n",
    "                                                trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//5*2:]])]), \n",
    "                                  'selection2': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//5*2], \n",
    "                                                pd.concat([trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//5*2:trainDatasetOriginal.shape[0]//5*3], \n",
    "                                                trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//5*3:]])]), \n",
    "                                  'selection3': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//5*3], \n",
    "                                                pd.concat([trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//5*3:trainDatasetOriginal.shape[0]//5*4], \n",
    "                                                trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][trainDatasetOriginal.shape[0]//5*4:]])]),\n",
    "                                  'selection4': pd.concat([trainDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:trainDatasetOriginal.shape[0]//5*4], \n",
    "                                                           trainDatasetOriginal['sentence'][trainDatasetOriginal.shape[0]//5*4:]]),\n",
    "                                  'label': pd.Series(0 if x < trainDatasetOriginal.shape[0]//5 else (1 if x < trainDatasetOriginal.shape[0]//5*2 \n",
    "                                                                                               else (2 if x < trainDatasetOriginal.shape[0]//5*3 \n",
    "                                                                                               else (3 if x < trainDatasetOriginal.shape[0]//5*4\n",
    "                                                                                               else  4))) for x in trainDatasetOriginal.index)}).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "testDatasetProcessed = DataFrame({'emotion' : testDatasetOriginal['emotion'],\n",
    "                                   'plutchik' : testDatasetOriginal['plutchik'],\n",
    "                                  'selection0': pd.concat([testDatasetOriginal['sentence'][:testDatasetOriginal.shape[0]//5], testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//5:]]), \n",
    "                                  'selection1': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//5], \n",
    "                                                pd.concat([testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//5:testDatasetOriginal.shape[0]//5*2], \n",
    "                                                testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//5*2:]])]), \n",
    "                                  'selection2': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//5*2], \n",
    "                                                pd.concat([testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//5*2:testDatasetOriginal.shape[0]//5*3], \n",
    "                                                testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//5*3:]])]), \n",
    "                                  'selection3': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//5*3], \n",
    "                                                pd.concat([testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//5*3:testDatasetOriginal.shape[0]//5*4], \n",
    "                                                testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][testDatasetOriginal.shape[0]//5*4:]])]),\n",
    "                                  'selection4': pd.concat([testDatasetOriginal.sample(frac = 1).reset_index()['sentence'][:testDatasetOriginal.shape[0]//5*4], \n",
    "                                                           testDatasetOriginal['sentence'][testDatasetOriginal.shape[0]//5*4:]]),\n",
    "                                  'label': pd.Series(0 if x < testDatasetOriginal.shape[0]//5 else (1 if x < testDatasetOriginal.shape[0]//5*2 \n",
    "                                                                                               else (2 if x < testDatasetOriginal.shape[0]//5*3 \n",
    "                                                                                               else (3 if x < testDatasetOriginal.shape[0]//5*4\n",
    "                                                                                               else  4))) for x in testDatasetOriginal.index)}).sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19e3c334-b371-44ad-b6e1-7161f405b741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>plutchik</th>\n",
       "      <th>selection0</th>\n",
       "      <th>selection1</th>\n",
       "      <th>selection2</th>\n",
       "      <th>selection3</th>\n",
       "      <th>selection4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['proud', 'excited', 'none']</td>\n",
       "      <td>{'joy': 2, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Ivan took a few landscapes and some of himself.</td>\n",
       "      <td>She watched as the doll was passed around the ...</td>\n",
       "      <td>One morning, Jim was admiring his crush, Micha...</td>\n",
       "      <td>But Carlos was glad to get it done.</td>\n",
       "      <td>He brought them home in a canvas bag.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['upset', 'frightened', 'annoyed', 'none']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>Jasper notices his hands are very cold when he...</td>\n",
       "      <td>Sophia was a neat freak.</td>\n",
       "      <td>She stood up quickly and knocked the bottle ov...</td>\n",
       "      <td>Chad was eight Year's old and growing fast.</td>\n",
       "      <td>I am already looking forward to next year's fair.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['satisfied', 'powerful', 'annoyed', 'surprise...</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>The chef knew tonight would be a busy night.</td>\n",
       "      <td>Jordan's mom is happy to see her little girl g...</td>\n",
       "      <td>When the other kids wouldn't move over I'd sta...</td>\n",
       "      <td>Tim pulled over to check on it.</td>\n",
       "      <td>They went outside the city areas.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['none']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>They stopped and looked at Gina.</td>\n",
       "      <td>Doug has always wanted to be married.</td>\n",
       "      <td>Her dad was hesitant, but he allowed her to si...</td>\n",
       "      <td>Her mom bought her a Chinese outfit, but Ellie...</td>\n",
       "      <td>One day I decided I wanted to become a profess...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['none', 'excited', 'JOLLY', 'happy']</td>\n",
       "      <td>{'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Travis was at a theme park.</td>\n",
       "      <td>I let them go play without my supervision.</td>\n",
       "      <td>However, it broke apart when he lifted it up.</td>\n",
       "      <td>Tom was excited for Tuesday, it was his new fa...</td>\n",
       "      <td>She thought she included all the ingredients.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12410</th>\n",
       "      <td>['surprise', 'FEELING UPSET', 'embarrassed']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...</td>\n",
       "      <td>One day, Dan let his dog out in the back yard.</td>\n",
       "      <td>So he felt regretful about having the smoothie...</td>\n",
       "      <td>We also had a lot of food to eat.</td>\n",
       "      <td>Everything was taken except for one spot.</td>\n",
       "      <td>Suddenly, he bumped one of the back tires.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12411</th>\n",
       "      <td>['nervous', 'judged', 'none']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>They ran and ran until they finally collapsed.</td>\n",
       "      <td>They team up and become a band.</td>\n",
       "      <td>John was digging in his backyard when he found...</td>\n",
       "      <td>Charles contacted the seller.</td>\n",
       "      <td>The device could determine if he was a good or...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12412</th>\n",
       "      <td>['none', 'Alarmed', 'Panic Stricken', 'sorrowf...</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...</td>\n",
       "      <td>Tom was able to get something close enough.</td>\n",
       "      <td>Kevin took the car out for a drive for the fir...</td>\n",
       "      <td>Tom noticed his watch was missing.</td>\n",
       "      <td>He was rushed to the hospital by the employees...</td>\n",
       "      <td>To his delight this meant he didn't have to ta...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12413</th>\n",
       "      <td>['Bored', 'Lonely', 'excited', 'hopeful', 'none']</td>\n",
       "      <td>{'joy': 1, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Jimmy wanted to go to the playground.</td>\n",
       "      <td>Her teacher saw Holly napping.</td>\n",
       "      <td>Candy was the owner's daughter, and Bill was a...</td>\n",
       "      <td>Eventually Chuck became incredibly fast.</td>\n",
       "      <td>Ed and Emma were twins and wanted to have matc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12414</th>\n",
       "      <td>['disgusted', 'frustrated', 'disappointed', 'n...</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>His friends thought it'd be funny, and left hi...</td>\n",
       "      <td>Fran just landed in Thailand for her grand one...</td>\n",
       "      <td>Oscar decided that he must get a job to be abl...</td>\n",
       "      <td>Her internships and grades earned her a spot i...</td>\n",
       "      <td>When she took the clothes out, everything that...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12415 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 emotion  \\\n",
       "0                           ['proud', 'excited', 'none']   \n",
       "1             ['upset', 'frightened', 'annoyed', 'none']   \n",
       "2      ['satisfied', 'powerful', 'annoyed', 'surprise...   \n",
       "3                                               ['none']   \n",
       "4                  ['none', 'excited', 'JOLLY', 'happy']   \n",
       "...                                                  ...   \n",
       "12410       ['surprise', 'FEELING UPSET', 'embarrassed']   \n",
       "12411                      ['nervous', 'judged', 'none']   \n",
       "12412  ['none', 'Alarmed', 'Panic Stricken', 'sorrowf...   \n",
       "12413  ['Bored', 'Lonely', 'excited', 'hopeful', 'none']   \n",
       "12414  ['disgusted', 'frustrated', 'disappointed', 'n...   \n",
       "\n",
       "                                                plutchik  \\\n",
       "0      {'joy': 2, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "1      {'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...   \n",
       "2      {'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...   \n",
       "3      {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "4      {'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...   \n",
       "...                                                  ...   \n",
       "12410  {'joy': 0, 'trust': 0, 'fear': 2, 'surprise': ...   \n",
       "12411  {'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...   \n",
       "12412  {'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...   \n",
       "12413  {'joy': 1, 'trust': 1, 'fear': 0, 'surprise': ...   \n",
       "12414  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "\n",
       "                                              selection0  \\\n",
       "0        Ivan took a few landscapes and some of himself.   \n",
       "1      Jasper notices his hands are very cold when he...   \n",
       "2           The chef knew tonight would be a busy night.   \n",
       "3                       They stopped and looked at Gina.   \n",
       "4                            Travis was at a theme park.   \n",
       "...                                                  ...   \n",
       "12410     One day, Dan let his dog out in the back yard.   \n",
       "12411     They ran and ran until they finally collapsed.   \n",
       "12412        Tom was able to get something close enough.   \n",
       "12413              Jimmy wanted to go to the playground.   \n",
       "12414  His friends thought it'd be funny, and left hi...   \n",
       "\n",
       "                                              selection1  \\\n",
       "0      She watched as the doll was passed around the ...   \n",
       "1                               Sophia was a neat freak.   \n",
       "2      Jordan's mom is happy to see her little girl g...   \n",
       "3                  Doug has always wanted to be married.   \n",
       "4             I let them go play without my supervision.   \n",
       "...                                                  ...   \n",
       "12410  So he felt regretful about having the smoothie...   \n",
       "12411                    They team up and become a band.   \n",
       "12412  Kevin took the car out for a drive for the fir...   \n",
       "12413                     Her teacher saw Holly napping.   \n",
       "12414  Fran just landed in Thailand for her grand one...   \n",
       "\n",
       "                                              selection2  \\\n",
       "0      One morning, Jim was admiring his crush, Micha...   \n",
       "1      She stood up quickly and knocked the bottle ov...   \n",
       "2      When the other kids wouldn't move over I'd sta...   \n",
       "3      Her dad was hesitant, but he allowed her to si...   \n",
       "4          However, it broke apart when he lifted it up.   \n",
       "...                                                  ...   \n",
       "12410                  We also had a lot of food to eat.   \n",
       "12411  John was digging in his backyard when he found...   \n",
       "12412                 Tom noticed his watch was missing.   \n",
       "12413  Candy was the owner's daughter, and Bill was a...   \n",
       "12414  Oscar decided that he must get a job to be abl...   \n",
       "\n",
       "                                              selection3  \\\n",
       "0                    But Carlos was glad to get it done.   \n",
       "1            Chad was eight Year's old and growing fast.   \n",
       "2                        Tim pulled over to check on it.   \n",
       "3      Her mom bought her a Chinese outfit, but Ellie...   \n",
       "4      Tom was excited for Tuesday, it was his new fa...   \n",
       "...                                                  ...   \n",
       "12410          Everything was taken except for one spot.   \n",
       "12411                      Charles contacted the seller.   \n",
       "12412  He was rushed to the hospital by the employees...   \n",
       "12413           Eventually Chuck became incredibly fast.   \n",
       "12414  Her internships and grades earned her a spot i...   \n",
       "\n",
       "                                              selection4  label  \n",
       "0                  He brought them home in a canvas bag.      1  \n",
       "1      I am already looking forward to next year's fair.      2  \n",
       "2                      They went outside the city areas.      2  \n",
       "3      One day I decided I wanted to become a profess...      0  \n",
       "4          She thought she included all the ingredients.      3  \n",
       "...                                                  ...    ...  \n",
       "12410         Suddenly, he bumped one of the back tires.      4  \n",
       "12411  The device could determine if he was a good or...      4  \n",
       "12412  To his delight this meant he didn't have to ta...      2  \n",
       "12413  Ed and Emma were twins and wanted to have matc...      0  \n",
       "12414  When she took the clothes out, everything that...      4  \n",
       "\n",
       "[12415 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDatasetProcessed.to_csv(f'./dataset/5Select-{fileTag}-train.csv')\n",
    "trainDatasetProcessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b770299d-567d-46e2-b928-8ee31a341c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>plutchik</th>\n",
       "      <th>selection0</th>\n",
       "      <th>selection1</th>\n",
       "      <th>selection2</th>\n",
       "      <th>selection3</th>\n",
       "      <th>selection4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['happy', 'proud', 'commanding', 'none', 'vict...</td>\n",
       "      <td>{'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>They decided to drive to the house.</td>\n",
       "      <td>She earned a college scholarship by winning th...</td>\n",
       "      <td>He got up the nerve to ask if he could sit wit...</td>\n",
       "      <td>She said it was the best thing she'd ever tasted.</td>\n",
       "      <td>I put my earphones on and listen to music.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Competitive', 'Intimidated', 'excited', 'none']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>When I woke up, I found out that the skies wer...</td>\n",
       "      <td>At the first light the car next to him wanted ...</td>\n",
       "      <td>Charles hates Tameka.</td>\n",
       "      <td>They are now engaged.</td>\n",
       "      <td>A substitute teacher came to teach her class f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['surprised', 'amused', 'none']</td>\n",
       "      <td>{'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Now Raymond is able to staple the papers toget...</td>\n",
       "      <td>I was in shape and ready for my upcoming wedding.</td>\n",
       "      <td>He took a train ride to the beautiful location.</td>\n",
       "      <td>Bob heard a weather report while listening to ...</td>\n",
       "      <td>An hour later, the delivery man pulled up.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['happy', 'satisfied', 'glad']</td>\n",
       "      <td>{'joy': 2, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>John was glad he had cleaned out his car.</td>\n",
       "      <td>Alex loves horror movies.</td>\n",
       "      <td>Mia took a cab home, and was angry at her daug...</td>\n",
       "      <td>There was a great deal on mangoes.</td>\n",
       "      <td>Marvin was afraid to fly.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['none', 'disappointed']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>A dead body was floating within a meter of whe...</td>\n",
       "      <td>Kay was taking piano lessons.</td>\n",
       "      <td>When Ben opened his cookie, his was empty.</td>\n",
       "      <td>He looked in his car and most of his apartment.</td>\n",
       "      <td>They joined for their boyfriends.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11845</th>\n",
       "      <td>['embarassed', 'surprised', 'humbled', 'sorry'...</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Being laid off meant more time to take his att...</td>\n",
       "      <td>Their latest therapy was a special diet, which...</td>\n",
       "      <td>The friend told him that he actually was Mexican.</td>\n",
       "      <td>She cleaned the car from top to bottom.</td>\n",
       "      <td>The committee wanted to raise $1000 for the ne...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11846</th>\n",
       "      <td>['excited', 'Excited', 'Happy']</td>\n",
       "      <td>{'joy': 3, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>When he got there, he went to the locker room.</td>\n",
       "      <td>She cleaned out her garage and closets.</td>\n",
       "      <td>Many cars rushed out of the way to make room f...</td>\n",
       "      <td>She went to a place recommended by her friends.</td>\n",
       "      <td>Like usual this year her home was the most pop...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11847</th>\n",
       "      <td>['Hopeful', 'excited', 'hopeful']</td>\n",
       "      <td>{'joy': 2, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>Every chance she had to make a scrapbook for s...</td>\n",
       "      <td>One day she saw a foreclosed home.</td>\n",
       "      <td>Thomas came home and caught his roommate steal...</td>\n",
       "      <td>Instead of failing them, he had to fail the en...</td>\n",
       "      <td>Fred laughed and told Luke they should play ag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11848</th>\n",
       "      <td>['none']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>We used the weekly circular to determine which...</td>\n",
       "      <td>They hit it off and kept talking to each other.</td>\n",
       "      <td>Aunt Becky use to be so calm.</td>\n",
       "      <td>DJ did her best and gave a powerful performance.</td>\n",
       "      <td>Anita wanted to make her son's father upset.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11849</th>\n",
       "      <td>['none', 'excited', 'hopeful']</td>\n",
       "      <td>{'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "      <td>His malpractice insurance lost the case.</td>\n",
       "      <td>Don wanted to become a dancer.</td>\n",
       "      <td>She brought her husband.</td>\n",
       "      <td>Bret got grounded for even longer.</td>\n",
       "      <td>Now i always put my keys on the hook.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11850 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 emotion  \\\n",
       "0      ['happy', 'proud', 'commanding', 'none', 'vict...   \n",
       "1      ['Competitive', 'Intimidated', 'excited', 'none']   \n",
       "2                        ['surprised', 'amused', 'none']   \n",
       "3                         ['happy', 'satisfied', 'glad']   \n",
       "4                               ['none', 'disappointed']   \n",
       "...                                                  ...   \n",
       "11845  ['embarassed', 'surprised', 'humbled', 'sorry'...   \n",
       "11846                    ['excited', 'Excited', 'Happy']   \n",
       "11847                  ['Hopeful', 'excited', 'hopeful']   \n",
       "11848                                           ['none']   \n",
       "11849                     ['none', 'excited', 'hopeful']   \n",
       "\n",
       "                                                plutchik  \\\n",
       "0      {'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...   \n",
       "1      {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "2      {'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "3      {'joy': 2, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "4      {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "...                                                  ...   \n",
       "11845  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "11846  {'joy': 3, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "11847  {'joy': 2, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "11848  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "11849  {'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...   \n",
       "\n",
       "                                              selection0  \\\n",
       "0                    They decided to drive to the house.   \n",
       "1      When I woke up, I found out that the skies wer...   \n",
       "2      Now Raymond is able to staple the papers toget...   \n",
       "3              John was glad he had cleaned out his car.   \n",
       "4      A dead body was floating within a meter of whe...   \n",
       "...                                                  ...   \n",
       "11845  Being laid off meant more time to take his att...   \n",
       "11846     When he got there, he went to the locker room.   \n",
       "11847  Every chance she had to make a scrapbook for s...   \n",
       "11848  We used the weekly circular to determine which...   \n",
       "11849           His malpractice insurance lost the case.   \n",
       "\n",
       "                                              selection1  \\\n",
       "0      She earned a college scholarship by winning th...   \n",
       "1      At the first light the car next to him wanted ...   \n",
       "2      I was in shape and ready for my upcoming wedding.   \n",
       "3                              Alex loves horror movies.   \n",
       "4                          Kay was taking piano lessons.   \n",
       "...                                                  ...   \n",
       "11845  Their latest therapy was a special diet, which...   \n",
       "11846            She cleaned out her garage and closets.   \n",
       "11847                 One day she saw a foreclosed home.   \n",
       "11848    They hit it off and kept talking to each other.   \n",
       "11849                     Don wanted to become a dancer.   \n",
       "\n",
       "                                              selection2  \\\n",
       "0      He got up the nerve to ask if he could sit wit...   \n",
       "1                                  Charles hates Tameka.   \n",
       "2        He took a train ride to the beautiful location.   \n",
       "3      Mia took a cab home, and was angry at her daug...   \n",
       "4             When Ben opened his cookie, his was empty.   \n",
       "...                                                  ...   \n",
       "11845  The friend told him that he actually was Mexican.   \n",
       "11846  Many cars rushed out of the way to make room f...   \n",
       "11847  Thomas came home and caught his roommate steal...   \n",
       "11848                      Aunt Becky use to be so calm.   \n",
       "11849                           She brought her husband.   \n",
       "\n",
       "                                              selection3  \\\n",
       "0      She said it was the best thing she'd ever tasted.   \n",
       "1                                  They are now engaged.   \n",
       "2      Bob heard a weather report while listening to ...   \n",
       "3                     There was a great deal on mangoes.   \n",
       "4        He looked in his car and most of his apartment.   \n",
       "...                                                  ...   \n",
       "11845            She cleaned the car from top to bottom.   \n",
       "11846    She went to a place recommended by her friends.   \n",
       "11847  Instead of failing them, he had to fail the en...   \n",
       "11848   DJ did her best and gave a powerful performance.   \n",
       "11849                 Bret got grounded for even longer.   \n",
       "\n",
       "                                              selection4  label  \n",
       "0             I put my earphones on and listen to music.      1  \n",
       "1      A substitute teacher came to teach her class f...      1  \n",
       "2             An hour later, the delivery man pulled up.      3  \n",
       "3                              Marvin was afraid to fly.      0  \n",
       "4                      They joined for their boyfriends.      2  \n",
       "...                                                  ...    ...  \n",
       "11845  The committee wanted to raise $1000 for the ne...      2  \n",
       "11846  Like usual this year her home was the most pop...      0  \n",
       "11847  Fred laughed and told Luke they should play ag...      1  \n",
       "11848       Anita wanted to make her son's father upset.      2  \n",
       "11849              Now i always put my keys on the hook.      1  \n",
       "\n",
       "[11850 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDatasetProcessed.to_csv(f'./dataset/5Select-{fileTag}-test.csv')\n",
    "testDatasetProcessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7283c1-d83e-4369-b5e4-6c2e09d654ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "828a5092-83e6-4580-99c9-bd9ec434708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "05151e3b-0bec-44f4-bf0a-ac58cddbf838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9a37d2835e3cbdf2\n",
      "Reusing dataset csv (C:\\Users\\JAM_0\\.cache\\huggingface\\datasets\\csv\\default-9a37d2835e3cbdf2\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "073082aacaed4165b3c5fd3fcc039e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('csv', data_files={'train': f'./dataset/5Select-{fileTag}-train.csv', \n",
    "                                           'test': f'./dataset/5Select-{fileTag}-test.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d776c270-7752-4445-ba6c-eb078f71eccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'emotion', 'plutchik', 'selection0', 'selection1', 'selection2', 'selection3', 'selection4', 'label'],\n",
       "        num_rows: 11610\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'emotion', 'plutchik', 'selection0', 'selection1', 'selection2', 'selection3', 'selection4', 'label'],\n",
       "        num_rows: 11129\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a1c79159-f795-4d02-b052-94f04286d53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 0,\n",
       " 'emotion': \"['honest', 'happy', 'proud']\",\n",
       " 'plutchik': \"{'joy': 2, 'trust': 1, 'fear': 0, 'surprise': 0, 'sadness': 0, 'disgust': 0, 'anger': 0, 'anticipation': 0}\",\n",
       " 'selection0': 'Since school is starting soon, I want to give her time to adjust.',\n",
       " 'selection1': \"I wasn't allowed to have toys, so I played with my brother's.\",\n",
       " 'selection2': 'Mark was an honest soccer player who played by the rules.',\n",
       " 'selection3': 'John desperately needed some money to pay bills.',\n",
       " 'selection4': 'It was good food and it was cheap.',\n",
       " 'label': 2}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1f6ad67d-b4cb-4f65-a9cb-d2d665deec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_one(example):\n",
    "    print(f\"Context: {example['plutchik']}\")\n",
    "    print(f\"  A - {example['selection0']}\")\n",
    "    print(f\"  B - {example['selection1']}\")\n",
    "    print(f\"  C - {example['selection2']}\")\n",
    "    print(f\"  D - {example['selection3']}\")\n",
    "    print(f\"  E - {example['selection4']}\")\n",
    "    print(f\"\\nGround truth: option {['A', 'B', 'C', 'D', 'E'][example['label']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "15cd7cfb-748a-4fe7-8152-7debf6a65ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: {'joy': 2, 'trust': 3, 'fear': 0, 'surprise': 0, 'sadness': 0, 'disgust': 0, 'anger': 0, 'anticipation': 2}\n",
      "  A - James rushed to finish his PowerPoint.\n",
      "  B - Breanna wants to lose some weight.\n",
      "  C - George was walking past a row of parked bikes.\n",
      "  D - He had to move away.\n",
      "  E - Once he got there the beekeeper asked if Mark would like a tour.\n",
      "\n",
      "Ground truth: option E\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da93346-1037-41ed-b67d-91877fa8c0ec",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3da78c12-9aff-4beb-a006-e287bbf61023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/vocab.txt from cache at C:\\Users\\JAM_0/.cache\\huggingface\\transformers\\ba377304984dc63e3ede0e23a938bbbf04d5c3835b66d5bb48343aecca188429.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/tokenizer_config.json from cache at C:\\Users\\JAM_0/.cache\\huggingface\\transformers\\81e970e5e6ec68be12da0f8f3b2f2469c78d579282299a2ea65b4b7441719107.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/distilbert-base-cased/resolve/main/config.json from cache at C:\\Users\\JAM_0/.cache\\huggingface\\transformers\\ebe1ea24d11aa664488b8de5b21e33989008ca78f207d4e30ec6350b693f073f.302bfd1b5e031cc1b17796e0b6e5b242ba2045d31d00f97589e12b458ebff27a\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if model_checkpoint != 'distilbert-base-uncased-finetuned-sst-2-english':\n",
    "    from transformers import AutoTokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "else:\n",
    "    from transformers import DistilBertTokenizer, DistilBertForMultipleChoice\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "caffe397-a65d-478f-b966-7b910fb2edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "selectionList = [\"selection0\", \"selection1\", \"selection2\", 'selection3', 'selection4']\n",
    "weightRemap = [\"NOT \", \"LITTLE \", \"\", \"VERY \", \"ABSOLUTELY \"]\n",
    "def preprocess_function(examples):\n",
    "    # Repeat each first sentence four times to go with the four possibilities of second sentences.\n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(context.strip(\"[\").strip(\"]\").replace('\\'', '')) ]*2 for context in examples[\"emotion\"] ]\n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(context.strip(\"[\").strip(\"]\").replace('\\\"', '')) ]*2 for context in examples[\"plutchik\"] ]\n",
    "    first_sentences = [[\"The following sentences contain emotions: {}\".format(\", \".join([weightRemap[int(eachCaseWeight.replace(\"]\", \"\").replace(\"[\", \"\").replace(\"}\", \"\").replace(\"{\", \"\").replace(\"\\\"\", \"\").replace(\"\\'\", \"\"))] \n",
    "                                                        + eachCaseEmotionType.replace(\"]\", \"\").replace(\"[\", \"\").replace(\"}\", \"\").replace(\"{\", \"\").replace(\"\\\"\", \"\").replace(\"\\'\", \"\").strip()\n",
    "                        for eachCaseWeight, eachCaseEmotionType in \n",
    "                        zip([re.split(':|,',eachEmotionCombination)[1::2] for eachEmotionCombination in examples[\"plutchik\"]][eventIndex], \n",
    "                           [re.split(':|,',eachEmotionCombination)[::2] for eachEmotionCombination in examples[\"plutchik\"]][eventIndex])]))]*5 for eventIndex in \n",
    "                           range(len([re.split(':|,',eachEmotionCombination)[1::2] for eachEmotionCombination in examples[\"plutchik\"]]))]\n",
    "    \n",
    "    # first_sentences = [[\"The following sentences contain emotions: {}\".format(', '.join([(weightRemap[eachEmotion[1]] + \" \" +eachEmotion[0]).strip() \n",
    "    #                    for eachEmotion in ast.literal_eval(context).items()]))]*2 \n",
    "    #                    for context in examples[\"plutchik\"]]\n",
    "    # Grab all second sentences possible for each context.\n",
    "    second_sentences = [[examples[selection][index] for selection in selectionList]for index in range(len(examples['selection0']))]\n",
    "\n",
    "    # Flatten everything\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "    \n",
    "    # Tokenize\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "    # Un-flatten\n",
    "    # print(tokenized_examples.items())\n",
    "    return {k: [v[i:i+5] for i in range(0, len(v), 5)] for k, v in tokenized_examples.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0afb4841-ab69-4b91-8859-fd249badb923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5 [46, 46, 47, 43, 52]\n"
     ]
    }
   ],
   "source": [
    "examples = dataset[\"train\"][:5]\n",
    "features = preprocess_function(examples)\n",
    "print(len(features[\"input_ids\"]), len(features[\"input_ids\"][0]), [len(x) for x in features[\"input_ids\"][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "903e2891-0e3d-4e87-b98a-727eaf36417a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] The following sentences contain emotions : joy, VERY trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, anticipation [SEP] James rushed to finish his PowerPoint. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : joy, VERY trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, anticipation [SEP] Breanna wants to lose some weight. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : joy, VERY trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, anticipation [SEP] George was walking past a row of parked bikes. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : joy, VERY trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, anticipation [SEP] He had to move away. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : NOT joy, NOT trust, fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, anticipation [SEP] She always gossiped about other people and said ugly things. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : NOT joy, NOT trust, fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, anticipation [SEP] My boyfriend took me to Amsterdam one year. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : NOT joy, NOT trust, fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, anticipation [SEP] Dale is at his favorite bar having drinks [SEP]',\n",
       " '[CLS] The following sentences contain emotions : NOT joy, NOT trust, fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, anticipation [SEP] The trail took them through dark woods. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : LITTLE joy, LITTLE trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation [SEP] The farmer woke up early everyday. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : LITTLE joy, LITTLE trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation [SEP] She had everyone dressed including herself. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : LITTLE joy, LITTLE trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation [SEP] He did this until he was 80 years old. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : LITTLE joy, LITTLE trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation [SEP] She decided to throw a big party. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : VERY joy, LITTLE trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, anticipation [SEP] She would tell everyone that Alice lived in cardboard box. [SEP]',\n",
       " \"[CLS] The following sentences contain emotions : VERY joy, LITTLE trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, anticipation [SEP] He can't because of his contract. [SEP]\",\n",
       " '[CLS] The following sentences contain emotions : VERY joy, LITTLE trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, anticipation [SEP] He looked inside and saw the Home Ec class had baked pies. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : VERY joy, LITTLE trust, NOT fear, LITTLE surprise, NOT sadness, NOT disgust, NOT anger, anticipation [SEP] He found many of them and hung them on his shirt like decorations. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : LITTLE joy, NOT trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation [SEP] Ronald had a bag that meant a lot to him. [SEP]',\n",
       " '[CLS] The following sentences contain emotions : LITTLE joy, NOT trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation [SEP] Henry was walking while holding Stacy. [SEP]',\n",
       " \"[CLS] The following sentences contain emotions : LITTLE joy, NOT trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation [SEP] Judy went to her grandmother's on Saturday morning. [SEP]\",\n",
       " '[CLS] The following sentences contain emotions : LITTLE joy, NOT trust, NOT fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, NOT anticipation [SEP] Jack and Diane tried to follow it but they were not able to find him. [SEP]']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(features[\"input_ids\"][a][i]) for a in range(5) for i in range(4) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4a286ba6-cb84-4619-b842-780124d26a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a13198dd2a4bc5ac5df16743b7c71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "308de070612c401b829849b4d47ad8dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7706d875-3a89-4e52-9f08-c77256b621ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-cased/resolve/main/config.json from cache at C:\\Users\\JAM_0/.cache\\huggingface\\transformers\\ebe1ea24d11aa664488b8de5b21e33989008ca78f207d4e30ec6350b693f073f.302bfd1b5e031cc1b17796e0b6e5b242ba2045d31d00f97589e12b458ebff27a\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-cased/resolve/main/pytorch_model.bin from cache at C:\\Users\\JAM_0/.cache\\huggingface\\transformers\\9c9f39769dba4c5fe379b4bc82973eb01297bd607954621434eb9f1bc85a23a0.06b428c87335c1bb22eae46fdab31c8286efa0aa09e898a7ac42ddf5c3f5dc19\n",
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForMultipleChoice: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForMultipleChoice were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "if model_checkpoint != 'distilbert-base-uncased-finetuned-sst-2-english':\n",
    "    from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "    model = AutoModelForMultipleChoice.from_pretrained(model_checkpoint)\n",
    "else:\n",
    "    from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "    from transformers import DistilBertTokenizer, DistilBertForMultipleChoice\n",
    "    import torch\n",
    "    model = DistilBertForMultipleChoice.from_pretrained(\"distilbert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2cd7be65-ebd8-43db-bcbf-a87d7e2342e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-emotionCommonsense\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=5e-6, # for bert-base\n",
    "    # learning_rate=1e-3,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2737e04e-19c2-407d-8ce1-06b675f208c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [[{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        # Un-flatten\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        # Add back labels\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "03a0ec05-de5e-434f-b07c-63212e7c7f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_keys = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "features = [{k: v for k, v in encoded_datasets[\"train\"][i].items() if k in accepted_keys} for i in range(10)]\n",
    "batch = DataCollatorForMultipleChoice(tokenizer)(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "45f7f26c-04bb-42ae-8627-897ced69888e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] The following sentences contain emotions : NOT joy, NOT trust, fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, anticipation [SEP] Paul purchased a book from the bookstore. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] The following sentences contain emotions : NOT joy, NOT trust, fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, anticipation [SEP] The dog started sniffing intently under a bush. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] The following sentences contain emotions : NOT joy, NOT trust, fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, anticipation [SEP] The next day, it took all her courage to be interviewed. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] The following sentences contain emotions : NOT joy, NOT trust, fear, NOT surprise, NOT sadness, NOT disgust, NOT anger, anticipation [SEP] Mike went to light the grill. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(batch[\"input_ids\"][8][i].tolist()) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c4b55256-30fa-4e30-a3a4-66fe1114b941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: {'joy': 0, 'trust': 0, 'fear': 2, 'surprise': 0, 'sadness': 0, 'disgust': 0, 'anger': 0, 'anticipation': 2}\n",
      "  A - Paul purchased a book from the bookstore.\n",
      "  B - The dog started sniffing intently under a bush.\n",
      "  C - The next day, it took all her courage to be interviewed.\n",
      "  D - Mike went to light the grill.\n",
      "  E - As the stars came into view she stood in awe.\n",
      "\n",
      "Ground truth: option C\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8305d3-8dc9-4d0f-8628-f51dc356c2d2",
   "metadata": {},
   "source": [
    "# Trainer Defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b707863a-bc16-43b0-b633-c7ffb4fa72e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "valStored = []\n",
    "def compute_metrics(eval_predictions):\n",
    "    predictions, label_ids = eval_predictions\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    valStored.append((preds != label_ids).astype(np.float32));\n",
    "    return {\"accuracy\": (preds == label_ids).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b115c1ba-323a-47d5-bb9d-55de985f13b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_datasets[\"train\"],\n",
    "    eval_dataset=encoded_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2a5e3430-bbd6-484d-8a8d-9cbcdba37d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4. If selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "C:\\Python\\miniconda3\\envs\\pytorchEnvWithDataSci\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 11610\n",
      "  Num Epochs = 16\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11616\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11616' max='11616' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11616/11616 32:13, Epoch 16/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.610500</td>\n",
       "      <td>1.598718</td>\n",
       "      <td>0.262288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.581600</td>\n",
       "      <td>1.345828</td>\n",
       "      <td>0.378201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.343900</td>\n",
       "      <td>1.331349</td>\n",
       "      <td>0.386558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.314000</td>\n",
       "      <td>1.335611</td>\n",
       "      <td>0.396981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.250600</td>\n",
       "      <td>1.331430</td>\n",
       "      <td>0.401653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.208700</td>\n",
       "      <td>1.341696</td>\n",
       "      <td>0.402642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.172100</td>\n",
       "      <td>1.342984</td>\n",
       "      <td>0.411088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.139000</td>\n",
       "      <td>1.345296</td>\n",
       "      <td>0.415581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.112200</td>\n",
       "      <td>1.381272</td>\n",
       "      <td>0.419894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.072100</td>\n",
       "      <td>1.396625</td>\n",
       "      <td>0.415850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.061800</td>\n",
       "      <td>1.405556</td>\n",
       "      <td>0.421152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.027200</td>\n",
       "      <td>1.432779</td>\n",
       "      <td>0.426633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.012600</td>\n",
       "      <td>1.453085</td>\n",
       "      <td>0.426723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.983600</td>\n",
       "      <td>1.453333</td>\n",
       "      <td>0.430946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.976600</td>\n",
       "      <td>1.463239</td>\n",
       "      <td>0.428879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.949500</td>\n",
       "      <td>1.477226</td>\n",
       "      <td>0.428790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4. If selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4. If selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-1500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4. If selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-2500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4. If selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-3500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4. If selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4. If selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-4500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4. If selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-5500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4. If selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-6500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4. If selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4. If selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-7500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4. If selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-8500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4. If selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4. If selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-9500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4. If selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-10500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4. If selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-sst-2-english-finetuned-emotionCommonsense\\checkpoint-11500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMultipleChoice.forward` and have been ignored: selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4. If selection1, selection0, selection3, Unnamed: 0, emotion, plutchik, selection2, selection4 are not expected by `DistilBertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11129\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11616, training_loss=1.165351300200155, metrics={'train_runtime': 1934.6141, 'train_samples_per_second': 96.019, 'train_steps_per_second': 6.004, 'total_flos': 1.542035577538794e+16, 'train_loss': 1.165351300200155, 'epoch': 16.0})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a17948-a8f7-4450-b2b0-8a7016e91391",
   "metadata": {},
   "source": [
    "出现validation loss 上升情况大多是训练集验证集数据分布不一致，或者训练集过小，未包含验证集中所有情况，\n",
    "也就是过拟合导致的。而解决这种现象可以尝试以下几种策略：\n",
    "1. 增加训练样本增加正则项系数权重，\n",
    "2. 减小过拟合加入早停机制，ValLoss上升几个epoch直接停止\n",
    "3. 采用Focal Loss\n",
    "4. 加入Label Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d6ab3-33ac-4e8e-99ee-3c3f17d71642",
   "metadata": {},
   "source": [
    "# Store Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c30271fe-7ce9-43e8-9e87-de8d6ae2c2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x23113595460>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "Z = np.transpose(valStored)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.pcolormesh(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5e77d30e-e51a-45a6-9130-83a17c4d2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "if model_checkpoint == 'distilbert-base-uncased-finetuned-sst-2-english':\n",
    "    model_checkpoint = 'distilbert-base'\n",
    "dataLog = pd.DataFrame(trainer.state.log_history)\n",
    "dataLog.to_csv(f'./trainingMetric/[Plutchik] 5Select/TI-{model_checkpoint}-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c90cfec4-96ec-46c8-a99f-3c78b989b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluationIterationResult = pd.DataFrame(np.transpose(valStored))\n",
    "evaluationIterationResult.to_csv(f'./trainingMetric/[Plutchik] 5Select/ESI-{model_checkpoint}-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd7f330-1477-4119-a9dc-1ebb7acb7665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchEnvWithDataSci",
   "language": "python",
   "name": "pytorchenvwithdatasci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
